{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39189dfb",
   "metadata": {},
   "source": [
    "# 1. Install modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e906fe9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hit:1 http://ports.ubuntu.com/ubuntu-ports noble InRelease                     \n",
      "Hit:2 http://ports.ubuntu.com/ubuntu-ports noble-updates InRelease             \n",
      "Hit:3 http://ports.ubuntu.com/ubuntu-ports noble-backports InRelease           \n",
      "Hit:4 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu noble InRelease\n",
      "Hit:5 http://ports.ubuntu.com/ubuntu-ports noble-security InRelease \n",
      "Hit:6 https://packages.microsoft.com/repos/code stable InRelease\n",
      "Reading package lists... Done\n",
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "fastp is already the newest version (0.23.4+dfsg-1).\n",
      "flash is already the newest version (1.2.11-2).\n",
      "bwa is already the newest version (0.7.17-7).\n",
      "samtools is already the newest version (1.19.2-1build2).\n",
      "The following packages were automatically installed and are no longer required:\n",
      "  pigz python3-xopen\n",
      "Use 'sudo apt autoremove' to remove them.\n",
      "0 upgraded, 0 newly installed, 0 to remove and 275 not upgraded.\n",
      "Requirement already satisfied: biopython in /usr/local/lib/python3.12/dist-packages (1.84)\n",
      "Requirement already satisfied: cutadapt in /usr/local/lib/python3.12/dist-packages (5.0)\n",
      "Requirement already satisfied: pysam in /usr/local/lib/python3.12/dist-packages (0.22.1)\n",
      "Requirement already satisfied: numpy in /usr/lib/python3/dist-packages (from biopython) (1.26.4)\n",
      "Requirement already satisfied: dnaio>=1.2.3 in /usr/local/lib/python3.12/dist-packages (from cutadapt) (1.2.3)\n",
      "Requirement already satisfied: xopen>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from cutadapt) (2.0.2)\n",
      "Requirement already satisfied: isal>=1.6.1 in /usr/local/lib/python3.12/dist-packages (from xopen>=1.6.0->cutadapt) (1.7.1)\n",
      "Requirement already satisfied: zlib-ng>=0.4.1 in /usr/local/lib/python3.12/dist-packages (from xopen>=1.6.0->cutadapt) (0.5.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# Bioinformatics Tools (Ubuntu)\n",
    "!sudo apt-get update\n",
    "!sudo apt-get install -y fastp flash bwa samtools\n",
    "\n",
    "# Python Library\n",
    "!pip3 install biopython cutadapt pysam --break-system-packages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd54a0a6",
   "metadata": {},
   "source": [
    "# 2. Trimming and Discard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8ac5eda6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Untrimmed sequences saved: fastq_7_8_9_10_11_12/A_Untrimmed_output/Stepwise_07step_R1_untrimmed.fastq.gz, fastq_7_8_9_10_11_12/A_Untrimmed_output/Stepwise_07step_R2_untrimmed.fastq.gz\n",
      "Untrimmed sequences saved: fastq_7_8_9_10_11_12/A_Untrimmed_output/Stepwise_08step_R1_untrimmed.fastq.gz, fastq_7_8_9_10_11_12/A_Untrimmed_output/Stepwise_08step_R2_untrimmed.fastq.gz\n",
      "Untrimmed sequences saved: fastq_7_8_9_10_11_12/A_Untrimmed_output/Stepwise_09step_R1_untrimmed.fastq.gz, fastq_7_8_9_10_11_12/A_Untrimmed_output/Stepwise_09step_R2_untrimmed.fastq.gz\n",
      "Untrimmed sequences saved: fastq_7_8_9_10_11_12/A_Untrimmed_output/Stepwise_10step_R1_untrimmed.fastq.gz, fastq_7_8_9_10_11_12/A_Untrimmed_output/Stepwise_10step_R2_untrimmed.fastq.gz\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# Specify the folder containing your input files\n",
    "# Specify the folder where you want to save the untrimmed sequences (adapter-free sequences)\n",
    "input_folder = \"fastq_7_8_9_10_11_12\"\n",
    "untrimmed_output_folder = \"fastq_7_8_9_10_11_12/A_Untrimmed_output\"\n",
    "\n",
    "# Define the adapter sequences for R1 and R2\n",
    "adapter_sequence_r1 = \"AGATCGGAAGAGCACACGTCTGAACTCCAGTCAC\"\n",
    "adapter_sequence_r2 = \"AGATCGGAAGAGCGTCGTGTAGGGAAAGAGTGT\"\n",
    "\n",
    "# Use glob to get a list of all input file pairs (R1 and R2) in the folder\n",
    "input_file_pairs = []\n",
    "for input_r1 in glob.glob(os.path.join(input_folder, \"*_R1.fastq.gz\")):\n",
    "    # Assuming R2 files have the same naming format as R1 files\n",
    "    input_r2 = input_r1.replace(\"_R1.fastq.gz\", \"_R2.fastq.gz\")\n",
    "    if os.path.exists(input_r2):  # Ensure R2 file exists\n",
    "        input_file_pairs.append({\"r1\": input_r1, \"r2\": input_r2})\n",
    "\n",
    "# Create the output folder if it doesn't exist\n",
    "os.makedirs(untrimmed_output_folder, exist_ok=True)\n",
    "\n",
    "for input_files in input_file_pairs:\n",
    "    input_r1 = input_files[\"r1\"]\n",
    "    input_r2 = input_files[\"r2\"]\n",
    "\n",
    "    # Define output file paths for untrimmed (clean, adapter-free) sequences\n",
    "    untrimmed_r1 = os.path.join(untrimmed_output_folder, os.path.basename(input_r1).replace(\".fastq.gz\", \"_untrimmed.fastq.gz\"))\n",
    "    untrimmed_r2 = os.path.join(untrimmed_output_folder, os.path.basename(input_r2).replace(\".fastq.gz\", \"_untrimmed.fastq.gz\"))\n",
    "\n",
    "    # Use cutadapt to keep only untrimmed sequences (completely adapter-free)\n",
    "    result = subprocess.run([\n",
    "        \"cutadapt\",\n",
    "        \"-a\", adapter_sequence_r1,  # Adapter for R1\n",
    "        \"-A\", adapter_sequence_r2,  # Adapter for R2\n",
    "        \"-O\", \"15\",  # Minimum overlap for adapter trimming\n",
    "        \"--discard-trimmed\",  # Discard sequences where trimming occurred\n",
    "        \"-o\", untrimmed_r1,  # Save only untrimmed R1 reads\n",
    "        \"-p\", untrimmed_r2,  # Save only untrimmed R2 reads\n",
    "        input_r1, input_r2\n",
    "    ], capture_output=True, text=True)\n",
    "\n",
    "    # Log result\n",
    "    if result.returncode == 0:\n",
    "        print(f\"Untrimmed sequences saved: {untrimmed_r1}, {untrimmed_r2}\")\n",
    "    else:\n",
    "        print(f\"Error processing {input_r1} and {input_r2}:\\n{result.stderr}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d43590a",
   "metadata": {},
   "source": [
    "# 3. Q filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "330bc19f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: you specified the options for cutting by quality, but forogt to enable any of cut_front/cut_tail/cut_right. This will have no effect.\n",
      "Detecting adapter sequence for read1...\n",
      "No adapter detected for read1\n",
      "\n",
      "Read1 before filtering:\n",
      "total reads: 1695\n",
      "total bases: 255945\n",
      "Q20 bases: 216727(84.6772%)\n",
      "Q30 bases: 192828(75.3396%)\n",
      "\n",
      "Read1 after filtering:\n",
      "total reads: 572\n",
      "total bases: 86372\n",
      "Q20 bases: 83774(96.9921%)\n",
      "Q30 bases: 79404(91.9326%)\n",
      "\n",
      "Filtering result:\n",
      "reads passed filter: 572\n",
      "reads failed due to low quality: 1123\n",
      "reads failed due to too many N: 0\n",
      "reads failed due to too short: 0\n",
      "reads with adapter trimmed: 0\n",
      "bases trimmed due to adapters: 0\n",
      "\n",
      "Duplication rate (may be overestimated since this is SE data): 18.6431%\n",
      "\n",
      "JSON report: fastq_7_8_9_10_11_12/B_Qfiltered/Stepwise_10step_R1_Qfiltered.fastq.gz.json\n",
      "HTML report: fastq_7_8_9_10_11_12/B_Qfiltered/Stepwise_10step_R1_Qfiltered.fastq.gz.html\n",
      "\n",
      "fastp -i fastq_7_8_9_10_11_12/A_Untrimmed_output/Stepwise_10step_R1_untrimmed.fastq.gz -o fastq_7_8_9_10_11_12/B_Qfiltered/Stepwise_10step_R1_Qfiltered.fastq.gz -q 30 -u 15 -l 151 --cut_mean_quality 30 --html fastq_7_8_9_10_11_12/B_Qfiltered/Stepwise_10step_R1_Qfiltered.fastq.gz.html --json fastq_7_8_9_10_11_12/B_Qfiltered/Stepwise_10step_R1_Qfiltered.fastq.gz.json \n",
      "fastp v0.23.4, time used: 1 seconds\n",
      "WARNING: you specified the options for cutting by quality, but forogt to enable any of cut_front/cut_tail/cut_right. This will have no effect.\n",
      "Detecting adapter sequence for read1...\n",
      "No adapter detected for read1\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering for Stepwise_10step_R1_untrimmed.fastq.gz is complete.\n",
      "Output FASTQ : fastq_7_8_9_10_11_12/B_Qfiltered/Stepwise_10step_R1_Qfiltered.fastq.gz\n",
      "Reports      : fastq_7_8_9_10_11_12/B_Qfiltered/Stepwise_10step_R1_Qfiltered.fastq.gz.html / fastq_7_8_9_10_11_12/B_Qfiltered/Stepwise_10step_R1_Qfiltered.fastq.gz.json\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read1 before filtering:\n",
      "total reads: 1695\n",
      "total bases: 255945\n",
      "Q20 bases: 216366(84.5361%)\n",
      "Q30 bases: 190719(74.5156%)\n",
      "\n",
      "Read1 after filtering:\n",
      "total reads: 430\n",
      "total bases: 64930\n",
      "Q20 bases: 62401(96.105%)\n",
      "Q30 bases: 58299(89.7875%)\n",
      "\n",
      "Filtering result:\n",
      "reads passed filter: 430\n",
      "reads failed due to low quality: 1265\n",
      "reads failed due to too many N: 0\n",
      "reads failed due to too short: 0\n",
      "reads with adapter trimmed: 0\n",
      "bases trimmed due to adapters: 0\n",
      "\n",
      "Duplication rate (may be overestimated since this is SE data): 12.6844%\n",
      "\n",
      "JSON report: fastq_7_8_9_10_11_12/B_Qfiltered/Stepwise_10step_R2_Qfiltered.fastq.gz.json\n",
      "HTML report: fastq_7_8_9_10_11_12/B_Qfiltered/Stepwise_10step_R2_Qfiltered.fastq.gz.html\n",
      "\n",
      "fastp -i fastq_7_8_9_10_11_12/A_Untrimmed_output/Stepwise_10step_R2_untrimmed.fastq.gz -o fastq_7_8_9_10_11_12/B_Qfiltered/Stepwise_10step_R2_Qfiltered.fastq.gz -q 30 -u 15 -l 151 --cut_mean_quality 30 --html fastq_7_8_9_10_11_12/B_Qfiltered/Stepwise_10step_R2_Qfiltered.fastq.gz.html --json fastq_7_8_9_10_11_12/B_Qfiltered/Stepwise_10step_R2_Qfiltered.fastq.gz.json \n",
      "fastp v0.23.4, time used: 0 seconds\n",
      "WARNING: you specified the options for cutting by quality, but forogt to enable any of cut_front/cut_tail/cut_right. This will have no effect.\n",
      "Detecting adapter sequence for read1...\n",
      "No adapter detected for read1\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering for Stepwise_10step_R2_untrimmed.fastq.gz is complete.\n",
      "Output FASTQ : fastq_7_8_9_10_11_12/B_Qfiltered/Stepwise_10step_R2_Qfiltered.fastq.gz\n",
      "Reports      : fastq_7_8_9_10_11_12/B_Qfiltered/Stepwise_10step_R2_Qfiltered.fastq.gz.html / fastq_7_8_9_10_11_12/B_Qfiltered/Stepwise_10step_R2_Qfiltered.fastq.gz.json\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read1 before filtering:\n",
      "total reads: 1829\n",
      "total bases: 276179\n",
      "Q20 bases: 240704(87.1551%)\n",
      "Q30 bases: 215126(77.8937%)\n",
      "\n",
      "Read1 after filtering:\n",
      "total reads: 696\n",
      "total bases: 105096\n",
      "Q20 bases: 101193(96.2863%)\n",
      "Q30 bases: 94970(90.365%)\n",
      "\n",
      "Filtering result:\n",
      "reads passed filter: 696\n",
      "reads failed due to low quality: 1133\n",
      "reads failed due to too many N: 0\n",
      "reads failed due to too short: 0\n",
      "reads with adapter trimmed: 0\n",
      "bases trimmed due to adapters: 0\n",
      "\n",
      "Duplication rate (may be overestimated since this is SE data): 21.3778%\n",
      "\n",
      "JSON report: fastq_7_8_9_10_11_12/B_Qfiltered/Stepwise_08step_R2_Qfiltered.fastq.gz.json\n",
      "HTML report: fastq_7_8_9_10_11_12/B_Qfiltered/Stepwise_08step_R2_Qfiltered.fastq.gz.html\n",
      "\n",
      "fastp -i fastq_7_8_9_10_11_12/A_Untrimmed_output/Stepwise_08step_R2_untrimmed.fastq.gz -o fastq_7_8_9_10_11_12/B_Qfiltered/Stepwise_08step_R2_Qfiltered.fastq.gz -q 30 -u 15 -l 151 --cut_mean_quality 30 --html fastq_7_8_9_10_11_12/B_Qfiltered/Stepwise_08step_R2_Qfiltered.fastq.gz.html --json fastq_7_8_9_10_11_12/B_Qfiltered/Stepwise_08step_R2_Qfiltered.fastq.gz.json \n",
      "fastp v0.23.4, time used: 0 seconds\n",
      "WARNING: you specified the options for cutting by quality, but forogt to enable any of cut_front/cut_tail/cut_right. This will have no effect.\n",
      "Detecting adapter sequence for read1...\n",
      "No adapter detected for read1\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering for Stepwise_08step_R2_untrimmed.fastq.gz is complete.\n",
      "Output FASTQ : fastq_7_8_9_10_11_12/B_Qfiltered/Stepwise_08step_R2_Qfiltered.fastq.gz\n",
      "Reports      : fastq_7_8_9_10_11_12/B_Qfiltered/Stepwise_08step_R2_Qfiltered.fastq.gz.html / fastq_7_8_9_10_11_12/B_Qfiltered/Stepwise_08step_R2_Qfiltered.fastq.gz.json\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read1 before filtering:\n",
      "total reads: 1829\n",
      "total bases: 276179\n",
      "Q20 bases: 250103(90.5583%)\n",
      "Q30 bases: 228867(82.8691%)\n",
      "\n",
      "Read1 after filtering:\n",
      "total reads: 1042\n",
      "total bases: 157342\n",
      "Q20 bases: 154282(98.0552%)\n",
      "Q30 bases: 147600(93.8084%)\n",
      "\n",
      "Filtering result:\n",
      "reads passed filter: 1042\n",
      "reads failed due to low quality: 787\n",
      "reads failed due to too many N: 0\n",
      "reads failed due to too short: 0\n",
      "reads with adapter trimmed: 0\n",
      "bases trimmed due to adapters: 0\n",
      "\n",
      "Duplication rate (may be overestimated since this is SE data): 44.5599%\n",
      "\n",
      "JSON report: fastq_7_8_9_10_11_12/B_Qfiltered/Stepwise_07step_R1_Qfiltered.fastq.gz.json\n",
      "HTML report: fastq_7_8_9_10_11_12/B_Qfiltered/Stepwise_07step_R1_Qfiltered.fastq.gz.html\n",
      "\n",
      "fastp -i fastq_7_8_9_10_11_12/A_Untrimmed_output/Stepwise_07step_R1_untrimmed.fastq.gz -o fastq_7_8_9_10_11_12/B_Qfiltered/Stepwise_07step_R1_Qfiltered.fastq.gz -q 30 -u 15 -l 151 --cut_mean_quality 30 --html fastq_7_8_9_10_11_12/B_Qfiltered/Stepwise_07step_R1_Qfiltered.fastq.gz.html --json fastq_7_8_9_10_11_12/B_Qfiltered/Stepwise_07step_R1_Qfiltered.fastq.gz.json \n",
      "fastp v0.23.4, time used: 0 seconds\n",
      "WARNING: you specified the options for cutting by quality, but forogt to enable any of cut_front/cut_tail/cut_right. This will have no effect.\n",
      "Detecting adapter sequence for read1...\n",
      "No adapter detected for read1\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering for Stepwise_07step_R1_untrimmed.fastq.gz is complete.\n",
      "Output FASTQ : fastq_7_8_9_10_11_12/B_Qfiltered/Stepwise_07step_R1_Qfiltered.fastq.gz\n",
      "Reports      : fastq_7_8_9_10_11_12/B_Qfiltered/Stepwise_07step_R1_Qfiltered.fastq.gz.html / fastq_7_8_9_10_11_12/B_Qfiltered/Stepwise_07step_R1_Qfiltered.fastq.gz.json\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read1 before filtering:\n",
      "total reads: 1829\n",
      "total bases: 276179\n",
      "Q20 bases: 246099(89.1085%)\n",
      "Q30 bases: 221783(80.3041%)\n",
      "\n",
      "Read1 after filtering:\n",
      "total reads: 909\n",
      "total bases: 137259\n",
      "Q20 bases: 132728(96.6989%)\n",
      "Q30 bases: 124722(90.8662%)\n",
      "\n",
      "Filtering result:\n",
      "reads passed filter: 909\n",
      "reads failed due to low quality: 920\n",
      "reads failed due to too many N: 0\n",
      "reads failed due to too short: 0\n",
      "reads with adapter trimmed: 0\n",
      "bases trimmed due to adapters: 0\n",
      "\n",
      "Duplication rate (may be overestimated since this is SE data): 36.9054%\n",
      "\n",
      "JSON report: fastq_7_8_9_10_11_12/B_Qfiltered/Stepwise_07step_R2_Qfiltered.fastq.gz.json\n",
      "HTML report: fastq_7_8_9_10_11_12/B_Qfiltered/Stepwise_07step_R2_Qfiltered.fastq.gz.html\n",
      "\n",
      "fastp -i fastq_7_8_9_10_11_12/A_Untrimmed_output/Stepwise_07step_R2_untrimmed.fastq.gz -o fastq_7_8_9_10_11_12/B_Qfiltered/Stepwise_07step_R2_Qfiltered.fastq.gz -q 30 -u 15 -l 151 --cut_mean_quality 30 --html fastq_7_8_9_10_11_12/B_Qfiltered/Stepwise_07step_R2_Qfiltered.fastq.gz.html --json fastq_7_8_9_10_11_12/B_Qfiltered/Stepwise_07step_R2_Qfiltered.fastq.gz.json \n",
      "fastp v0.23.4, time used: 1 seconds\n",
      "WARNING: you specified the options for cutting by quality, but forogt to enable any of cut_front/cut_tail/cut_right. This will have no effect.\n",
      "Detecting adapter sequence for read1...\n",
      "No adapter detected for read1\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering for Stepwise_07step_R2_untrimmed.fastq.gz is complete.\n",
      "Output FASTQ : fastq_7_8_9_10_11_12/B_Qfiltered/Stepwise_07step_R2_Qfiltered.fastq.gz\n",
      "Reports      : fastq_7_8_9_10_11_12/B_Qfiltered/Stepwise_07step_R2_Qfiltered.fastq.gz.html / fastq_7_8_9_10_11_12/B_Qfiltered/Stepwise_07step_R2_Qfiltered.fastq.gz.json\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read1 before filtering:\n",
      "total reads: 1829\n",
      "total bases: 276179\n",
      "Q20 bases: 242175(87.6877%)\n",
      "Q30 bases: 218794(79.2218%)\n",
      "\n",
      "Read1 after filtering:\n",
      "total reads: 838\n",
      "total bases: 126538\n",
      "Q20 bases: 123192(97.3557%)\n",
      "Q30 bases: 117361(92.7476%)\n",
      "\n",
      "Filtering result:\n",
      "reads passed filter: 838\n",
      "reads failed due to low quality: 991\n",
      "reads failed due to too many N: 0\n",
      "reads failed due to too short: 0\n",
      "reads with adapter trimmed: 0\n",
      "bases trimmed due to adapters: 0\n",
      "\n",
      "Duplication rate (may be overestimated since this is SE data): 31.5473%\n",
      "\n",
      "JSON report: fastq_7_8_9_10_11_12/B_Qfiltered/Stepwise_08step_R1_Qfiltered.fastq.gz.json\n",
      "HTML report: fastq_7_8_9_10_11_12/B_Qfiltered/Stepwise_08step_R1_Qfiltered.fastq.gz.html\n",
      "\n",
      "fastp -i fastq_7_8_9_10_11_12/A_Untrimmed_output/Stepwise_08step_R1_untrimmed.fastq.gz -o fastq_7_8_9_10_11_12/B_Qfiltered/Stepwise_08step_R1_Qfiltered.fastq.gz -q 30 -u 15 -l 151 --cut_mean_quality 30 --html fastq_7_8_9_10_11_12/B_Qfiltered/Stepwise_08step_R1_Qfiltered.fastq.gz.html --json fastq_7_8_9_10_11_12/B_Qfiltered/Stepwise_08step_R1_Qfiltered.fastq.gz.json \n",
      "fastp v0.23.4, time used: 0 seconds\n",
      "WARNING: you specified the options for cutting by quality, but forogt to enable any of cut_front/cut_tail/cut_right. This will have no effect.\n",
      "Detecting adapter sequence for read1...\n",
      "No adapter detected for read1\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering for Stepwise_08step_R1_untrimmed.fastq.gz is complete.\n",
      "Output FASTQ : fastq_7_8_9_10_11_12/B_Qfiltered/Stepwise_08step_R1_Qfiltered.fastq.gz\n",
      "Reports      : fastq_7_8_9_10_11_12/B_Qfiltered/Stepwise_08step_R1_Qfiltered.fastq.gz.html / fastq_7_8_9_10_11_12/B_Qfiltered/Stepwise_08step_R1_Qfiltered.fastq.gz.json\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read1 before filtering:\n",
      "total reads: 1956\n",
      "total bases: 295356\n",
      "Q20 bases: 256879(86.9727%)\n",
      "Q30 bases: 231776(78.4734%)\n",
      "\n",
      "Read1 after filtering:\n",
      "total reads: 852\n",
      "total bases: 128652\n",
      "Q20 bases: 125281(97.3798%)\n",
      "Q30 bases: 119457(92.8528%)\n",
      "\n",
      "Filtering result:\n",
      "reads passed filter: 852\n",
      "reads failed due to low quality: 1104\n",
      "reads failed due to too many N: 0\n",
      "reads failed due to too short: 0\n",
      "reads with adapter trimmed: 0\n",
      "bases trimmed due to adapters: 0\n",
      "\n",
      "Duplication rate (may be overestimated since this is SE data): 27.2495%\n",
      "\n",
      "JSON report: fastq_7_8_9_10_11_12/B_Qfiltered/Stepwise_09step_R1_Qfiltered.fastq.gz.json\n",
      "HTML report: fastq_7_8_9_10_11_12/B_Qfiltered/Stepwise_09step_R1_Qfiltered.fastq.gz.html\n",
      "\n",
      "fastp -i fastq_7_8_9_10_11_12/A_Untrimmed_output/Stepwise_09step_R1_untrimmed.fastq.gz -o fastq_7_8_9_10_11_12/B_Qfiltered/Stepwise_09step_R1_Qfiltered.fastq.gz -q 30 -u 15 -l 151 --cut_mean_quality 30 --html fastq_7_8_9_10_11_12/B_Qfiltered/Stepwise_09step_R1_Qfiltered.fastq.gz.html --json fastq_7_8_9_10_11_12/B_Qfiltered/Stepwise_09step_R1_Qfiltered.fastq.gz.json \n",
      "fastp v0.23.4, time used: 0 seconds\n",
      "WARNING: you specified the options for cutting by quality, but forogt to enable any of cut_front/cut_tail/cut_right. This will have no effect.\n",
      "Detecting adapter sequence for read1...\n",
      "No adapter detected for read1\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering for Stepwise_09step_R1_untrimmed.fastq.gz is complete.\n",
      "Output FASTQ : fastq_7_8_9_10_11_12/B_Qfiltered/Stepwise_09step_R1_Qfiltered.fastq.gz\n",
      "Reports      : fastq_7_8_9_10_11_12/B_Qfiltered/Stepwise_09step_R1_Qfiltered.fastq.gz.html / fastq_7_8_9_10_11_12/B_Qfiltered/Stepwise_09step_R1_Qfiltered.fastq.gz.json\n",
      "\n",
      "Filtering for Stepwise_09step_R2_untrimmed.fastq.gz is complete.\n",
      "Output FASTQ : fastq_7_8_9_10_11_12/B_Qfiltered/Stepwise_09step_R2_Qfiltered.fastq.gz\n",
      "Reports      : fastq_7_8_9_10_11_12/B_Qfiltered/Stepwise_09step_R2_Qfiltered.fastq.gz.html / fastq_7_8_9_10_11_12/B_Qfiltered/Stepwise_09step_R2_Qfiltered.fastq.gz.json\n",
      "\n",
      "All filtering processes are done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read1 before filtering:\n",
      "total reads: 1956\n",
      "total bases: 295356\n",
      "Q20 bases: 254346(86.1151%)\n",
      "Q30 bases: 226989(76.8527%)\n",
      "\n",
      "Read1 after filtering:\n",
      "total reads: 692\n",
      "total bases: 104492\n",
      "Q20 bases: 100693(96.3643%)\n",
      "Q30 bases: 94792(90.717%)\n",
      "\n",
      "Filtering result:\n",
      "reads passed filter: 692\n",
      "reads failed due to low quality: 1264\n",
      "reads failed due to too many N: 0\n",
      "reads failed due to too short: 0\n",
      "reads with adapter trimmed: 0\n",
      "bases trimmed due to adapters: 0\n",
      "\n",
      "Duplication rate (may be overestimated since this is SE data): 17.0245%\n",
      "\n",
      "JSON report: fastq_7_8_9_10_11_12/B_Qfiltered/Stepwise_09step_R2_Qfiltered.fastq.gz.json\n",
      "HTML report: fastq_7_8_9_10_11_12/B_Qfiltered/Stepwise_09step_R2_Qfiltered.fastq.gz.html\n",
      "\n",
      "fastp -i fastq_7_8_9_10_11_12/A_Untrimmed_output/Stepwise_09step_R2_untrimmed.fastq.gz -o fastq_7_8_9_10_11_12/B_Qfiltered/Stepwise_09step_R2_Qfiltered.fastq.gz -q 30 -u 15 -l 151 --cut_mean_quality 30 --html fastq_7_8_9_10_11_12/B_Qfiltered/Stepwise_09step_R2_Qfiltered.fastq.gz.html --json fastq_7_8_9_10_11_12/B_Qfiltered/Stepwise_09step_R2_Qfiltered.fastq.gz.json \n",
      "fastp v0.23.4, time used: 1 seconds\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "# Quality threshold (Phred score)\n",
    "quality_threshold = 30\n",
    "\n",
    "# Set input and output folders\n",
    "input_folder = \"fastq_7_8_9_10_11_12/A_Untrimmed_output\"\n",
    "output_folder = \"fastq_7_8_9_10_11_12/B_Qfiltered\"\n",
    "\n",
    "# Create output folder if it doesn't exist\n",
    "os.makedirs(output_folder, exist_ok=True)  \n",
    "\n",
    "# Iterate over files in the input folder; process only those ending with \"_untrimmed.fastq.gz\"\n",
    "for filename in os.listdir(input_folder):\n",
    "    if filename.endswith(\"_untrimmed.fastq.gz\"):\n",
    "        # Input file path\n",
    "        input_file = os.path.join(input_folder, filename)\n",
    "        \n",
    "        # Output file name (e.g., sample_untrimmed.fastq.gz -> sample_Qfiltered.fastq.gz)\n",
    "        output_file = os.path.join(\n",
    "            output_folder, \n",
    "            filename.replace(\"_untrimmed.fastq.gz\", \"_Qfiltered.fastq.gz\")\n",
    "        )\n",
    "        \n",
    "        # Run fastp (single-end mode)\n",
    "        subprocess.call([\n",
    "            \"fastp\",\n",
    "            \"-i\", input_file,                 # Input file\n",
    "            \"-o\", output_file,                # Output file\n",
    "            \"-q\", str(quality_threshold),     # Remove bases below Q30\n",
    "            \"-u\", \"15\",                       # Discard reads if >15% of bases are low quality\n",
    "            \"-l\", \"151\",                      # Minimum read length\n",
    "            \"--cut_mean_quality\", \"30\",       # Discard reads with mean quality < 30\n",
    "            \"--html\", f\"{output_file}.html\",  # HTML report\n",
    "            \"--json\", f\"{output_file}.json\"   # JSON report\n",
    "        ])\n",
    "        \n",
    "        print(f\"Filtering for {filename} is complete.\\n\"\n",
    "              f\"Output FASTQ : {output_file}\\n\"\n",
    "              f\"Reports      : {output_file}.html / {output_file}.json\\n\")\n",
    "\n",
    "print(\"All filtering processes are done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34270d38",
   "metadata": {},
   "source": [
    "# 4. Match Paired-End Read IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0f915a10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Stepwise_09step_R1_Qfiltered.fastq.gz and Stepwise_09step_R2_Qfiltered.fastq.gz\n",
      "Total R1 IDs: 852, Total R2 IDs: 692, Matching IDs: 605\n",
      "IDs only in R1: 247, IDs only in R2: 87\n",
      "\n",
      "Processing Stepwise_10step_R1_Qfiltered.fastq.gz and Stepwise_10step_R2_Qfiltered.fastq.gz\n",
      "Total R1 IDs: 572, Total R2 IDs: 430, Matching IDs: 349\n",
      "IDs only in R1: 223, IDs only in R2: 81\n",
      "\n",
      "Processing Stepwise_08step_R1_Qfiltered.fastq.gz and Stepwise_08step_R2_Qfiltered.fastq.gz\n",
      "Total R1 IDs: 838, Total R2 IDs: 696, Matching IDs: 590\n",
      "IDs only in R1: 248, IDs only in R2: 106\n",
      "\n",
      "Processing Stepwise_07step_R1_Qfiltered.fastq.gz and Stepwise_07step_R2_Qfiltered.fastq.gz\n",
      "Total R1 IDs: 1042, Total R2 IDs: 909, Matching IDs: 814\n",
      "IDs only in R1: 228, IDs only in R2: 95\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "import glob\n",
    "import os\n",
    "\n",
    "def extract_matching_reads(r1_path, r2_path, out_r1_path, out_r2_path):\n",
    "    def get_read_id(header):\n",
    "        # Extract ID from FASTQ header\n",
    "        return header.split()[0].replace('/1', '').replace('/2', '')\n",
    "\n",
    "    r1_ids = set()\n",
    "    r2_ids = set()\n",
    "\n",
    "    with gzip.open(r1_path, 'rt') as r1_file:\n",
    "        while True:\n",
    "            header = r1_file.readline()\n",
    "            if not header:\n",
    "                break\n",
    "            r1_ids.add(get_read_id(header.strip()))\n",
    "            # Skip the other 3 lines of the read (sequence, +, quality)\n",
    "            [r1_file.readline() for _ in range(3)]  \n",
    "\n",
    "    with gzip.open(r2_path, 'rt') as r2_file:\n",
    "        while True:\n",
    "            header = r2_file.readline()\n",
    "            if not header:\n",
    "                break\n",
    "            r2_ids.add(get_read_id(header.strip()))\n",
    "            [r2_file.readline() for _ in range(3)]\n",
    "\n",
    "    matching_ids = r1_ids & r2_ids\n",
    "    r1_only = r1_ids - r2_ids\n",
    "    r2_only = r2_ids - r1_ids\n",
    "\n",
    "    print(f\"Processing {os.path.basename(r1_path)} and {os.path.basename(r2_path)}\")\n",
    "    print(f\"Total R1 IDs: {len(r1_ids)}, Total R2 IDs: {len(r2_ids)}, Matching IDs: {len(matching_ids)}\")\n",
    "    print(f\"IDs only in R1: {len(r1_only)}, IDs only in R2: {len(r2_only)}\\n\")\n",
    "\n",
    "    # Create output directories if needed\n",
    "    for out_path in [out_r1_path, out_r2_path]:\n",
    "        os.makedirs(os.path.dirname(out_path), exist_ok=True)\n",
    "\n",
    "    # Function to write only the reads with matching IDs to a new file\n",
    "    def write_matching_reads(input_path, output_path, matching_ids):\n",
    "        with gzip.open(input_path, 'rt') as infile, gzip.open(output_path, 'wt') as outfile:\n",
    "            while True:\n",
    "                lines = [infile.readline() for _ in range(4)]\n",
    "                if not lines[0]:\n",
    "                    break\n",
    "                read_id = get_read_id(lines[0].strip())\n",
    "                if read_id in matching_ids:\n",
    "                    outfile.writelines(lines)\n",
    " \n",
    "    # Write the filtered R1 and R2 files\n",
    "    write_matching_reads(r1_path, out_r1_path, matching_ids)\n",
    "    write_matching_reads(r2_path, out_r2_path, matching_ids)\n",
    "\n",
    "# ----------------------\n",
    "# Apply to all files\n",
    "# ----------------------\n",
    "\n",
    "input_folder = \"fastq_7_8_9_10_11_12/B_Qfiltered\"\n",
    "output_folder = \"fastq_7_8_9_10_11_12/C_ID_matched\"\n",
    "\n",
    "# Find all R1 files\n",
    "r1_files = glob.glob(os.path.join(input_folder, \"*_R1_Qfiltered.fastq.gz\"))\n",
    "\n",
    "# For each R1, find the matching R2 and process\n",
    "for r1_file in r1_files:\n",
    "    r2_file = r1_file.replace(\"_R1_Qfiltered.fastq.gz\", \"_R2_Qfiltered.fastq.gz\")\n",
    "    \n",
    "    if os.path.exists(r2_file):\n",
    "        # Set output paths\n",
    "        base_name = os.path.basename(r1_file).replace(\"_R1_Qfiltered.fastq.gz\", \"\")\n",
    "        out_r1 = os.path.join(output_folder, f\"{base_name}_ID_match_R1.fastq.gz\")\n",
    "        out_r2 = os.path.join(output_folder, f\"{base_name}_ID_match_R2.fastq.gz\")\n",
    "        \n",
    "        # Execute the function\n",
    "        extract_matching_reads(r1_file, r2_file, out_r1, out_r2)\n",
    "    else:\n",
    "        print(f\"Warning: {r2_file} not found. Skipping.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b724595",
   "metadata": {},
   "source": [
    "# 5. Merge W/ Flash"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925bb690",
   "metadata": {},
   "source": [
    "## 5.1. DNA Fragmentation R1(Front, Back), R2(Front, Back)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "80291728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Split complete: Stepwise_10step → fastq_7_8_9_10_11_12/D_split_reads (N=82)\n",
      "✅ Split complete: Stepwise_07step → fastq_7_8_9_10_11_12/D_split_reads (N=144)\n",
      "✅ Split complete: Stepwise_09step → fastq_7_8_9_10_11_12/D_split_reads (N=102)\n",
      "✅ Split complete: Stepwise_08step → fastq_7_8_9_10_11_12/D_split_reads (N=124)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gzip\n",
    "import glob\n",
    "\n",
    "def split_fastq_by_position(r1_path, r2_path, n, output_dir):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    sample_base = os.path.basename(r1_path).replace(\"_ID_match_R1.fastq.gz\", \"\")\n",
    "    r1_f_path = os.path.join(output_dir, f\"{sample_base}_R1_F.fastq.gz\")\n",
    "    r1_b_path = os.path.join(output_dir, f\"{sample_base}_R1_B.fastq.gz\")\n",
    "    r2_f_path = os.path.join(output_dir, f\"{sample_base}_R2_F.fastq.gz\")\n",
    "    r2_b_path = os.path.join(output_dir, f\"{sample_base}_R2_B.fastq.gz\")\n",
    "\n",
    "    with gzip.open(r1_path, 'rt') as r1_file, \\\n",
    "         gzip.open(r2_path, 'rt') as r2_file, \\\n",
    "         gzip.open(r1_f_path, 'wt') as r1_f_out, \\\n",
    "         gzip.open(r1_b_path, 'wt') as r1_b_out, \\\n",
    "         gzip.open(r2_f_path, 'wt') as r2_f_out, \\\n",
    "         gzip.open(r2_b_path, 'wt') as r2_b_out:\n",
    "\n",
    "        while True:\n",
    "            r1_lines = [r1_file.readline() for _ in range(4)]\n",
    "            r2_lines = [r2_file.readline() for _ in range(4)]\n",
    "\n",
    "            if not r1_lines[0] or not r2_lines[0]:\n",
    "                break\n",
    "\n",
    "            header1, seq1, plus1, qual1 = [line.strip() for line in r1_lines]\n",
    "            header2, seq2, plus2, qual2 = [line.strip() for line in r2_lines]\n",
    "\n",
    "            r1_f_out.write(f\"{header1}\\n{seq1[:151-n]}\\n{plus1}\\n{qual1[:151-n]}\\n\")\n",
    "            r1_b_out.write(f\"{header1}\\n{seq1[-n:]}\\n{plus1}\\n{qual1[-n:]}\\n\")\n",
    "            r2_f_out.write(f\"{header2}\\n{seq2[:151-n]}\\n{plus2}\\n{qual2[:151-n]}\\n\")\n",
    "            r2_b_out.write(f\"{header2}\\n{seq2[-n:]}\\n{plus2}\\n{qual2[-n:]}\\n\")\n",
    "\n",
    "    print(f\"✅ Split complete: {sample_base} → {output_dir} (N={n})\")\n",
    "\n",
    "# -----------------------------------\n",
    "# Apply splitting to all files\n",
    "# -----------------------------------\n",
    "\n",
    "input_folder = \"fastq_7_8_9_10_11_12/C_id_matched\"\n",
    "output_folder = \"fastq_7_8_9_10_11_12/D_split_reads\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Define the N-value (length of the back part) for each sample prefix\n",
    "sample_n_mapping = {\n",
    "    \"07step\": 144,\n",
    "    \"08step\": 124,\n",
    "    \"09step\": 102,\n",
    "    \"10step\": 82,\n",
    "    \"11step\": 60,\n",
    "    \"12step\": 40, \n",
    "}\n",
    "\n",
    "# Find all R1 files\n",
    "r1_files = glob.glob(os.path.join(input_folder, \"*_ID_match_R1.fastq.gz\"))\n",
    "\n",
    "for r1_file in r1_files:\n",
    "    r2_file = r1_file.replace(\"_R1.fastq.gz\", \"_R2.fastq.gz\")\n",
    "\n",
    "    if not os.path.exists(r2_file):\n",
    "        print(f\"⚠️ Matching R2 file not found: {r2_file}\")\n",
    "        continue\n",
    "\n",
    "    # Find the corresponding N value based on the filename prefix\n",
    "    matched_n = None\n",
    "    for prefix, n_value in sample_n_mapping.items():\n",
    "        if prefix in os.path.basename(r1_file):\n",
    "            matched_n = n_value\n",
    "            break\n",
    "\n",
    "    if matched_n is None:\n",
    "        print(f\"⚠️ Could not find N value: {r1_file} → Skipping\")\n",
    "        continue\n",
    "\n",
    "    # Execute the split function\n",
    "    split_fastq_by_position(r1_file, r2_file, matched_n, output_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f8f8da",
   "metadata": {},
   "source": [
    "# 5.2. R2 DNA reverse complementary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "bb8d70a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Reverse complemented: Stepwise_07step_R2_F_revcomp.fastq.gz\n",
      "✅ Reverse complemented: Stepwise_08step_R2_B_revcomp.fastq.gz\n",
      "✅ Reverse complemented: Stepwise_10step_R2_B_revcomp.fastq.gz\n",
      "✅ Reverse complemented: Stepwise_09step_R2_B_revcomp.fastq.gz\n",
      "✅ Reverse complemented: Stepwise_08step_R2_F_revcomp.fastq.gz\n",
      "✅ Reverse complemented: Stepwise_09step_R2_F_revcomp.fastq.gz\n",
      "✅ Reverse complemented: Stepwise_10step_R2_F_revcomp.fastq.gz\n",
      "✅ Reverse complemented: Stepwise_07step_R2_B_revcomp.fastq.gz\n"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "import glob\n",
    "import os\n",
    "from Bio import SeqIO\n",
    "\n",
    "def reverse_complement_fastq(input_fastq_path, output_fastq_path):\n",
    "    #Reads a FASTQ file, creates the reverse complement of each record, and writes it to a new file.\n",
    "    with gzip.open(input_fastq_path, \"rt\") as infile, gzip.open(output_fastq_path, \"wt\") as outfile:\n",
    "        for record in SeqIO.parse(infile, \"fastq\"):\n",
    "            record.seq = record.seq.reverse_complement()\n",
    "            record.letter_annotations[\"phred_quality\"] = record.letter_annotations[\"phred_quality\"][::-1]\n",
    "            SeqIO.write(record, outfile, \"fastq\")\n",
    "    print(f\"✅ Reverse complemented: {os.path.basename(output_fastq_path)}\")\n",
    "\n",
    "# --------------------------------------\n",
    "# Apply reverse complement to all files\n",
    "# --------------------------------------\n",
    "\n",
    "input_folder = \"fastq_7_8_9_10_11_12/D_split_reads\"\n",
    "os.makedirs(input_folder, exist_ok=True)\n",
    "\n",
    "# Find files ending with _R2_B.fastq.gz or _R2_F.fastq.gz\n",
    "input_files = glob.glob(os.path.join(input_folder, \"*_R2_[BF].fastq.gz\"))\n",
    "\n",
    "for input_path in input_files:\n",
    "    base = os.path.basename(input_path)\n",
    "    # Remove the .fastq.gz extension to create a new filename\n",
    "    name_without_ext = base.replace(\".fastq.gz\", \"\") \n",
    "    output_path = os.path.join(input_folder, f\"{name_without_ext}_revcomp.fastq.gz\")\n",
    "    \n",
    "    reverse_complement_fastq(input_path, output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8cf6b4",
   "metadata": {},
   "source": [
    "## 5.3 [R1_back]-[R2_back] merge (FLASH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d5cee727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔎 Found 4 R1_B files.\n",
      "🔵 Running FLASH for sample: Stepwise_07step (N=144)\n",
      "[FLASH] Starting FLASH v1.2.11\n",
      "[FLASH] Fast Length Adjustment of SHort reads\n",
      "[FLASH]  \n",
      "[FLASH] Input files:\n",
      "[FLASH]     fastq_7_8_9_10_11_12/D_split_reads/Stepwise_07step_R1_B.fastq.gz\n",
      "[FLASH]     fastq_7_8_9_10_11_12/D_split_reads/Stepwise_07step_R2_B.fastq.gz\n",
      "[FLASH]  \n",
      "[FLASH] Output files:\n",
      "[FLASH]     fastq_7_8_9_10_11_12/E_merged_output/Stepwise_07step_FLASH.extendedFrags.fastq\n",
      "[FLASH]     fastq_7_8_9_10_11_12/E_merged_output/Stepwise_07step_FLASH.notCombined_1.fastq\n",
      "[FLASH]     fastq_7_8_9_10_11_12/E_merged_output/Stepwise_07step_FLASH.notCombined_2.fastq\n",
      "[FLASH]     fastq_7_8_9_10_11_12/E_merged_output/Stepwise_07step_FLASH.hist\n",
      "[FLASH]     fastq_7_8_9_10_11_12/E_merged_output/Stepwise_07step_FLASH.histogram\n",
      "[FLASH]  \n",
      "[FLASH] Parameters:\n",
      "[FLASH]     Min overlap:           144\n",
      "[FLASH]     Max overlap:           144\n",
      "[FLASH]     Max mismatch density:  0.250000\n",
      "[FLASH]     Allow \"outie\" pairs:   false\n",
      "[FLASH]     Cap mismatch quals:    false\n",
      "[FLASH]     Combiner threads:      4\n",
      "[FLASH]     Input format:          FASTQ, phred_offset=33\n",
      "[FLASH]     Output format:         FASTQ, phred_offset=33\n",
      "[FLASH]  \n",
      "[FLASH] Starting reader and writer threads\n",
      "[FLASH] Starting 4 combiner threads\n",
      "[FLASH] Processed 814 read pairs\n",
      "[FLASH]  \n",
      "[FLASH] Read combination statistics:\n",
      "[FLASH]     Total pairs:      814\n",
      "[FLASH]     Combined pairs:   437\n",
      "[FLASH]     Uncombined pairs: 377\n",
      "[FLASH]     Percent combined: 53.69%\n",
      "[FLASH]  \n",
      "[FLASH] Writing histogram files.\n",
      "[FLASH]  \n",
      "[FLASH] FLASH v1.2.11 complete!\n",
      "[FLASH] 0.027 seconds elapsed\n",
      "✅ FLASH merging complete → fastq_7_8_9_10_11_12/E_merged_output/Stepwise_07step_FLASH.fastq\n",
      "🔵 Running FLASH for sample: Stepwise_10step (N=82)\n",
      "[FLASH] Starting FLASH v1.2.11\n",
      "[FLASH] Fast Length Adjustment of SHort reads\n",
      "[FLASH]  \n",
      "[FLASH] Input files:\n",
      "[FLASH]     fastq_7_8_9_10_11_12/D_split_reads/Stepwise_10step_R1_B.fastq.gz\n",
      "[FLASH]     fastq_7_8_9_10_11_12/D_split_reads/Stepwise_10step_R2_B.fastq.gz\n",
      "[FLASH]  \n",
      "[FLASH] Output files:\n",
      "[FLASH]     fastq_7_8_9_10_11_12/E_merged_output/Stepwise_10step_FLASH.extendedFrags.fastq\n",
      "[FLASH]     fastq_7_8_9_10_11_12/E_merged_output/Stepwise_10step_FLASH.notCombined_1.fastq\n",
      "[FLASH]     fastq_7_8_9_10_11_12/E_merged_output/Stepwise_10step_FLASH.notCombined_2.fastq\n",
      "[FLASH]     fastq_7_8_9_10_11_12/E_merged_output/Stepwise_10step_FLASH.hist\n",
      "[FLASH]     fastq_7_8_9_10_11_12/E_merged_output/Stepwise_10step_FLASH.histogram\n",
      "[FLASH]  \n",
      "[FLASH] Parameters:\n",
      "[FLASH]     Min overlap:           82\n",
      "[FLASH]     Max overlap:           82\n",
      "[FLASH]     Max mismatch density:  0.250000\n",
      "[FLASH]     Allow \"outie\" pairs:   false\n",
      "[FLASH]     Cap mismatch quals:    false\n",
      "[FLASH]     Combiner threads:      4\n",
      "[FLASH]     Input format:          FASTQ, phred_offset=33\n",
      "[FLASH]     Output format:         FASTQ, phred_offset=33\n",
      "[FLASH]  \n",
      "[FLASH] Starting reader and writer threads\n",
      "[FLASH] Starting 4 combiner threads\n",
      "[FLASH] Processed 349 read pairs\n",
      "[FLASH]  \n",
      "[FLASH] Read combination statistics:\n",
      "[FLASH]     Total pairs:      349\n",
      "[FLASH]     Combined pairs:   44\n",
      "[FLASH]     Uncombined pairs: 305\n",
      "[FLASH]     Percent combined: 12.61%\n",
      "[FLASH]  \n",
      "[FLASH] Writing histogram files.\n",
      "[FLASH]  \n",
      "[FLASH] FLASH v1.2.11 complete!\n",
      "[FLASH] 0.020 seconds elapsed\n",
      "✅ FLASH merging complete → fastq_7_8_9_10_11_12/E_merged_output/Stepwise_10step_FLASH.fastq\n",
      "🔵 Running FLASH for sample: Stepwise_09step (N=102)\n",
      "[FLASH] Starting FLASH v1.2.11\n",
      "[FLASH] Fast Length Adjustment of SHort reads\n",
      "[FLASH]  \n",
      "[FLASH] Input files:\n",
      "[FLASH]     fastq_7_8_9_10_11_12/D_split_reads/Stepwise_09step_R1_B.fastq.gz\n",
      "[FLASH]     fastq_7_8_9_10_11_12/D_split_reads/Stepwise_09step_R2_B.fastq.gz\n",
      "[FLASH]  \n",
      "[FLASH] Output files:\n",
      "[FLASH]     fastq_7_8_9_10_11_12/E_merged_output/Stepwise_09step_FLASH.extendedFrags.fastq\n",
      "[FLASH]     fastq_7_8_9_10_11_12/E_merged_output/Stepwise_09step_FLASH.notCombined_1.fastq\n",
      "[FLASH]     fastq_7_8_9_10_11_12/E_merged_output/Stepwise_09step_FLASH.notCombined_2.fastq\n",
      "[FLASH]     fastq_7_8_9_10_11_12/E_merged_output/Stepwise_09step_FLASH.hist\n",
      "[FLASH]     fastq_7_8_9_10_11_12/E_merged_output/Stepwise_09step_FLASH.histogram\n",
      "[FLASH]  \n",
      "[FLASH] Parameters:\n",
      "[FLASH]     Min overlap:           102\n",
      "[FLASH]     Max overlap:           102\n",
      "[FLASH]     Max mismatch density:  0.250000\n",
      "[FLASH]     Allow \"outie\" pairs:   false\n",
      "[FLASH]     Cap mismatch quals:    false\n",
      "[FLASH]     Combiner threads:      4\n",
      "[FLASH]     Input format:          FASTQ, phred_offset=33\n",
      "[FLASH]     Output format:         FASTQ, phred_offset=33\n",
      "[FLASH]  \n",
      "[FLASH] Starting reader and writer threads\n",
      "[FLASH] Starting 4 combiner threads\n",
      "[FLASH] Processed 605 read pairs\n",
      "[FLASH]  \n",
      "[FLASH] Read combination statistics:\n",
      "[FLASH]     Total pairs:      605\n",
      "[FLASH]     Combined pairs:   161\n",
      "[FLASH]     Uncombined pairs: 444\n",
      "[FLASH]     Percent combined: 26.61%\n",
      "[FLASH]  \n",
      "[FLASH] Writing histogram files.\n",
      "[FLASH]  \n",
      "[FLASH] FLASH v1.2.11 complete!\n",
      "[FLASH] 0.028 seconds elapsed\n",
      "✅ FLASH merging complete → fastq_7_8_9_10_11_12/E_merged_output/Stepwise_09step_FLASH.fastq\n",
      "🔵 Running FLASH for sample: Stepwise_08step (N=124)\n",
      "[FLASH] Starting FLASH v1.2.11\n",
      "[FLASH] Fast Length Adjustment of SHort reads\n",
      "[FLASH]  \n",
      "[FLASH] Input files:\n",
      "[FLASH]     fastq_7_8_9_10_11_12/D_split_reads/Stepwise_08step_R1_B.fastq.gz\n",
      "[FLASH]     fastq_7_8_9_10_11_12/D_split_reads/Stepwise_08step_R2_B.fastq.gz\n",
      "[FLASH]  \n",
      "[FLASH] Output files:\n",
      "[FLASH]     fastq_7_8_9_10_11_12/E_merged_output/Stepwise_08step_FLASH.extendedFrags.fastq\n",
      "[FLASH]     fastq_7_8_9_10_11_12/E_merged_output/Stepwise_08step_FLASH.notCombined_1.fastq\n",
      "[FLASH]     fastq_7_8_9_10_11_12/E_merged_output/Stepwise_08step_FLASH.notCombined_2.fastq\n",
      "[FLASH]     fastq_7_8_9_10_11_12/E_merged_output/Stepwise_08step_FLASH.hist\n",
      "[FLASH]     fastq_7_8_9_10_11_12/E_merged_output/Stepwise_08step_FLASH.histogram\n",
      "[FLASH]  \n",
      "[FLASH] Parameters:\n",
      "[FLASH]     Min overlap:           124\n",
      "[FLASH]     Max overlap:           124\n",
      "[FLASH]     Max mismatch density:  0.250000\n",
      "[FLASH]     Allow \"outie\" pairs:   false\n",
      "[FLASH]     Cap mismatch quals:    false\n",
      "[FLASH]     Combiner threads:      4\n",
      "[FLASH]     Input format:          FASTQ, phred_offset=33\n",
      "[FLASH]     Output format:         FASTQ, phred_offset=33\n",
      "[FLASH]  \n",
      "[FLASH] Starting reader and writer threads\n",
      "[FLASH] Starting 4 combiner threads\n",
      "[FLASH] Processed 590 read pairs\n",
      "[FLASH]  \n",
      "[FLASH] Read combination statistics:\n",
      "[FLASH]     Total pairs:      590\n",
      "[FLASH]     Combined pairs:   127\n",
      "[FLASH]     Uncombined pairs: 463\n",
      "[FLASH]     Percent combined: 21.53%\n",
      "[FLASH]  \n",
      "[FLASH] Writing histogram files.\n",
      "[FLASH]  \n",
      "[FLASH] FLASH v1.2.11 complete!\n",
      "[FLASH] 0.030 seconds elapsed\n",
      "✅ FLASH merging complete → fastq_7_8_9_10_11_12/E_merged_output/Stepwise_08step_FLASH.fastq\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import subprocess\n",
    "\n",
    "# === Folder setup ===\n",
    "input_folder = \"fastq_7_8_9_10_11_12/D_split_reads\"\n",
    "output_folder = \"fastq_7_8_9_10_11_12/E_merged_output\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# === N values per prefix ===\n",
    "sample_n_mapping = {\n",
    "    \"07step\": 144,\n",
    "    \"08step\": 124,\n",
    "    \"09step\": 102,\n",
    "    \"10step\": 82,\n",
    "    \"11step\": 60,\n",
    "    \"12step\": 40, \n",
    "}\n",
    "\n",
    "# === Find R1_B files ===\n",
    "r1_files = glob.glob(os.path.join(input_folder, \"*_R1_B.fastq.gz\"))\n",
    "print(f\"🔎 Found {len(r1_files)} R1_B files.\")\n",
    "\n",
    "# === Process each R1_B file ===\n",
    "for r1_path in r1_files:\n",
    "    sample_base = os.path.basename(r1_path).replace(\"_R1_B.fastq.gz\", \"\")\n",
    "    r2_path = os.path.join(input_folder, f\"{sample_base}_R2_B.fastq.gz\")\n",
    "\n",
    "    if not os.path.exists(r2_path):\n",
    "        print(f\"⚠️ Matching R2_B file not found for {sample_base} → Skipping.\")\n",
    "        continue\n",
    "\n",
    "    # Find the corresponding N value from the filename\n",
    "    matched_n = None\n",
    "    for prefix, n_value in sample_n_mapping.items():\n",
    "        if prefix in sample_base:\n",
    "            matched_n = n_value\n",
    "            break\n",
    "\n",
    "    if matched_n is None:\n",
    "        print(f\"⚠️ No N value matched for {sample_base} → Skipping.\")\n",
    "        continue\n",
    "\n",
    "    output_name = f\"{sample_base}_FLASH\"\n",
    "\n",
    "    print(f\"🔵 Running FLASH for sample: {sample_base} (N={matched_n})\")\n",
    "\n",
    "    try:\n",
    "        # Execute the FLASH command\n",
    "        subprocess.check_call([\n",
    "            \"flash\",\n",
    "            \"-m\", str(matched_n),   # minimum overlap\n",
    "            \"-M\", str(matched_n),   # maximum overlap\n",
    "            \"-o\", output_name,      # output file prefix\n",
    "            \"-d\", output_folder,    # output directory\n",
    "            r1_path,\n",
    "            r2_path\n",
    "        ])\n",
    "        print(f\"✅ FLASH merging complete → {os.path.join(output_folder, output_name)}.fastq\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"❌ FLASH merging failed for {sample_base}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "020a528e",
   "metadata": {},
   "source": [
    "## 5.4 Assemble \n",
    "## R1_Front - [R1_Back]-[R2_Back]_merged (FLASH) - R2_Front_ReverseComplement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "32be38d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Found 4 merged samples to assemble.\n",
      "🔄 Assembling for sample: Stepwise_09step_assemble.fastq.gz\n",
      "✅ Assembled FASTQ saved: fastq_7_8_9_10_11_12/1_assemble/Stepwise_09step_assemble.fastq.gz\n",
      "🔄 Assembling for sample: Stepwise_10step_assemble.fastq.gz\n",
      "✅ Assembled FASTQ saved: fastq_7_8_9_10_11_12/1_assemble/Stepwise_10step_assemble.fastq.gz\n",
      "🔄 Assembling for sample: Stepwise_08step_assemble.fastq.gz\n",
      "✅ Assembled FASTQ saved: fastq_7_8_9_10_11_12/1_assemble/Stepwise_08step_assemble.fastq.gz\n",
      "🔄 Assembling for sample: Stepwise_07step_assemble.fastq.gz\n",
      "✅ Assembled FASTQ saved: fastq_7_8_9_10_11_12/1_assemble/Stepwise_07step_assemble.fastq.gz\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gzip\n",
    "import glob\n",
    "from Bio import SeqIO\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "\n",
    "def load_fastq_to_dict(file_path):\n",
    "    \"\"\"Loads a FASTQ file into a dictionary: key=read_id, value=(sequence, quality).\"\"\"\n",
    "    data = {}\n",
    "    open_func = gzip.open if file_path.endswith(\".gz\") else open\n",
    "\n",
    "    with open_func(file_path, \"rt\") as handle:\n",
    "        for record in SeqIO.parse(handle, \"fastq\"):\n",
    "            seq = str(record.seq)\n",
    "            qual = record.letter_annotations[\"phred_quality\"]\n",
    "            data[record.id] = (seq, qual)\n",
    "    return data\n",
    "\n",
    "def assemble_fastq(r1_path, merged_path, r2_path, output_path):\n",
    "    \"\"\"Assembles the final sequence from R1_F, Merged, and R2_F_revcomp fragments.\"\"\"\n",
    "    print(f\"🔄 Assembling for sample: {os.path.basename(output_path)}\")\n",
    "    r1_dict = load_fastq_to_dict(r1_path)\n",
    "    r2_dict = load_fastq_to_dict(r2_path)\n",
    "\n",
    "    with open(merged_path, \"r\") as merged_file, gzip.open(output_path, \"wt\") as output_file:\n",
    "        for record in SeqIO.parse(merged_file, \"fastq\"):\n",
    "            read_id = record.id\n",
    "            merged_seq = str(record.seq)\n",
    "            merged_qual = record.letter_annotations[\"phred_quality\"]\n",
    "\n",
    "            # A read must have corresponding R1 and R2 fragments to be assembled.\n",
    "            if read_id not in r1_dict or read_id not in r2_dict:\n",
    "                continue  \n",
    "\n",
    "            r1_seq, r1_qual = r1_dict[read_id]\n",
    "            r2_seq, r2_qual = r2_dict[read_id]\n",
    "\n",
    "            # Concatenate in order: R1_F → Merged_Fragment → R2_F_revcomp\n",
    "            full_seq = r1_seq + merged_seq + r2_seq\n",
    "            full_qual = r1_qual + merged_qual + r2_qual\n",
    "\n",
    "            new_record = SeqRecord(\n",
    "                Seq(full_seq),\n",
    "                id=read_id,\n",
    "                description=\"\",\n",
    "                letter_annotations={\"phred_quality\": full_qual}\n",
    "            )\n",
    "\n",
    "            SeqIO.write(new_record, output_file, \"fastq\")\n",
    "\n",
    "    print(f\"✅ Assembled FASTQ saved: {output_path}\")\n",
    "\n",
    "# ===== Batch processing =====\n",
    "\n",
    "# Path setup\n",
    "input_merged_folder = \"fastq_7_8_9_10_11_12/E_merged_output\"\n",
    "input_split_folder = \"fastq_7_8_9_10_11_12/D_split_reads\"\n",
    "output_folder = \"fastq_7_8_9_10_11_12/1_assemble\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Get a list of all merged files from FLASH\n",
    "merged_files = glob.glob(os.path.join(input_merged_folder, \"*_FLASH.extendedFrags.fastq\"))\n",
    "\n",
    "print(f\"🔍 Found {len(merged_files)} merged samples to assemble.\")\n",
    "\n",
    "for merged_file in merged_files:\n",
    "    sample_base = os.path.basename(merged_file).replace(\"_FLASH.extendedFrags.fastq\", \"\")\n",
    "\n",
    "    r1_path = os.path.join(input_split_folder, f\"{sample_base}_R1_F.fastq.gz\")\n",
    "    r2_path = os.path.join(input_split_folder, f\"{sample_base}_R2_F_revcomp.fastq.gz\")\n",
    "    output_path = os.path.join(output_folder, f\"{sample_base}_assemble.fastq.gz\")\n",
    "\n",
    "    if os.path.exists(r1_path) and os.path.exists(r2_path):\n",
    "        assemble_fastq(r1_path, merged_file, r2_path, output_path)\n",
    "    else:\n",
    "        print(f\"⚠️ Missing split files for {sample_base}, skipping.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66072f7f",
   "metadata": {},
   "source": [
    "# 6. fastq -> fasta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1e8f6bc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted: Stepwise_07step_assemble.fastq.gz → Stepwise_07step_assemble.fasta\n",
      "Converted: Stepwise_09step_assemble.fastq.gz → Stepwise_09step_assemble.fasta\n",
      "Converted: Stepwise_10step_assemble.fastq.gz → Stepwise_10step_assemble.fasta\n",
      "Converted: Stepwise_08step_assemble.fastq.gz → Stepwise_08step_assemble.fasta\n",
      "All conversions are done.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gzip\n",
    "from Bio import SeqIO\n",
    "\n",
    "# Input and output folder paths\n",
    "input_folder = \"fastq_7_8_9_10_11_12/1_assemble\"\n",
    "output_folder = \"fastq_7_8_9_10_11_12/2_fastq_to_fasta\"\n",
    "# Create the output folder if it doesn't exist.\n",
    "os.makedirs(output_folder, exist_ok=True) \n",
    "\n",
    "for filename in os.listdir(input_folder):\n",
    "    # Process only files with .fastq or .fastq.gz extensions\n",
    "    if filename.endswith(\".fastq\") or filename.endswith(\".fastq.gz\"):\n",
    "        input_file = os.path.join(input_folder, filename)\n",
    "        \n",
    "        # Set output filename (.fasta extension)\n",
    "        output_file = os.path.join(\n",
    "            output_folder,\n",
    "            filename.replace(\".fastq.gz\", \".fasta\").replace(\".fastq\", \".fasta\")\n",
    "        )\n",
    "\n",
    "        # Choose open mode based on gzip\n",
    "        open_func = gzip.open if filename.endswith(\".gz\") else open\n",
    "\n",
    "        # Read FASTQ and convert to FASTA\n",
    "        with open_func(input_file, \"rt\") as fastq_file:  # open in text mode\n",
    "            records = list(SeqIO.parse(fastq_file, \"fastq\"))\n",
    "\n",
    "        # Save as FASTA\n",
    "        with open(output_file, \"w\") as fasta_file:\n",
    "            SeqIO.write(records, fasta_file, \"fasta\")\n",
    "\n",
    "        print(f\"Converted: {filename} → {os.path.basename(output_file)}\")\n",
    "\n",
    "print(\"All conversions are done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d693e91a",
   "metadata": {},
   "source": [
    "# 7. Binary data reference seqeunce data generate\n",
    "\n",
    "Binary data reference seqeunce was already generated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679101a1",
   "metadata": {},
   "source": [
    "# 8. Reference sequence - Sample Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d4c469c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 Aligning: Stepwise_10step_assemble.fasta → 10step_reference.fasta (step=10)\n",
      "🔧 Indexing reference...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[bwa_index] Pack FASTA... 0.00 sec\n",
      "[bwa_index] Construct BWT for the packed sequence...\n",
      "[bwa_index] 0.01 seconds elapse.\n",
      "[bwa_index] Update BWT... 0.00 sec\n",
      "[bwa_index] Pack forward-only FASTA... 0.00 sec\n",
      "[bwa_index] Construct SA from BWT and Occ... 0.01 sec\n",
      "[main] Version: 0.7.17-r1188\n",
      "[main] CMD: bwa index step_reference/10step_reference.fasta\n",
      "[main] Real time: 0.102 sec; CPU: 0.029 sec\n",
      "[M::bwa_idx_load_from_disk] read 0 ALT contigs\n",
      "[M::process] read 44 sequences (9680 bp)...\n",
      "[M::mem_process_seqs] Processed 44 reads in 0.109 CPU sec, 0.037 real sec\n",
      "[main] Version: 0.7.17-r1188\n",
      "[main] CMD: bwa mem -M -t 4 step_reference/10step_reference.fasta fastq_7_8_9_10_11_12/2_fastq_to_fasta/Stepwise_10step_assemble.fasta\n",
      "[main] Real time: 0.075 sec; CPU: 0.114 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Done: fastq_7_8_9_10_11_12/3_align_sam/Stepwise_10step_assemble.sam\n",
      "🔄 Aligning: Stepwise_09step_assemble.fasta → 09step_reference.fasta (step=09)\n",
      "🔧 Indexing reference...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[bwa_index] Pack FASTA... 0.00 sec\n",
      "[bwa_index] Construct BWT for the packed sequence...\n",
      "[bwa_index] 0.01 seconds elapse.\n",
      "[bwa_index] Update BWT... 0.00 sec\n",
      "[bwa_index] Pack forward-only FASTA... 0.00 sec\n",
      "[bwa_index] Construct SA from BWT and Occ... 0.00 sec\n",
      "[main] Version: 0.7.17-r1188\n",
      "[main] CMD: bwa index step_reference/09step_reference.fasta\n",
      "[main] Real time: 0.070 sec; CPU: 0.015 sec\n",
      "[M::bwa_idx_load_from_disk] read 0 ALT contigs\n",
      "[M::process] read 161 sequences (32200 bp)...\n",
      "[M::mem_process_seqs] Processed 161 reads in 0.238 CPU sec, 0.081 real sec\n",
      "[main] Version: 0.7.17-r1188\n",
      "[main] CMD: bwa mem -M -t 4 step_reference/09step_reference.fasta fastq_7_8_9_10_11_12/2_fastq_to_fasta/Stepwise_09step_assemble.fasta\n",
      "[main] Real time: 0.113 sec; CPU: 0.243 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Done: fastq_7_8_9_10_11_12/3_align_sam/Stepwise_09step_assemble.sam\n",
      "🔄 Aligning: Stepwise_07step_assemble.fasta → 07step_reference.fasta (step=07)\n",
      "🔧 Indexing reference...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[bwa_index] Pack FASTA... 0.00 sec\n",
      "[bwa_index] Construct BWT for the packed sequence...\n",
      "[bwa_index] 0.00 seconds elapse.\n",
      "[bwa_index] Update BWT... 0.00 sec\n",
      "[bwa_index] Pack forward-only FASTA... 0.00 sec\n",
      "[bwa_index] Construct SA from BWT and Occ... 0.00 sec\n",
      "[main] Version: 0.7.17-r1188\n",
      "[main] CMD: bwa index step_reference/07step_reference.fasta\n",
      "[main] Real time: 0.040 sec; CPU: 0.006 sec\n",
      "[M::bwa_idx_load_from_disk] read 0 ALT contigs\n",
      "[M::process] read 437 sequences (69046 bp)...\n",
      "[M::mem_process_seqs] Processed 437 reads in 0.103 CPU sec, 0.034 real sec\n",
      "[main] Version: 0.7.17-r1188\n",
      "[main] CMD: bwa mem -M -t 4 step_reference/07step_reference.fasta fastq_7_8_9_10_11_12/2_fastq_to_fasta/Stepwise_07step_assemble.fasta\n",
      "[main] Real time: 0.070 sec; CPU: 0.107 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Done: fastq_7_8_9_10_11_12/3_align_sam/Stepwise_07step_assemble.sam\n",
      "🔄 Aligning: Stepwise_08step_assemble.fasta → 08step_reference.fasta (step=08)\n",
      "🔧 Indexing reference...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[bwa_index] Pack FASTA... 0.00 sec\n",
      "[bwa_index] Construct BWT for the packed sequence...\n",
      "[bwa_index] 0.00 seconds elapse.\n",
      "[bwa_index] Update BWT... 0.00 sec\n",
      "[bwa_index] Pack forward-only FASTA... 0.00 sec\n",
      "[bwa_index] Construct SA from BWT and Occ... 0.00 sec\n",
      "[main] Version: 0.7.17-r1188\n",
      "[main] CMD: bwa index step_reference/08step_reference.fasta\n",
      "[main] Real time: 0.056 sec; CPU: 0.009 sec\n",
      "[M::bwa_idx_load_from_disk] read 0 ALT contigs\n",
      "[M::process] read 127 sequences (22606 bp)...\n",
      "[M::mem_process_seqs] Processed 127 reads in 0.035 CPU sec, 0.012 real sec\n",
      "[main] Version: 0.7.17-r1188\n",
      "[main] CMD: bwa mem -M -t 4 step_reference/08step_reference.fasta fastq_7_8_9_10_11_12/2_fastq_to_fasta/Stepwise_08step_assemble.fasta\n",
      "[main] Real time: 0.047 sec; CPU: 0.038 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Done: fastq_7_8_9_10_11_12/3_align_sam/Stepwise_08step_assemble.sam\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "set -euo pipefail\n",
    "shopt -s nullglob\n",
    "\n",
    "# ========== Configuration ==========\n",
    "ref_dir=\"step_reference\"                       # Reference FASTA directory\n",
    "query_dir=\"fastq_7_8_9_10_11_12/2_fastq_to_fasta\"  # Input FASTA directory\n",
    "output_dir=\"fastq_7_8_9_10_11_12/3_align_sam\"      # Output SAM directory\n",
    "threads=4\n",
    "\n",
    "# Optional: filter steps (e.g., \"07\"–\"12\")\n",
    "# Leave empty to process all steps automatically.\n",
    "step_min=\"07\"   # e.g., \"07\"\n",
    "step_max=\"12\"   # e.g., \"12\"\n",
    "# ====================================\n",
    "\n",
    "mkdir -p \"$output_dir\"\n",
    "\n",
    "# Avoid duplicate indexing during the run\n",
    "declare -A indexed\n",
    "# Avoid duplicate processing: prefer \"*assemble.fasta\"\n",
    "declare -A seen\n",
    "\n",
    "# 1) Collect \"*assemble.fasta\" first\n",
    "for f in \"$query_dir\"/*step*assemble.fasta; do\n",
    "  seen[\"$f\"]=1\n",
    "done\n",
    "\n",
    "# 2) Collect other *step*.fasta only if not already included\n",
    "for f in \"$query_dir\"/*step*.fasta; do\n",
    "  [[ -n \"${seen[$f]:-}\" ]] && continue\n",
    "  seen[\"$f\"]=1\n",
    "done\n",
    "\n",
    "# Alignment loop\n",
    "for query_file in \"${!seen[@]}\"; do\n",
    "  filename=\"$(basename \"$query_file\")\"\n",
    "\n",
    "  # Extract step digit(s): matches both _07step_ and _7step\n",
    "  if [[ \"$filename\" =~ _([0-9]+)step(_|$) ]]; then\n",
    "    step_raw=\"${BASH_REMATCH[1]}\"\n",
    "  else\n",
    "    echo \"⚠️  Step number not found in filename: $filename\"\n",
    "    continue\n",
    "  fi\n",
    "\n",
    "  # Zero-padding to 2 digits (e.g., 7 → 07)\n",
    "  step_pad=$(printf \"%02d\" $((10#$step_raw)))\n",
    "\n",
    "  # Optional step range filtering\n",
    "  if [[ -n \"$step_min\" && -n \"$step_max\" ]]; then\n",
    "    s_val=$((10#$step_pad))\n",
    "    s_min=$((10#$step_min))\n",
    "    s_max=$((10#$step_max))\n",
    "    if (( s_val < s_min || s_val > s_max )); then\n",
    "      echo \"⏭️  Skip (step not in ${step_min}–${step_max}): $filename\"\n",
    "      continue\n",
    "    fi\n",
    "  fi\n",
    "\n",
    "  reference_file=\"${ref_dir}/${step_pad}step_reference.fasta\"\n",
    "  if [[ ! -f \"$reference_file\" ]]; then\n",
    "    echo \"⚠️  Missing reference: $reference_file\"\n",
    "    continue\n",
    "  fi\n",
    "\n",
    "  out_file=\"${output_dir}/${filename%.fasta}.sam\"\n",
    "  echo \"🔄 Aligning: $filename → $(basename \"$reference_file\") (step=$step_pad)\"\n",
    "\n",
    "  # Index only once per reference in this run, and reuse existing index files\n",
    "  if [[ -z \"${indexed[$reference_file]:-}\" ]]; then\n",
    "    if [[ -f \"${reference_file}.bwt\" ]]; then\n",
    "      echo \"⏭️  Index exists, skipping indexing.\"\n",
    "    else\n",
    "      echo \"🔧 Indexing reference...\"\n",
    "      bwa index \"$reference_file\"\n",
    "    fi\n",
    "    indexed[$reference_file]=1\n",
    "  fi\n",
    "\n",
    "  bwa mem -M -t \"$threads\" \"$reference_file\" \"$query_file\" > \"$out_file\"\n",
    "  echo \"✅ Done: $out_file\"\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41fdcc51",
   "metadata": {},
   "source": [
    "## 8.1 sam to bam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d4a6079c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversion from fastq_7_8_9_10_11_12/3_align_sam/Stepwise_07step_assemble.sam to fastq_7_8_9_10_11_12/4_align_bam/Stepwise_07step_assemble.bam is complete.\n",
      "Conversion from fastq_7_8_9_10_11_12/3_align_sam/Stepwise_08step_assemble.sam to fastq_7_8_9_10_11_12/4_align_bam/Stepwise_08step_assemble.bam is complete.\n",
      "Conversion from fastq_7_8_9_10_11_12/3_align_sam/Stepwise_09step_assemble.sam to fastq_7_8_9_10_11_12/4_align_bam/Stepwise_09step_assemble.bam is complete.\n",
      "Conversion from fastq_7_8_9_10_11_12/3_align_sam/Stepwise_10step_assemble.sam to fastq_7_8_9_10_11_12/4_align_bam/Stepwise_10step_assemble.bam is complete.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "# Set the path to the directory containing SAM files\n",
    "sam_dir=\"fastq_7_8_9_10_11_12/3_align_sam\"\n",
    "# Set the output directory for BAM files\n",
    "bam_dir=\"fastq_7_8_9_10_11_12/4_align_bam\"\n",
    "\n",
    "\n",
    "# Make sure the output directory exists or create it if necessary\n",
    "mkdir -p \"$bam_dir\"\n",
    "\n",
    "# Convert SAM files to BAM\n",
    "for sam_file in \"$sam_dir\"/*.sam; do\n",
    "    bam_file=\"$bam_dir/$(basename \"$sam_file\" .sam).bam\"\n",
    "    samtools view -bS \"$sam_file\" -o \"$bam_file\"\n",
    "    echo \"Conversion from $sam_file to $bam_file is complete.\"\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1ff9fb",
   "metadata": {},
   "source": [
    "## 8.2  Convert BAM to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e10dffcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fastq_7_8_9_10_11_12/5_align_csv/Stepwise_10step_assemble.csv',\n",
       " 'fastq_7_8_9_10_11_12/5_align_csv/Stepwise_08step_assemble.csv',\n",
       " 'fastq_7_8_9_10_11_12/5_align_csv/Stepwise_07step_assemble.csv',\n",
       " 'fastq_7_8_9_10_11_12/5_align_csv/Stepwise_09step_assemble.csv']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pysam\n",
    "import pandas as pd\n",
    "\n",
    "# Input folder (path containing BAM files)\n",
    "input_folder = \"fastq_7_8_9_10_11_12/4_align_bam\"\n",
    "# Output folder (path to save CSV files; change if needed)\n",
    "output_folder = \"fastq_7_8_9_10_11_12/5_align_csv\"\n",
    "\n",
    "# Create output folder if it does not exist\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# BAM -> CSV conversion function (including optional SAM tags)\n",
    "def bam_to_csv(bam_file, output_folder):\n",
    "    output_csv = os.path.join(output_folder, os.path.basename(bam_file).replace(\".bam\", \".csv\"))\n",
    "    \n",
    "    # Read BAM file\n",
    "    with pysam.AlignmentFile(bam_file, \"rb\") as bam:\n",
    "        records = []\n",
    "        all_tags = set()  # set to collect optional tag names\n",
    "        \n",
    "        for read in bam:\n",
    "            # Core fields\n",
    "            record = {\n",
    "                \"QNAME\": read.query_name,\n",
    "                \"FLAG\": read.flag,\n",
    "                \"RNAME\": bam.get_reference_name(read.reference_id) if read.reference_id >= 0 else \"*\",\n",
    "                \"POS\": read.reference_start + 1,\n",
    "                \"MAPQ\": read.mapping_quality,\n",
    "                \"CIGAR\": read.cigarstring if read.cigarstring else \"*\",\n",
    "                \"RNEXT\": bam.get_reference_name(read.next_reference_id) if read.next_reference_id >= 0 else \"*\",\n",
    "                \"PNEXT\": read.next_reference_start + 1 if read.next_reference_start >= 0 else 0,\n",
    "                \"TLEN\": read.template_length,\n",
    "                \"SEQ\": read.query_sequence if read.query_sequence else \"*\",\n",
    "                \"QUAL\": read.qual if read.qual else \"*\",\n",
    "            }\n",
    "            \n",
    "            # Optional SAM tags (aux fields)\n",
    "            for tag, value in read.tags:\n",
    "                record[tag] = value\n",
    "                all_tags.add(tag)\n",
    "\n",
    "            records.append(record)\n",
    "    \n",
    "    # Build DataFrame\n",
    "    df = pd.DataFrame(records)\n",
    "\n",
    "    # Fill missing optional fields with \"*\"\n",
    "    df = df.fillna(\"*\")\n",
    "\n",
    "    # Save CSV\n",
    "    df.to_csv(output_csv, index=False)\n",
    "    return output_csv\n",
    "\n",
    "# Find all BAM files in the folder\n",
    "bam_files = [os.path.join(input_folder, f) for f in os.listdir(input_folder) if f.endswith(\".bam\")]\n",
    "\n",
    "# Convert all BAM files to CSV\n",
    "csv_files = []\n",
    "for bam_file in bam_files:\n",
    "    csv_file = bam_to_csv(bam_file, output_folder)\n",
    "    csv_files.append(csv_file)\n",
    "\n",
    "# Print list of converted CSV files\n",
    "csv_files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893d55ae",
   "metadata": {},
   "source": [
    "## 8.3 Filter Alignments by MAPQ Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2d7c8b61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Stepwise_07step_assemble.csv → Stepwise_07step_assemble.csv | kept=425, removed=12 | threshold=10, keep_nan=True\n",
      "✅ Stepwise_08step_assemble.csv → Stepwise_08step_assemble.csv | kept=120, removed=7 | threshold=10, keep_nan=True\n",
      "✅ Stepwise_09step_assemble.csv → Stepwise_09step_assemble.csv | kept=136, removed=25 | threshold=10, keep_nan=True\n",
      "✅ Stepwise_10step_assemble.csv → Stepwise_10step_assemble.csv | kept=27, removed=17 | threshold=10, keep_nan=True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# ===== Settings =====\n",
    "input_dir = Path(\"fastq_7_8_9_10_11_12/5_align_csv\")  # Input folder containing CSV files\n",
    "output_dir = input_dir / \"MAPQ_removed\"            # Output folder for filtered CSV files\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "MAPQ_THRESHOLD = 10     # Keep rows where MAPQ > this value\n",
    "KEEP_NAN = True         # Keep rows with NaN MAPQ values (e.g., unaligned reads)\n",
    "# ====================\n",
    "\n",
    "def process_one_csv(in_path: Path, out_dir: Path, mapq_threshold: int, keep_nan: bool = True):\n",
    "    out_path = out_dir / in_path.name\n",
    "\n",
    "    # Remove existing output file to avoid duplicates\n",
    "    if out_path.exists():\n",
    "        out_path.unlink()\n",
    "\n",
    "    # Read input CSV\n",
    "    try:\n",
    "        df = pd.read_csv(in_path)\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️  Read fail: {in_path.name} -> {e}\")\n",
    "        return\n",
    "\n",
    "    # Skip if MAPQ column does not exist\n",
    "    if \"MAPQ\" not in df.columns:\n",
    "        print(f\"⚠️  Skip (no MAPQ column): {in_path.name}\")\n",
    "        return\n",
    "\n",
    "    # Convert MAPQ column to numeric (invalid entries become NaN)\n",
    "    m = pd.to_numeric(df[\"MAPQ\"], errors=\"coerce\")\n",
    "\n",
    "    # Filtering mask: keep MAPQ > threshold, optionally keep NaN\n",
    "    keep_mask = (m > mapq_threshold) | (m.isna() if keep_nan else False)\n",
    "\n",
    "    kept = int(keep_mask.sum())\n",
    "    removed = int((~keep_mask).sum())\n",
    "\n",
    "    # Save filtered CSV\n",
    "    df.loc[keep_mask].to_csv(out_path, index=False)\n",
    "    print(\n",
    "        f\"✅ {in_path.name} → {out_path.name} | kept={kept}, removed={removed} \"\n",
    "        f\"| threshold={mapq_threshold}, keep_nan={keep_nan}\"\n",
    "    )\n",
    "\n",
    "def main():\n",
    "    csv_files = sorted(input_dir.glob(\"*.csv\"))\n",
    "    if not csv_files:\n",
    "        print(f\"⚠️  No CSV files in {input_dir}\")\n",
    "        return\n",
    "\n",
    "    for p in csv_files:\n",
    "        process_one_csv(p, output_dir, MAPQ_THRESHOLD, KEEP_NAN)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4a0c21",
   "metadata": {},
   "source": [
    "# Histogram Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24245d72",
   "metadata": {},
   "source": [
    "## A. Generate Histogram Data from Aligned Reads(MAPQ filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5c4724b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved cleaned RNAME histogram: fastq_7_8_9_10_11_12/6_align_histogram/histogram_Stepwise_09step_.csv\n",
      "✅ Saved cleaned RNAME histogram: fastq_7_8_9_10_11_12/6_align_histogram/histogram_Stepwise_07step_.csv\n",
      "✅ Saved cleaned RNAME histogram: fastq_7_8_9_10_11_12/6_align_histogram/histogram_Stepwise_08step_.csv\n",
      "✅ Saved cleaned RNAME histogram: fastq_7_8_9_10_11_12/6_align_histogram/histogram_Stepwise_10step_.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Folder setup\n",
    "input_folder = \"fastq_7_8_9_10_11_12/5_align_csv/MAPQ_removed\"\n",
    "histogram_folder = \"fastq_7_8_9_10_11_12/6_align_histogram\"\n",
    "os.makedirs(histogram_folder, exist_ok=True)\n",
    "\n",
    "# Process all CSV files in the input folder\n",
    "files = [f for f in os.listdir(input_folder) if f.endswith('.csv')]\n",
    "\n",
    "for file_name in files:\n",
    "    file_path = os.path.join(input_folder, file_name)\n",
    "\n",
    "    # Clean filename (remove specific substrings)\n",
    "    clean_name = file_name\n",
    "    clean_name = clean_name.replace(\"assemble\", \"\")\n",
    "    clean_name = clean_name.replace(\"ID_match_FLASH.extendedFrags\", \"\")\n",
    "    # remove duplicate/trailing underscores\n",
    "    clean_name = clean_name.replace(\"__\", \"_\").strip(\"_\")  \n",
    "    output_csv = os.path.join(histogram_folder, f\"histogram_{clean_name}\")\n",
    "\n",
    "    try:\n",
    "        df = pd.read_csv(file_path, dtype=str)\n",
    "        if 'RNAME' not in df.columns:\n",
    "            print(f\"⚠️ Skipping file: {file_name} (no 'RNAME' column found)\")\n",
    "            continue\n",
    "\n",
    "        # Aggregate and normalize RNAME counts\n",
    "        rname_counts = df['RNAME'].value_counts().reset_index()\n",
    "        rname_counts.columns = ['RNAME', 'Count']\n",
    "        rname_counts.insert(0, 'File_Name', clean_name)\n",
    "        rname_counts['Count'] = rname_counts['Count'].astype(int)\n",
    "        total_count = rname_counts['Count'].sum()\n",
    "        rname_counts['Normalized_Count'] = rname_counts['Count'] / total_count\n",
    "\n",
    "        rname_counts.to_csv(output_csv, index=False)\n",
    "        print(f\"✅ Saved cleaned RNAME histogram: {output_csv}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error processing file '{file_name}': {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a3bf229",
   "metadata": {},
   "source": [
    "## B. Create Top 5 Histogram Plots for Each Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3b663461",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved plot: fastq_7_8_9_10_11_12/6_align_histogram/graph_top5/histogram_Stepwise_07step_.png, fastq_7_8_9_10_11_12/6_align_histogram/graph_top5/histogram_Stepwise_07step_.svg\n",
      "✅ Saved plot: fastq_7_8_9_10_11_12/6_align_histogram/graph_top5/histogram_Stepwise_10step_.png, fastq_7_8_9_10_11_12/6_align_histogram/graph_top5/histogram_Stepwise_10step_.svg\n",
      "✅ Saved plot: fastq_7_8_9_10_11_12/6_align_histogram/graph_top5/histogram_Stepwise_09step_.png, fastq_7_8_9_10_11_12/6_align_histogram/graph_top5/histogram_Stepwise_09step_.svg\n",
      "✅ Saved plot: fastq_7_8_9_10_11_12/6_align_histogram/graph_top5/histogram_Stepwise_08step_.png, fastq_7_8_9_10_11_12/6_align_histogram/graph_top5/histogram_Stepwise_08step_.svg\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 📁 Folder setup\n",
    "histogram_folder = \"fastq_7_8_9_10_11_12/6_align_histogram\"\n",
    "summary_folder = \"fastq_7_8_9_10_11_12/6_align_histogram/graph_top5\"\n",
    "os.makedirs(summary_folder, exist_ok=True)\n",
    "\n",
    "# 🔴 Highlight mapping (based on filename suffix)\n",
    "highlight_mapping = {\n",
    "    \"_01step\": \"seq_0001_1\",\n",
    "    \"_02step\": \"seq_0002_10\",\n",
    "    \"_03step\": \"seq_0005_101\",\n",
    "    \"_04step\": \"seq_0010_1010\",\n",
    "    \"_05step\": \"seq_0021_10101\",\n",
    "    \"_06step\": \"seq_0042_101010\",\n",
    "    \"_07step\": \"seq_0085_1010101\",\n",
    "    \"_08step\": \"seq_0170_10101010\",\n",
    "    \"_09step\": \"seq_0341_101010101\",\n",
    "    \"_10step\": \"seq_0682_1010101010\",\n",
    "    \"_11step\": \"seq_1365_10101010101\",\n",
    "    \"_12step\": \"seq_2730_101010101010\",\n",
    "}\n",
    "\n",
    "# 📄 List CSV files\n",
    "csv_files = [f for f in os.listdir(histogram_folder) if f.startswith(\"histogram_\") and f.endswith(\".csv\")]\n",
    "\n",
    "# 🔁 Process each file\n",
    "for file_name in csv_files:\n",
    "    file_path = os.path.join(histogram_folder, file_name)\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        if 'RNAME' not in df.columns or 'Normalized_Count' not in df.columns:\n",
    "            print(f\"⚠️ Skipping file: {file_name} (missing column)\")\n",
    "            continue\n",
    "\n",
    "        # Extract Top 5 RNAMEs\n",
    "        top_df = df.sort_values(by=\"Count\", ascending=False).head(5).reset_index(drop=True)\n",
    "        sample_name = file_name.replace(\"histogram_\", \"\").replace(\".csv\", \"\")\n",
    "\n",
    "        # 🔍 Find highlight RNAME using the suffix\n",
    "        highlight_rname = None\n",
    "        for suffix, rname in highlight_mapping.items():\n",
    "            if suffix in file_name:\n",
    "                highlight_rname = rname\n",
    "                break\n",
    "\n",
    "        # 📊 Create plot\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        bars = plt.bar(top_df[\"RNAME\"], top_df[\"Normalized_Count\"], color='blue')\n",
    "\n",
    "        # 🔴 Color the matched RNAME in red\n",
    "        for bar, rname in zip(bars, top_df[\"RNAME\"]):\n",
    "            if rname == highlight_rname:\n",
    "                bar.set_color('red')\n",
    "\n",
    "        plt.title(f\"Top 5 RNAME Histogram - {sample_name}\")\n",
    "        plt.xlabel(\"RNAME\")\n",
    "        plt.ylabel(\"Normalized Count\")\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.ylim(0, 1)\n",
    "        plt.tight_layout()\n",
    "\n",
    "        # 💾 Save\n",
    "        output_png = os.path.join(summary_folder, file_name.replace(\".csv\", \".png\"))\n",
    "        output_svg = os.path.join(summary_folder, file_name.replace(\".csv\", \".svg\"))\n",
    "        plt.savefig(output_png)\n",
    "        plt.savefig(output_svg)\n",
    "        plt.close()\n",
    "\n",
    "        print(f\"✅ Saved plot: {output_png}, {output_svg}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error processing {file_name}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78786654",
   "metadata": {},
   "source": [
    "## C. Summarize Highlighted Read Counts into a CSV File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "4c241be4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📌 Highlight summary saved to: fastq_7_8_9_10_11_12/7_align_summary/highlight_result.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# === Highlight mapping (suffix -> RNAME) ===\n",
    "highlight_mapping = {\n",
    "    \"_01step\": \"seq_0001_1\",\n",
    "    \"_02step\": \"seq_0002_10\",\n",
    "    \"_03step\": \"seq_0005_101\",\n",
    "    \"_04step\": \"seq_0010_1010\",\n",
    "    \"_05step\": \"seq_0021_10101\",\n",
    "    \"_06step\": \"seq_0042_101010\",\n",
    "    \"_07step\": \"seq_0085_1010101\",\n",
    "    \"_08step\": \"seq_0170_10101010\",\n",
    "    \"_09step\": \"seq_0341_101010101\",\n",
    "    \"_10step\": \"seq_0682_1010101010\",\n",
    "    \"_11step\": \"seq_1365_10101010101\",\n",
    "    \"_12step\": \"seq_2730_101010101010\",\n",
    "}\n",
    "\n",
    "# === Folder setup ===\n",
    "histogram_folder = \"fastq_7_8_9_10_11_12/6_align_histogram\"\n",
    "summary_folder = \"fastq_7_8_9_10_11_12/7_align_summary\"\n",
    "os.makedirs(summary_folder, exist_ok=True)\n",
    "highlight_result_csv = os.path.join(summary_folder, \"highlight_result.csv\")\n",
    "\n",
    "# === Function to extract step number ===\n",
    "def extract_step_number(filename):\n",
    "    match = re.search(r\"_(\\d+)step\", filename)\n",
    "    return int(match.group(1)) if match else float(\"inf\")\n",
    "\n",
    "# === Collect highlight summary info ===\n",
    "highlight_data = []\n",
    "csv_files = [f for f in os.listdir(histogram_folder) if f.startswith(\"histogram_\") and f.endswith(\".csv\")]\n",
    "\n",
    "for file in csv_files:\n",
    "    file_path = os.path.join(histogram_folder, file)\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        file_name = file.replace(\"histogram_\", \"\")\n",
    "\n",
    "        # Get highlight_rname by suffix\n",
    "        highlight_rname = \"\"\n",
    "        for suffix, rname in highlight_mapping.items():\n",
    "            if suffix in file_name:\n",
    "                highlight_rname = rname\n",
    "                break\n",
    "\n",
    "        df['Count'] = df['Count'].astype(int)\n",
    "        total_count = df['Count'].sum()\n",
    "\n",
    "        highlight_count = df[df['RNAME'] == highlight_rname]['Count'].sum() if highlight_rname else 0\n",
    "        highlight_percentage = (highlight_count / total_count) * 100 if total_count > 0 else 0\n",
    "\n",
    "        sorted_counts = df['Count'].sort_values(ascending=False).values\n",
    "        second_max_count = sorted_counts[1] if len(sorted_counts) >= 2 else (sorted_counts[0] if len(sorted_counts) == 1 else 0)\n",
    "        highlight_vs_second_ratio = (highlight_count / second_max_count) if second_max_count > 0 else 0\n",
    "\n",
    "        highlight_data.append([\n",
    "            file_name,\n",
    "            highlight_count,\n",
    "            total_count,\n",
    "            round(highlight_percentage, 2),\n",
    "            highlight_rname,\n",
    "            round(highlight_vs_second_ratio, 3),\n",
    "            extract_step_number(file_name)\n",
    "        ])\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error processing file '{file}': {e}\")\n",
    "\n",
    "# === Create DataFrame, sort by step, and save ===\n",
    "highlight_df = pd.DataFrame(highlight_data, columns=[\n",
    "    'File',\n",
    "    'Highlight_Count',\n",
    "    'Total_Count',\n",
    "    'Highlight_Percentage',\n",
    "    'Highlight_RNAMEs',\n",
    "    'Highlight_vs_SecondTop_Ratio',\n",
    "    'Step_Number'\n",
    "])\n",
    "\n",
    "highlight_df = highlight_df.sort_values(by='Step_Number').drop(columns='Step_Number')\n",
    "highlight_df.to_csv(highlight_result_csv, index=False)\n",
    "\n",
    "print(f\"📌 Highlight summary saved to: {highlight_result_csv}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fcc5d68",
   "metadata": {},
   "source": [
    "## D. Plot Stacked Bar Graph top5_gray_rest_white_box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "75ae5f74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved:\n",
      " - PNG: fastq_7_8_9_10_11_12/7_align_summary/stacked_bar_top5_gray_rest_white_box.png\n",
      " - SVG: fastq_7_8_9_10_11_12/7_align_summary/stacked_bar_top5_gray_rest_white_box.svg\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# Folder setup\n",
    "histogram_folder = \"fastq_7_8_9_10_11_12/6_align_histogram\"\n",
    "summary_folder = \"fastq_7_8_9_10_11_12/7_align_summary\"\n",
    "os.makedirs(summary_folder, exist_ok=True)\n",
    "\n",
    "# Highlight mapping (based on filename suffix)\n",
    "highlight_mapping = {\n",
    "    \"_01step\": \"seq_0001_1\",\n",
    "    \"_02step\": \"seq_0002_10\",\n",
    "    \"_03step\": \"seq_0005_101\",\n",
    "    \"_04step\": \"seq_0010_1010\",\n",
    "    \"_05step\": \"seq_0021_10101\",\n",
    "    \"_06step\": \"seq_0042_101010\",\n",
    "    \"_07step\": \"seq_0085_1010101\",\n",
    "    \"_08step\": \"seq_0170_10101010\",\n",
    "    \"_09step\": \"seq_0341_101010101\",\n",
    "    \"_10step\": \"seq_0682_1010101010\",\n",
    "    \"_11step\": \"seq_1365_10101010101\",\n",
    "    \"_12step\": \"seq_2730_101010101010\",\n",
    "}\n",
    "\n",
    "# Gray → white gradient color function\n",
    "def blend_color(base_rgb, t):\n",
    "    white = np.array([255, 255, 255])\n",
    "    base = np.array(base_rgb)\n",
    "    blended = (1 - t) * base + t * white\n",
    "    return tuple(blended / 255)\n",
    "\n",
    "base_rgb = (137, 137, 138)\n",
    "\n",
    "# Extract step number for ascending sort\n",
    "def extract_step_number(name):\n",
    "    match = re.search(r'_(\\d+)step', name)\n",
    "    return int(match.group(1)) if match else float('inf')\n",
    "\n",
    "# Load per-sample data\n",
    "sample_rname_dfs = {}\n",
    "for file_name in os.listdir(histogram_folder):\n",
    "    if file_name.startswith(\"histogram_\") and file_name.endswith(\".csv\"):\n",
    "        sample_name = file_name.replace(\"histogram_\", \"\").replace(\".csv\", \"\")\n",
    "        df = pd.read_csv(os.path.join(histogram_folder, file_name))\n",
    "        if 'RNAME' not in df.columns or 'Count' not in df.columns:\n",
    "            continue\n",
    "        df['Sample'] = sample_name\n",
    "        df['Count'] = df['Count'].astype(int)\n",
    "        df['Normalized_Count'] = df['Count'] / df['Count'].sum()\n",
    "        df = df.sort_values(by='Count', ascending=False).reset_index(drop=True)\n",
    "        sample_rname_dfs[sample_name] = df\n",
    "\n",
    "# Sort sample_name by step number\n",
    "sorted_samples = sorted(sample_rname_dfs.items(), key=lambda x: extract_step_number(x[0]))\n",
    "\n",
    "# Visualization\n",
    "fig, ax = plt.subplots(figsize=(24, 12))\n",
    "\n",
    "for sample_idx, (sample_name, df) in enumerate(sorted_samples):\n",
    "    # Find highlight RNAME\n",
    "    highlight_rname = None\n",
    "    for suffix, rname in highlight_mapping.items():\n",
    "        if suffix in sample_name:  # check inclusion, not strictly end-of-string\n",
    "            highlight_rname = rname\n",
    "            break\n",
    "\n",
    "    bottom = 0\n",
    "    top_n = 5\n",
    "    rest_sum = 0\n",
    "\n",
    "    for rank, row in df.iterrows():\n",
    "        rname = row['RNAME']\n",
    "        height = row['Normalized_Count']\n",
    "\n",
    "        if rname == highlight_rname:\n",
    "            ax.bar(sample_name, height, bottom=bottom, color='red', edgecolor='black', linewidth=0.2)\n",
    "            bottom += height\n",
    "        elif rank < top_n:\n",
    "            t = rank / (top_n - 1) if top_n > 1 else 0\n",
    "            color = blend_color(base_rgb, t)\n",
    "            ax.bar(sample_name, height, bottom=bottom, color=color, edgecolor='black', linewidth=0.2)\n",
    "            bottom += height\n",
    "        else:\n",
    "            rest_sum += height\n",
    "\n",
    "    if rest_sum > 0:\n",
    "        ax.bar(sample_name, rest_sum, bottom=bottom, color='white', edgecolor='black', linewidth=0.2)\n",
    "\n",
    "# Reference line & styling\n",
    "ax.axhline(y=0.5, color='gray', linestyle='--', linewidth=1, label='y = 0.5')\n",
    "ax.set_ylabel(\"Normalized Count\", fontsize=20)\n",
    "ax.set_xlabel(\"Sample\", fontsize=20)\n",
    "ax.set_title(\"Stacked Bar Chart (Red = Highlight, Gray→White = Top 5, Rest = One White Box)\", fontsize=16)\n",
    "ax.tick_params(axis='x', labelsize=20)\n",
    "ax.tick_params(axis='y', labelsize=20)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save\n",
    "png_path = os.path.join(summary_folder, \"stacked_bar_top5_gray_rest_white_box.png\")\n",
    "svg_path = os.path.join(summary_folder, \"stacked_bar_top5_gray_rest_white_box.svg\")\n",
    "plt.savefig(png_path)\n",
    "plt.savefig(svg_path)\n",
    "plt.close()\n",
    "\n",
    "print(f\"✅ Saved:\\n - PNG: {png_path}\\n - SVG: {svg_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d973acc8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
