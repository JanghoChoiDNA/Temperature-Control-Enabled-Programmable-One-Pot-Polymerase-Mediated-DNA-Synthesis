{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39189dfb",
   "metadata": {},
   "source": [
    "# **Install modules**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e906fe9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: biopython in /usr/local/lib/python3.12/dist-packages (1.84)\n",
      "Requirement already satisfied: numpy in /usr/lib/python3/dist-packages (from biopython) (1.26.4)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "fastp is already the newest version (0.23.4+dfsg-1).\n",
      "The following packages were automatically installed and are no longer required:\n",
      "  pigz python3-xopen\n",
      "Use 'sudo apt autoremove' to remove them.\n",
      "0 upgraded, 0 newly installed, 0 to remove and 265 not upgraded.\n",
      "Hit:1 https://packages.microsoft.com/repos/code stable InRelease               \n",
      "Hit:2 http://ports.ubuntu.com/ubuntu-ports noble InRelease                     \n",
      "Hit:3 http://ports.ubuntu.com/ubuntu-ports noble-updates InRelease             \n",
      "Hit:4 http://ports.ubuntu.com/ubuntu-ports noble-backports InRelease\n",
      "Hit:5 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu noble InRelease\n",
      "Hit:6 http://ports.ubuntu.com/ubuntu-ports noble-security InRelease\n",
      "Reading package lists... Done\n",
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "flash is already the newest version (1.2.11-2).\n",
      "The following packages were automatically installed and are no longer required:\n",
      "  pigz python3-xopen\n",
      "Use 'sudo apt autoremove' to remove them.\n",
      "0 upgraded, 0 newly installed, 0 to remove and 265 not upgraded.\n",
      "Requirement already satisfied: cutadapt in /usr/local/lib/python3.12/dist-packages (5.0)\n",
      "Requirement already satisfied: dnaio>=1.2.3 in /usr/local/lib/python3.12/dist-packages (from cutadapt) (1.2.3)\n",
      "Requirement already satisfied: xopen>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from cutadapt) (2.0.2)\n",
      "Requirement already satisfied: isal>=1.6.1 in /usr/local/lib/python3.12/dist-packages (from xopen>=1.6.0->cutadapt) (1.7.1)\n",
      "Requirement already satisfied: zlib-ng>=0.4.1 in /usr/local/lib/python3.12/dist-packages (from xopen>=1.6.0->cutadapt) (0.5.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "bwa is already the newest version (0.7.17-7).\n",
      "The following packages were automatically installed and are no longer required:\n",
      "  pigz python3-xopen\n",
      "Use 'sudo apt autoremove' to remove them.\n",
      "0 upgraded, 0 newly installed, 0 to remove and 265 not upgraded.\n",
      "Requirement already satisfied: pysam in /usr/local/lib/python3.12/dist-packages (0.22.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "samtools is already the newest version (1.19.2-1build2).\n",
      "The following packages were automatically installed and are no longer required:\n",
      "  pigz python3-xopen\n",
      "Use 'sudo apt autoremove' to remove them.\n",
      "0 upgraded, 0 newly installed, 0 to remove and 265 not upgraded.\n"
     ]
    }
   ],
   "source": [
    "# Install modules\n",
    "!sudo pip3 install biopython --break-system-packages\n",
    "!sudo apt-get install fastp \n",
    "!sudo apt-get update \n",
    "!sudo apt-get install flash\n",
    "!sudo pip3 install cutadapt --break-system-packages\n",
    "!sudo apt-get install bwa \n",
    "!sudo pip3 install pysam --break-system-packages\n",
    "!sudo apt-get install samtools "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd54a0a6",
   "metadata": {},
   "source": [
    "# Trimming and Discard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8ac5eda6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Untrimmed sequences saved: fastq_7_8_9_10_11_12/A_Untrimmed_output/250910_batch20_09step_R1_untrimmed.fastq.gz, fastq_7_8_9_10_11_12/A_Untrimmed_output/250910_batch20_09step_R2_untrimmed.fastq.gz\n",
      "Untrimmed sequences saved: fastq_7_8_9_10_11_12/A_Untrimmed_output/250910_batch20_10step_R1_untrimmed.fastq.gz, fastq_7_8_9_10_11_12/A_Untrimmed_output/250910_batch20_10step_R2_untrimmed.fastq.gz\n",
      "Untrimmed sequences saved: fastq_7_8_9_10_11_12/A_Untrimmed_output/250910_batch20_07step_R1_untrimmed.fastq.gz, fastq_7_8_9_10_11_12/A_Untrimmed_output/250910_batch20_07step_R2_untrimmed.fastq.gz\n",
      "Untrimmed sequences saved: fastq_7_8_9_10_11_12/A_Untrimmed_output/250905_batch19_08step_R1_untrimmed.fastq.gz, fastq_7_8_9_10_11_12/A_Untrimmed_output/250905_batch19_08step_R2_untrimmed.fastq.gz\n",
      "Untrimmed sequences saved: fastq_7_8_9_10_11_12/A_Untrimmed_output/250910_batch20_08step_R1_untrimmed.fastq.gz, fastq_7_8_9_10_11_12/A_Untrimmed_output/250910_batch20_08step_R2_untrimmed.fastq.gz\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# Specify the folder containing your input files\n",
    "# Specify the folder where you want to save the untrimmed sequences (adapter-free sequences)\n",
    "\n",
    "input_folder = \"fastq_7_8_9_10_11_12\"\n",
    "untrimmed_output_folder = \"fastq_7_8_9_10_11_12/A_Untrimmed_output\"\n",
    "\n",
    "# Define the adapter sequences for R1 and R2\n",
    "adapter_sequence_r1 = \"AGATCGGAAGAGCACACGTCTGAACTCCAGTCAC\"\n",
    "adapter_sequence_r2 = \"AGATCGGAAGAGCGTCGTGTAGGGAAAGAGTGT\"\n",
    "\n",
    "# Use glob to get a list of all input file pairs (R1 and R2) in the folder\n",
    "input_file_pairs = []\n",
    "for input_r1 in glob.glob(os.path.join(input_folder, \"*_R1.fastq.gz\")):\n",
    "    # Assuming R2 files have the same naming format as R1 files\n",
    "    input_r2 = input_r1.replace(\"_R1.fastq.gz\", \"_R2.fastq.gz\")\n",
    "    if os.path.exists(input_r2):  # Ensure R2 file exists\n",
    "        input_file_pairs.append({\"r1\": input_r1, \"r2\": input_r2})\n",
    "\n",
    "# Create the output folder if it doesn't exist\n",
    "os.makedirs(untrimmed_output_folder, exist_ok=True)\n",
    "\n",
    "for input_files in input_file_pairs:\n",
    "    input_r1 = input_files[\"r1\"]\n",
    "    input_r2 = input_files[\"r2\"]\n",
    "\n",
    "    # Define output file paths for untrimmed (clean, adapter-free) sequences\n",
    "    untrimmed_r1 = os.path.join(untrimmed_output_folder, os.path.basename(input_r1).replace(\".fastq.gz\", \"_untrimmed.fastq.gz\"))\n",
    "    untrimmed_r2 = os.path.join(untrimmed_output_folder, os.path.basename(input_r2).replace(\".fastq.gz\", \"_untrimmed.fastq.gz\"))\n",
    "\n",
    "    # Use cutadapt to keep only untrimmed sequences (completely adapter-free)\n",
    "    result = subprocess.run([\n",
    "        \"cutadapt\",\n",
    "        \"-a\", adapter_sequence_r1,  # Adapter for R1\n",
    "        \"-A\", adapter_sequence_r2,  # Adapter for R2\n",
    "        \"-O\", \"15\",  # Minimum overlap for adapter trimming\n",
    "        \"--discard-trimmed\",  # Discard sequences where trimming occurred\n",
    "        \"-o\", untrimmed_r1,  # Save only untrimmed R1 reads\n",
    "        \"-p\", untrimmed_r2,  # Save only untrimmed R2 reads\n",
    "        input_r1, input_r2\n",
    "    ], capture_output=True, text=True)\n",
    "\n",
    "    # Log result\n",
    "    if result.returncode == 0:\n",
    "        print(f\"Untrimmed sequences saved: {untrimmed_r1}, {untrimmed_r2}\")\n",
    "    else:\n",
    "        print(f\"Error processing {input_r1} and {input_r2}:\\n{result.stderr}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7feb2152",
   "metadata": {},
   "source": [
    "# Quality check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8377e270",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import gzip\n",
    "# from Bio import SeqIO\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # ğŸ“ ì…ë ¥ í´ë”ì™€ ì¶œë ¥ í´ë” ì„¤ì •\n",
    "# input_folder = \"fastq_step/1_3_5_7_9_11/A_Untrimmed_output\"\n",
    "# output_csv_folder = \"fastq_step/1_3_5_7_9_11/A_Untrimmed_output/quality_stats_csv\"\n",
    "# output_plot_folder = \"fastq_step/1_3_5_7_9_11/A_Untrimmed_output/quality_plots\"\n",
    "\n",
    "# os.makedirs(output_csv_folder, exist_ok=True)\n",
    "# os.makedirs(output_plot_folder, exist_ok=True)\n",
    "\n",
    "# # ğŸ” í’ˆì§ˆ í†µê³„ ì¶”ì¶œ í•¨ìˆ˜\n",
    "# def compute_quality_stats(file_path):\n",
    "#     position_qualities = {}\n",
    "#     open_func = gzip.open if file_path.endswith(\".gz\") else open\n",
    "\n",
    "#     with open_func(file_path, \"rt\") as handle:\n",
    "#         for record in SeqIO.parse(handle, \"fastq\"):\n",
    "#             for i, q in enumerate(record.letter_annotations[\"phred_quality\"]):\n",
    "#                 position_qualities.setdefault(i, []).append(q)\n",
    "\n",
    "#     stats = []\n",
    "#     for pos in sorted(position_qualities):\n",
    "#         scores = np.array(position_qualities[pos])\n",
    "#         stats.append({\n",
    "#             \"position\": pos + 1,\n",
    "#             \"mean\": np.mean(scores),\n",
    "#             \"q1\": np.percentile(scores, 25),\n",
    "#             \"median\": np.median(scores),\n",
    "#             \"q3\": np.percentile(scores, 75),\n",
    "#             \"min\": np.min(scores),\n",
    "#             \"max\": np.max(scores)\n",
    "#         })\n",
    "#     return pd.DataFrame(stats)\n",
    "\n",
    "# # ğŸ“Š ë°°ê²½ ìƒ‰ìƒ í•¨ìˆ˜ (fastp ìŠ¤íƒ€ì¼)\n",
    "# def add_quality_background(ax):\n",
    "#     ax.axhspan(30, 40, facecolor='lightgreen', alpha=0.5)\n",
    "#     ax.axhspan(25, 30, facecolor='khaki', alpha=0.5)\n",
    "#     ax.axhspan(20, 25, facecolor='moccasin', alpha=0.5)\n",
    "#     ax.axhspan(0, 20, facecolor='lightcoral', alpha=0.5)\n",
    "\n",
    "# # ğŸ“‚ í´ë” ë‚´ ëª¨ë“  FASTQ(.gz í¬í•¨) ì²˜ë¦¬\n",
    "# for filename in os.listdir(input_folder):\n",
    "#     if filename.endswith(\".fastq\") or filename.endswith(\".fastq.gz\"):\n",
    "#         input_path = os.path.join(input_folder, filename)\n",
    "#         sample_name = os.path.splitext(filename)[0].replace(\".fastq\", \"\").replace(\".gz\", \"\")\n",
    "\n",
    "#         print(f\"ğŸ“Œ Processing: {sample_name}\")\n",
    "#         df = compute_quality_stats(input_path)\n",
    "\n",
    "#         # CSV ì €ì¥\n",
    "#         csv_path = os.path.join(output_csv_folder, f\"{sample_name}_quality.csv\")\n",
    "#         df.to_csv(csv_path, index=False)\n",
    "\n",
    "#         # ê·¸ë˜í”„ ì €ì¥\n",
    "#         plt.figure(figsize=(18, 8))\n",
    "#         ax = plt.gca()\n",
    "#         add_quality_background(ax)\n",
    "#         plt.plot(df[\"position\"], df[\"mean\"], color=\"blue\", linewidth=1.5, label=\"Mean Quality\")\n",
    "\n",
    "#         for i in range(len(df)):\n",
    "#             x = df.loc[i, \"position\"]\n",
    "#             q1 = df.loc[i, \"q1\"]\n",
    "#             q3 = df.loc[i, \"q3\"]\n",
    "#             plt.fill_between([x - 0.4, x + 0.4], [q1, q1], [q3, q3], color=\"yellow\", edgecolor=\"black\")\n",
    "\n",
    "#         plt.vlines(df[\"position\"], df[\"min\"], df[\"max\"], color=\"black\", linewidth=0.5)\n",
    "#         plt.title(f\"Quality scores across all bases: {sample_name}\", fontsize=14)\n",
    "#         plt.xlabel(\"Position in read (bp)\", fontsize=12)\n",
    "#         plt.ylabel(\"Quality score\", fontsize=12)\n",
    "#         plt.ylim(0, 40)\n",
    "#         plt.xlim(1, df[\"position\"].max())\n",
    "#         plt.legend()\n",
    "#         plt.tight_layout()\n",
    "#         plot_path = os.path.join(output_plot_folder, f\"{sample_name}_quality_plot.png\")\n",
    "#         plt.savefig(plot_path, dpi=300)\n",
    "#         plt.close()\n",
    "\n",
    "#         print(f\"âœ… Saved: {sample_name}_quality.csv and quality_plot.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90408c7",
   "metadata": {},
   "source": [
    "# read count check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3bc6daeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import gzip\n",
    "# from Bio import SeqIO\n",
    "\n",
    "# # ë¶„ì„ ëŒ€ìƒ í´ë”\n",
    "# input_folder = \"fastq_step/1_3_5_7_9_11/A_Untrimmed_output\"  # ì—¬ê¸°ì— ëŒ€ìƒ í´ë” ê²½ë¡œë¥¼ ì…ë ¥í•˜ì„¸ìš”\n",
    "\n",
    "# # í—ˆìš© í™•ì¥ì\n",
    "# valid_extensions = [\".fastq\", \".fastq.gz\", \".fasta\", \".fasta.gz\"]\n",
    "\n",
    "# # í¬ë§· ê²°ì • í•¨ìˆ˜\n",
    "# def get_format(filename):\n",
    "#     if filename.endswith(\".fastq\") or filename.endswith(\".fastq.gz\"):\n",
    "#         return \"fastq\"\n",
    "#     elif filename.endswith(\".fasta\") or filename.endswith(\".fasta.gz\"):\n",
    "#         return \"fasta\"\n",
    "#     else:\n",
    "#         return None\n",
    "\n",
    "# # ê²°ê³¼ ì €ì¥ ë¦¬ìŠ¤íŠ¸\n",
    "# read_counts = []\n",
    "\n",
    "# # íŒŒì¼ ìˆœíšŒ ë° read ìˆ˜ ì¹´ìš´íŠ¸\n",
    "# for filename in os.listdir(input_folder):\n",
    "#     if any(filename.endswith(ext) for ext in valid_extensions):\n",
    "#         file_path = os.path.join(input_folder, filename)\n",
    "#         file_format = get_format(filename)\n",
    "#         open_func = gzip.open if filename.endswith(\".gz\") else open\n",
    "\n",
    "#         try:\n",
    "#             with open_func(file_path, \"rt\") as handle:\n",
    "#                 count = sum(1 for _ in SeqIO.parse(handle, file_format))\n",
    "#             read_counts.append((filename, count))\n",
    "#         except Exception as e:\n",
    "#             print(f\"âŒ Error processing {filename}: {e}\")\n",
    "\n",
    "# # ğŸ“„ íŒŒì¼ëª… ê¸°ì¤€ ì •ë ¬ í›„ ì¶œë ¥\n",
    "# read_counts.sort(key=lambda x: x[0].lower())  # íŒŒì¼ëª… ê¸°ì¤€ (ëŒ€ì†Œë¬¸ì êµ¬ë¶„ ì—†ì´) ì •ë ¬\n",
    "# for fname, count in read_counts:\n",
    "#     print(f\"{fname:40} : {count} reads\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a68943",
   "metadata": {},
   "source": [
    "# length check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f9023132",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250905_batch19_08step_R1_untrimmed.fastq.gz :   1903 reads, Avg Length =  151.0 bp\n",
      "250905_batch19_08step_R2_untrimmed.fastq.gz :   1903 reads, Avg Length =  151.0 bp\n",
      "250910_batch20_07step_R1_untrimmed.fastq.gz :   1829 reads, Avg Length =  151.0 bp\n",
      "250910_batch20_07step_R2_untrimmed.fastq.gz :   1829 reads, Avg Length =  151.0 bp\n",
      "250910_batch20_08step_R1_untrimmed.fastq.gz :   1829 reads, Avg Length =  151.0 bp\n",
      "250910_batch20_08step_R2_untrimmed.fastq.gz :   1829 reads, Avg Length =  151.0 bp\n",
      "250910_batch20_09step_R1_untrimmed.fastq.gz :   1956 reads, Avg Length =  151.0 bp\n",
      "250910_batch20_09step_R2_untrimmed.fastq.gz :   1956 reads, Avg Length =  151.0 bp\n",
      "250910_batch20_10step_R1_untrimmed.fastq.gz :   1695 reads, Avg Length =  151.0 bp\n",
      "250910_batch20_10step_R2_untrimmed.fastq.gz :   1695 reads, Avg Length =  151.0 bp\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gzip\n",
    "from Bio import SeqIO\n",
    "\n",
    "# ë¶„ì„ ëŒ€ìƒ í´ë”\n",
    "input_folder = \"fastq_7_8_9_10_11_12/A_Untrimmed_output\"  # ì—¬ê¸°ì— ëŒ€ìƒ í´ë” ê²½ë¡œë¥¼ ì…ë ¥í•˜ì„¸ìš”\n",
    "\n",
    "# í—ˆìš© í™•ì¥ì\n",
    "valid_extensions = [\".fastq\", \".fastq.gz\"]\n",
    "\n",
    "# íŒŒì¼ í¬ë§· ê²°ì • í•¨ìˆ˜\n",
    "def get_format(filename):\n",
    "    if filename.endswith(\".fastq\") or filename.endswith(\".fastq.gz\"):\n",
    "        return \"fastq\"\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# ê²°ê³¼ ì €ì¥ ë¦¬ìŠ¤íŠ¸\n",
    "read_stats = []\n",
    "\n",
    "# íŒŒì¼ ìˆœíšŒ ë° ë¶„ì„\n",
    "for filename in os.listdir(input_folder):\n",
    "    if any(filename.endswith(ext) for ext in valid_extensions):\n",
    "        file_path = os.path.join(input_folder, filename)\n",
    "        file_format = get_format(filename)\n",
    "        open_func = gzip.open if filename.endswith(\".gz\") else open\n",
    "\n",
    "        try:\n",
    "            total_len = 0\n",
    "            read_count = 0\n",
    "            with open_func(file_path, \"rt\") as handle:\n",
    "                for record in SeqIO.parse(handle, file_format):\n",
    "                    total_len += len(record.seq)\n",
    "                    read_count += 1\n",
    "            avg_length = total_len / read_count if read_count > 0 else 0\n",
    "            read_stats.append((filename, read_count, round(avg_length, 2)))\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Error processing {filename}: {e}\")\n",
    "\n",
    "# ì •ë ¬ í›„ ì¶œë ¥\n",
    "read_stats.sort(key=lambda x: x[0].lower())\n",
    "for fname, count, avg_len in read_stats:\n",
    "    print(f\"{fname:40} : {count:6} reads, Avg Length = {avg_len:6} bp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d43590a",
   "metadata": {},
   "source": [
    "# Q filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "330bc19f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: you specified the options for cutting by quality, but forogt to enable any of cut_front/cut_tail/cut_right. This will have no effect.\n",
      "Detecting adapter sequence for read1...\n",
      "No adapter detected for read1\n",
      "\n",
      "Read1 before filtering:\n",
      "total reads: 1956\n",
      "total bases: 295356\n",
      "Q20 bases: 256879(86.9727%)\n",
      "Q30 bases: 231776(78.4734%)\n",
      "\n",
      "Read1 after filtering:\n",
      "total reads: 852\n",
      "total bases: 128652\n",
      "Q20 bases: 125281(97.3798%)\n",
      "Q30 bases: 119457(92.8528%)\n",
      "\n",
      "Filtering result:\n",
      "reads passed filter: 852\n",
      "reads failed due to low quality: 1104\n",
      "reads failed due to too many N: 0\n",
      "reads failed due to too short: 0\n",
      "reads with adapter trimmed: 0\n",
      "bases trimmed due to adapters: 0\n",
      "\n",
      "Duplication rate (may be overestimated since this is SE data): 27.2495%\n",
      "\n",
      "JSON report: fastq_7_8_9_10_11_12/B_Qfiltered/250910_batch20_09step_R1_Qfiltered.fastq.gz.json\n",
      "HTML report: fastq_7_8_9_10_11_12/B_Qfiltered/250910_batch20_09step_R1_Qfiltered.fastq.gz.html\n",
      "\n",
      "fastp -i fastq_7_8_9_10_11_12/A_Untrimmed_output/250910_batch20_09step_R1_untrimmed.fastq.gz -o fastq_7_8_9_10_11_12/B_Qfiltered/250910_batch20_09step_R1_Qfiltered.fastq.gz -q 30 -u 15 -l 151 --cut_mean_quality 30 --html fastq_7_8_9_10_11_12/B_Qfiltered/250910_batch20_09step_R1_Qfiltered.fastq.gz.html --json fastq_7_8_9_10_11_12/B_Qfiltered/250910_batch20_09step_R1_Qfiltered.fastq.gz.json \n",
      "fastp v0.23.4, time used: 1 seconds\n",
      "WARNING: you specified the options for cutting by quality, but forogt to enable any of cut_front/cut_tail/cut_right. This will have no effect.\n",
      "Detecting adapter sequence for read1...\n",
      "No adapter detected for read1\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering for 250910_batch20_09step_R1_untrimmed.fastq.gz is complete.\n",
      "Output FASTQ : fastq_7_8_9_10_11_12/B_Qfiltered/250910_batch20_09step_R1_Qfiltered.fastq.gz\n",
      "Reports      : fastq_7_8_9_10_11_12/B_Qfiltered/250910_batch20_09step_R1_Qfiltered.fastq.gz.html / fastq_7_8_9_10_11_12/B_Qfiltered/250910_batch20_09step_R1_Qfiltered.fastq.gz.json\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read1 before filtering:\n",
      "total reads: 1956\n",
      "total bases: 295356\n",
      "Q20 bases: 254346(86.1151%)\n",
      "Q30 bases: 226989(76.8527%)\n",
      "\n",
      "Read1 after filtering:\n",
      "total reads: 692\n",
      "total bases: 104492\n",
      "Q20 bases: 100693(96.3643%)\n",
      "Q30 bases: 94792(90.717%)\n",
      "\n",
      "Filtering result:\n",
      "reads passed filter: 692\n",
      "reads failed due to low quality: 1264\n",
      "reads failed due to too many N: 0\n",
      "reads failed due to too short: 0\n",
      "reads with adapter trimmed: 0\n",
      "bases trimmed due to adapters: 0\n",
      "\n",
      "Duplication rate (may be overestimated since this is SE data): 17.0245%\n",
      "\n",
      "JSON report: fastq_7_8_9_10_11_12/B_Qfiltered/250910_batch20_09step_R2_Qfiltered.fastq.gz.json\n",
      "HTML report: fastq_7_8_9_10_11_12/B_Qfiltered/250910_batch20_09step_R2_Qfiltered.fastq.gz.html\n",
      "\n",
      "fastp -i fastq_7_8_9_10_11_12/A_Untrimmed_output/250910_batch20_09step_R2_untrimmed.fastq.gz -o fastq_7_8_9_10_11_12/B_Qfiltered/250910_batch20_09step_R2_Qfiltered.fastq.gz -q 30 -u 15 -l 151 --cut_mean_quality 30 --html fastq_7_8_9_10_11_12/B_Qfiltered/250910_batch20_09step_R2_Qfiltered.fastq.gz.html --json fastq_7_8_9_10_11_12/B_Qfiltered/250910_batch20_09step_R2_Qfiltered.fastq.gz.json \n",
      "fastp v0.23.4, time used: 0 seconds\n",
      "WARNING: you specified the options for cutting by quality, but forogt to enable any of cut_front/cut_tail/cut_right. This will have no effect.\n",
      "Detecting adapter sequence for read1...\n",
      "No adapter detected for read1\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering for 250910_batch20_09step_R2_untrimmed.fastq.gz is complete.\n",
      "Output FASTQ : fastq_7_8_9_10_11_12/B_Qfiltered/250910_batch20_09step_R2_Qfiltered.fastq.gz\n",
      "Reports      : fastq_7_8_9_10_11_12/B_Qfiltered/250910_batch20_09step_R2_Qfiltered.fastq.gz.html / fastq_7_8_9_10_11_12/B_Qfiltered/250910_batch20_09step_R2_Qfiltered.fastq.gz.json\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read1 before filtering:\n",
      "total reads: 1903\n",
      "total bases: 287353\n",
      "Q20 bases: 253719(88.2952%)\n",
      "Q30 bases: 230302(80.146%)\n",
      "\n",
      "Read1 after filtering:\n",
      "total reads: 899\n",
      "total bases: 135749\n",
      "Q20 bases: 130905(96.4316%)\n",
      "Q30 bases: 123946(91.3053%)\n",
      "\n",
      "Filtering result:\n",
      "reads passed filter: 899\n",
      "reads failed due to low quality: 1004\n",
      "reads failed due to too many N: 0\n",
      "reads failed due to too short: 0\n",
      "reads with adapter trimmed: 0\n",
      "bases trimmed due to adapters: 0\n",
      "\n",
      "Duplication rate (may be overestimated since this is SE data): 26.3269%\n",
      "\n",
      "JSON report: fastq_7_8_9_10_11_12/B_Qfiltered/250905_batch19_08step_R2_Qfiltered.fastq.gz.json\n",
      "HTML report: fastq_7_8_9_10_11_12/B_Qfiltered/250905_batch19_08step_R2_Qfiltered.fastq.gz.html\n",
      "\n",
      "fastp -i fastq_7_8_9_10_11_12/A_Untrimmed_output/250905_batch19_08step_R2_untrimmed.fastq.gz -o fastq_7_8_9_10_11_12/B_Qfiltered/250905_batch19_08step_R2_Qfiltered.fastq.gz -q 30 -u 15 -l 151 --cut_mean_quality 30 --html fastq_7_8_9_10_11_12/B_Qfiltered/250905_batch19_08step_R2_Qfiltered.fastq.gz.html --json fastq_7_8_9_10_11_12/B_Qfiltered/250905_batch19_08step_R2_Qfiltered.fastq.gz.json \n",
      "fastp v0.23.4, time used: 0 seconds\n",
      "WARNING: you specified the options for cutting by quality, but forogt to enable any of cut_front/cut_tail/cut_right. This will have no effect.\n",
      "Detecting adapter sequence for read1...\n",
      "No adapter detected for read1\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering for 250905_batch19_08step_R2_untrimmed.fastq.gz is complete.\n",
      "Output FASTQ : fastq_7_8_9_10_11_12/B_Qfiltered/250905_batch19_08step_R2_Qfiltered.fastq.gz\n",
      "Reports      : fastq_7_8_9_10_11_12/B_Qfiltered/250905_batch19_08step_R2_Qfiltered.fastq.gz.html / fastq_7_8_9_10_11_12/B_Qfiltered/250905_batch19_08step_R2_Qfiltered.fastq.gz.json\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read1 before filtering:\n",
      "total reads: 1903\n",
      "total bases: 287353\n",
      "Q20 bases: 261970(91.1666%)\n",
      "Q30 bases: 241965(84.2048%)\n",
      "\n",
      "Read1 after filtering:\n",
      "total reads: 1167\n",
      "total bases: 176217\n",
      "Q20 bases: 172491(97.8856%)\n",
      "Q30 bases: 165465(93.8984%)\n",
      "\n",
      "Filtering result:\n",
      "reads passed filter: 1167\n",
      "reads failed due to low quality: 736\n",
      "reads failed due to too many N: 0\n",
      "reads failed due to too short: 0\n",
      "reads with adapter trimmed: 0\n",
      "bases trimmed due to adapters: 0\n",
      "\n",
      "Duplication rate (may be overestimated since this is SE data): 46.6106%\n",
      "\n",
      "JSON report: fastq_7_8_9_10_11_12/B_Qfiltered/250905_batch19_08step_R1_Qfiltered.fastq.gz.json\n",
      "HTML report: fastq_7_8_9_10_11_12/B_Qfiltered/250905_batch19_08step_R1_Qfiltered.fastq.gz.html\n",
      "\n",
      "fastp -i fastq_7_8_9_10_11_12/A_Untrimmed_output/250905_batch19_08step_R1_untrimmed.fastq.gz -o fastq_7_8_9_10_11_12/B_Qfiltered/250905_batch19_08step_R1_Qfiltered.fastq.gz -q 30 -u 15 -l 151 --cut_mean_quality 30 --html fastq_7_8_9_10_11_12/B_Qfiltered/250905_batch19_08step_R1_Qfiltered.fastq.gz.html --json fastq_7_8_9_10_11_12/B_Qfiltered/250905_batch19_08step_R1_Qfiltered.fastq.gz.json \n",
      "fastp v0.23.4, time used: 0 seconds\n",
      "WARNING: you specified the options for cutting by quality, but forogt to enable any of cut_front/cut_tail/cut_right. This will have no effect.\n",
      "Detecting adapter sequence for read1...\n",
      "No adapter detected for read1\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering for 250905_batch19_08step_R1_untrimmed.fastq.gz is complete.\n",
      "Output FASTQ : fastq_7_8_9_10_11_12/B_Qfiltered/250905_batch19_08step_R1_Qfiltered.fastq.gz\n",
      "Reports      : fastq_7_8_9_10_11_12/B_Qfiltered/250905_batch19_08step_R1_Qfiltered.fastq.gz.html / fastq_7_8_9_10_11_12/B_Qfiltered/250905_batch19_08step_R1_Qfiltered.fastq.gz.json\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read1 before filtering:\n",
      "total reads: 1695\n",
      "total bases: 255945\n",
      "Q20 bases: 216727(84.6772%)\n",
      "Q30 bases: 192828(75.3396%)\n",
      "\n",
      "Read1 after filtering:\n",
      "total reads: 572\n",
      "total bases: 86372\n",
      "Q20 bases: 83774(96.9921%)\n",
      "Q30 bases: 79404(91.9326%)\n",
      "\n",
      "Filtering result:\n",
      "reads passed filter: 572\n",
      "reads failed due to low quality: 1123\n",
      "reads failed due to too many N: 0\n",
      "reads failed due to too short: 0\n",
      "reads with adapter trimmed: 0\n",
      "bases trimmed due to adapters: 0\n",
      "\n",
      "Duplication rate (may be overestimated since this is SE data): 18.6431%\n",
      "\n",
      "JSON report: fastq_7_8_9_10_11_12/B_Qfiltered/250910_batch20_10step_R1_Qfiltered.fastq.gz.json\n",
      "HTML report: fastq_7_8_9_10_11_12/B_Qfiltered/250910_batch20_10step_R1_Qfiltered.fastq.gz.html\n",
      "\n",
      "fastp -i fastq_7_8_9_10_11_12/A_Untrimmed_output/250910_batch20_10step_R1_untrimmed.fastq.gz -o fastq_7_8_9_10_11_12/B_Qfiltered/250910_batch20_10step_R1_Qfiltered.fastq.gz -q 30 -u 15 -l 151 --cut_mean_quality 30 --html fastq_7_8_9_10_11_12/B_Qfiltered/250910_batch20_10step_R1_Qfiltered.fastq.gz.html --json fastq_7_8_9_10_11_12/B_Qfiltered/250910_batch20_10step_R1_Qfiltered.fastq.gz.json \n",
      "fastp v0.23.4, time used: 1 seconds\n",
      "WARNING: you specified the options for cutting by quality, but forogt to enable any of cut_front/cut_tail/cut_right. This will have no effect.\n",
      "Detecting adapter sequence for read1...\n",
      "No adapter detected for read1\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering for 250910_batch20_10step_R1_untrimmed.fastq.gz is complete.\n",
      "Output FASTQ : fastq_7_8_9_10_11_12/B_Qfiltered/250910_batch20_10step_R1_Qfiltered.fastq.gz\n",
      "Reports      : fastq_7_8_9_10_11_12/B_Qfiltered/250910_batch20_10step_R1_Qfiltered.fastq.gz.html / fastq_7_8_9_10_11_12/B_Qfiltered/250910_batch20_10step_R1_Qfiltered.fastq.gz.json\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read1 before filtering:\n",
      "total reads: 1695\n",
      "total bases: 255945\n",
      "Q20 bases: 216366(84.5361%)\n",
      "Q30 bases: 190719(74.5156%)\n",
      "\n",
      "Read1 after filtering:\n",
      "total reads: 430\n",
      "total bases: 64930\n",
      "Q20 bases: 62401(96.105%)\n",
      "Q30 bases: 58299(89.7875%)\n",
      "\n",
      "Filtering result:\n",
      "reads passed filter: 430\n",
      "reads failed due to low quality: 1265\n",
      "reads failed due to too many N: 0\n",
      "reads failed due to too short: 0\n",
      "reads with adapter trimmed: 0\n",
      "bases trimmed due to adapters: 0\n",
      "\n",
      "Duplication rate (may be overestimated since this is SE data): 12.6844%\n",
      "\n",
      "JSON report: fastq_7_8_9_10_11_12/B_Qfiltered/250910_batch20_10step_R2_Qfiltered.fastq.gz.json\n",
      "HTML report: fastq_7_8_9_10_11_12/B_Qfiltered/250910_batch20_10step_R2_Qfiltered.fastq.gz.html\n",
      "\n",
      "fastp -i fastq_7_8_9_10_11_12/A_Untrimmed_output/250910_batch20_10step_R2_untrimmed.fastq.gz -o fastq_7_8_9_10_11_12/B_Qfiltered/250910_batch20_10step_R2_Qfiltered.fastq.gz -q 30 -u 15 -l 151 --cut_mean_quality 30 --html fastq_7_8_9_10_11_12/B_Qfiltered/250910_batch20_10step_R2_Qfiltered.fastq.gz.html --json fastq_7_8_9_10_11_12/B_Qfiltered/250910_batch20_10step_R2_Qfiltered.fastq.gz.json \n",
      "fastp v0.23.4, time used: 0 seconds\n",
      "WARNING: you specified the options for cutting by quality, but forogt to enable any of cut_front/cut_tail/cut_right. This will have no effect.\n",
      "Detecting adapter sequence for read1...\n",
      "No adapter detected for read1\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering for 250910_batch20_10step_R2_untrimmed.fastq.gz is complete.\n",
      "Output FASTQ : fastq_7_8_9_10_11_12/B_Qfiltered/250910_batch20_10step_R2_Qfiltered.fastq.gz\n",
      "Reports      : fastq_7_8_9_10_11_12/B_Qfiltered/250910_batch20_10step_R2_Qfiltered.fastq.gz.html / fastq_7_8_9_10_11_12/B_Qfiltered/250910_batch20_10step_R2_Qfiltered.fastq.gz.json\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read1 before filtering:\n",
      "total reads: 1829\n",
      "total bases: 276179\n",
      "Q20 bases: 250103(90.5583%)\n",
      "Q30 bases: 228867(82.8691%)\n",
      "\n",
      "Read1 after filtering:\n",
      "total reads: 1042\n",
      "total bases: 157342\n",
      "Q20 bases: 154282(98.0552%)\n",
      "Q30 bases: 147600(93.8084%)\n",
      "\n",
      "Filtering result:\n",
      "reads passed filter: 1042\n",
      "reads failed due to low quality: 787\n",
      "reads failed due to too many N: 0\n",
      "reads failed due to too short: 0\n",
      "reads with adapter trimmed: 0\n",
      "bases trimmed due to adapters: 0\n",
      "\n",
      "Duplication rate (may be overestimated since this is SE data): 44.5599%\n",
      "\n",
      "JSON report: fastq_7_8_9_10_11_12/B_Qfiltered/250910_batch20_07step_R1_Qfiltered.fastq.gz.json\n",
      "HTML report: fastq_7_8_9_10_11_12/B_Qfiltered/250910_batch20_07step_R1_Qfiltered.fastq.gz.html\n",
      "\n",
      "fastp -i fastq_7_8_9_10_11_12/A_Untrimmed_output/250910_batch20_07step_R1_untrimmed.fastq.gz -o fastq_7_8_9_10_11_12/B_Qfiltered/250910_batch20_07step_R1_Qfiltered.fastq.gz -q 30 -u 15 -l 151 --cut_mean_quality 30 --html fastq_7_8_9_10_11_12/B_Qfiltered/250910_batch20_07step_R1_Qfiltered.fastq.gz.html --json fastq_7_8_9_10_11_12/B_Qfiltered/250910_batch20_07step_R1_Qfiltered.fastq.gz.json \n",
      "fastp v0.23.4, time used: 0 seconds\n",
      "WARNING: you specified the options for cutting by quality, but forogt to enable any of cut_front/cut_tail/cut_right. This will have no effect.\n",
      "Detecting adapter sequence for read1...\n",
      "No adapter detected for read1\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering for 250910_batch20_07step_R1_untrimmed.fastq.gz is complete.\n",
      "Output FASTQ : fastq_7_8_9_10_11_12/B_Qfiltered/250910_batch20_07step_R1_Qfiltered.fastq.gz\n",
      "Reports      : fastq_7_8_9_10_11_12/B_Qfiltered/250910_batch20_07step_R1_Qfiltered.fastq.gz.html / fastq_7_8_9_10_11_12/B_Qfiltered/250910_batch20_07step_R1_Qfiltered.fastq.gz.json\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read1 before filtering:\n",
      "total reads: 1829\n",
      "total bases: 276179\n",
      "Q20 bases: 240704(87.1551%)\n",
      "Q30 bases: 215126(77.8937%)\n",
      "\n",
      "Read1 after filtering:\n",
      "total reads: 696\n",
      "total bases: 105096\n",
      "Q20 bases: 101193(96.2863%)\n",
      "Q30 bases: 94970(90.365%)\n",
      "\n",
      "Filtering result:\n",
      "reads passed filter: 696\n",
      "reads failed due to low quality: 1133\n",
      "reads failed due to too many N: 0\n",
      "reads failed due to too short: 0\n",
      "reads with adapter trimmed: 0\n",
      "bases trimmed due to adapters: 0\n",
      "\n",
      "Duplication rate (may be overestimated since this is SE data): 21.3778%\n",
      "\n",
      "JSON report: fastq_7_8_9_10_11_12/B_Qfiltered/250910_batch20_08step_R2_Qfiltered.fastq.gz.json\n",
      "HTML report: fastq_7_8_9_10_11_12/B_Qfiltered/250910_batch20_08step_R2_Qfiltered.fastq.gz.html\n",
      "\n",
      "fastp -i fastq_7_8_9_10_11_12/A_Untrimmed_output/250910_batch20_08step_R2_untrimmed.fastq.gz -o fastq_7_8_9_10_11_12/B_Qfiltered/250910_batch20_08step_R2_Qfiltered.fastq.gz -q 30 -u 15 -l 151 --cut_mean_quality 30 --html fastq_7_8_9_10_11_12/B_Qfiltered/250910_batch20_08step_R2_Qfiltered.fastq.gz.html --json fastq_7_8_9_10_11_12/B_Qfiltered/250910_batch20_08step_R2_Qfiltered.fastq.gz.json \n",
      "fastp v0.23.4, time used: 1 seconds\n",
      "WARNING: you specified the options for cutting by quality, but forogt to enable any of cut_front/cut_tail/cut_right. This will have no effect.\n",
      "Detecting adapter sequence for read1...\n",
      "No adapter detected for read1\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering for 250910_batch20_08step_R2_untrimmed.fastq.gz is complete.\n",
      "Output FASTQ : fastq_7_8_9_10_11_12/B_Qfiltered/250910_batch20_08step_R2_Qfiltered.fastq.gz\n",
      "Reports      : fastq_7_8_9_10_11_12/B_Qfiltered/250910_batch20_08step_R2_Qfiltered.fastq.gz.html / fastq_7_8_9_10_11_12/B_Qfiltered/250910_batch20_08step_R2_Qfiltered.fastq.gz.json\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read1 before filtering:\n",
      "total reads: 1829\n",
      "total bases: 276179\n",
      "Q20 bases: 242175(87.6877%)\n",
      "Q30 bases: 218794(79.2218%)\n",
      "\n",
      "Read1 after filtering:\n",
      "total reads: 838\n",
      "total bases: 126538\n",
      "Q20 bases: 123192(97.3557%)\n",
      "Q30 bases: 117361(92.7476%)\n",
      "\n",
      "Filtering result:\n",
      "reads passed filter: 838\n",
      "reads failed due to low quality: 991\n",
      "reads failed due to too many N: 0\n",
      "reads failed due to too short: 0\n",
      "reads with adapter trimmed: 0\n",
      "bases trimmed due to adapters: 0\n",
      "\n",
      "Duplication rate (may be overestimated since this is SE data): 31.5473%\n",
      "\n",
      "JSON report: fastq_7_8_9_10_11_12/B_Qfiltered/250910_batch20_08step_R1_Qfiltered.fastq.gz.json\n",
      "HTML report: fastq_7_8_9_10_11_12/B_Qfiltered/250910_batch20_08step_R1_Qfiltered.fastq.gz.html\n",
      "\n",
      "fastp -i fastq_7_8_9_10_11_12/A_Untrimmed_output/250910_batch20_08step_R1_untrimmed.fastq.gz -o fastq_7_8_9_10_11_12/B_Qfiltered/250910_batch20_08step_R1_Qfiltered.fastq.gz -q 30 -u 15 -l 151 --cut_mean_quality 30 --html fastq_7_8_9_10_11_12/B_Qfiltered/250910_batch20_08step_R1_Qfiltered.fastq.gz.html --json fastq_7_8_9_10_11_12/B_Qfiltered/250910_batch20_08step_R1_Qfiltered.fastq.gz.json \n",
      "fastp v0.23.4, time used: 0 seconds\n",
      "WARNING: you specified the options for cutting by quality, but forogt to enable any of cut_front/cut_tail/cut_right. This will have no effect.\n",
      "Detecting adapter sequence for read1...\n",
      "No adapter detected for read1\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering for 250910_batch20_08step_R1_untrimmed.fastq.gz is complete.\n",
      "Output FASTQ : fastq_7_8_9_10_11_12/B_Qfiltered/250910_batch20_08step_R1_Qfiltered.fastq.gz\n",
      "Reports      : fastq_7_8_9_10_11_12/B_Qfiltered/250910_batch20_08step_R1_Qfiltered.fastq.gz.html / fastq_7_8_9_10_11_12/B_Qfiltered/250910_batch20_08step_R1_Qfiltered.fastq.gz.json\n",
      "\n",
      "Filtering for 250910_batch20_07step_R2_untrimmed.fastq.gz is complete.\n",
      "Output FASTQ : fastq_7_8_9_10_11_12/B_Qfiltered/250910_batch20_07step_R2_Qfiltered.fastq.gz\n",
      "Reports      : fastq_7_8_9_10_11_12/B_Qfiltered/250910_batch20_07step_R2_Qfiltered.fastq.gz.html / fastq_7_8_9_10_11_12/B_Qfiltered/250910_batch20_07step_R2_Qfiltered.fastq.gz.json\n",
      "\n",
      "All filtering processes are done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read1 before filtering:\n",
      "total reads: 1829\n",
      "total bases: 276179\n",
      "Q20 bases: 246099(89.1085%)\n",
      "Q30 bases: 221783(80.3041%)\n",
      "\n",
      "Read1 after filtering:\n",
      "total reads: 909\n",
      "total bases: 137259\n",
      "Q20 bases: 132728(96.6989%)\n",
      "Q30 bases: 124722(90.8662%)\n",
      "\n",
      "Filtering result:\n",
      "reads passed filter: 909\n",
      "reads failed due to low quality: 920\n",
      "reads failed due to too many N: 0\n",
      "reads failed due to too short: 0\n",
      "reads with adapter trimmed: 0\n",
      "bases trimmed due to adapters: 0\n",
      "\n",
      "Duplication rate (may be overestimated since this is SE data): 36.9054%\n",
      "\n",
      "JSON report: fastq_7_8_9_10_11_12/B_Qfiltered/250910_batch20_07step_R2_Qfiltered.fastq.gz.json\n",
      "HTML report: fastq_7_8_9_10_11_12/B_Qfiltered/250910_batch20_07step_R2_Qfiltered.fastq.gz.html\n",
      "\n",
      "fastp -i fastq_7_8_9_10_11_12/A_Untrimmed_output/250910_batch20_07step_R2_untrimmed.fastq.gz -o fastq_7_8_9_10_11_12/B_Qfiltered/250910_batch20_07step_R2_Qfiltered.fastq.gz -q 30 -u 15 -l 151 --cut_mean_quality 30 --html fastq_7_8_9_10_11_12/B_Qfiltered/250910_batch20_07step_R2_Qfiltered.fastq.gz.html --json fastq_7_8_9_10_11_12/B_Qfiltered/250910_batch20_07step_R2_Qfiltered.fastq.gz.json \n",
      "fastp v0.23.4, time used: 0 seconds\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "# í’ˆì§ˆ ê¸°ì¤€(Q30)\n",
    "quality_threshold = 30\n",
    "\n",
    "# ì…ë ¥ í´ë”ì™€ ì¶œë ¥ í´ë” ì„¤ì •\n",
    "\n",
    "input_folder = \"fastq_7_8_9_10_11_12/A_Untrimmed_output\"\n",
    "output_folder = \"fastq_7_8_9_10_11_12/B_Qfiltered\"\n",
    "\n",
    "os.makedirs(output_folder, exist_ok=True)  # ì¶œë ¥ í´ë”ê°€ ì—†ìœ¼ë©´ ìƒì„±\n",
    "\n",
    "# ì…ë ¥ í´ë” ë‚´ íŒŒì¼ë“¤ì„ ìˆœíšŒí•˜ë©°, \"_trimmed.fastq.gz\"ë¡œ ëë‚˜ëŠ” íŒŒì¼ë§Œ ì²˜ë¦¬\n",
    "for filename in os.listdir(input_folder):\n",
    "    if filename.endswith(\"_untrimmed.fastq.gz\"):\n",
    "        # ì…ë ¥ íŒŒì¼ ê²½ë¡œ\n",
    "        input_file = os.path.join(input_folder, filename)\n",
    "        \n",
    "        # ì¶œë ¥ íŒŒì¼ ì´ë¦„(ì˜ˆ: sample_trimmed.fastq.gz -> sample_trimmed_filtered.fastq.gz)\n",
    "        output_file = os.path.join(\n",
    "            output_folder, \n",
    "            filename.replace(\"_untrimmed.fastq.gz\", \"_Qfiltered.fastq.gz\")\n",
    "        )\n",
    "        \n",
    "        # fastp ì‹¤í–‰ (ì‹±ê¸€ ì—”ë“œ ëª¨ë“œ)\n",
    "        subprocess.call([\n",
    "            \"fastp\",\n",
    "            \"-i\", input_file,               # ì…ë ¥ íŒŒì¼\n",
    "            \"-o\", output_file,              # ì¶œë ¥ íŒŒì¼\n",
    "            \"-q\", str(quality_threshold),   # Q30 ë¯¸ë§Œ í’ˆì§ˆ ì œê±°\n",
    "            \"-u\", \"15\",                      # low-quality base ë¹„ìœ¨ 20% ì´ìƒì´ë©´ read ì œê±°\n",
    "            \"-l\", \"151\",                      # ìµœì†Œ read ê¸¸ì´\n",
    "            \"--cut_mean_quality\", \"30\",     # í‰ê·  Q<30ì´ë©´ read ì œê±°\n",
    "            \"--html\", f\"{output_file}.html\",  # HTML ë¦¬í¬íŠ¸\n",
    "            \"--json\", f\"{output_file}.json\"   # JSON ë¦¬í¬íŠ¸\n",
    "        ])\n",
    "        \n",
    "        print(f\"Filtering for {filename} is complete.\\n\"\n",
    "              f\"Output FASTQ : {output_file}\\n\"\n",
    "              f\"Reports      : {output_file}.html / {output_file}.json\\n\")\n",
    "\n",
    "print(\"All filtering processes are done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02151d72",
   "metadata": {},
   "source": [
    "# Quality check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3647a597",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import gzip\n",
    "# from Bio import SeqIO\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # ğŸ“ ì…ë ¥ í´ë”ì™€ ì¶œë ¥ í´ë” ì„¤ì •\n",
    "# input_folder = \"fastq_step/1_3_5_7_9_11/B_Qfiltered\"\n",
    "# output_csv_folder = \"fastq_step/1_3_5_7_9_11/B_Qfiltered/quality_stats_csv\"\n",
    "# output_plot_folder = \"fastq_step/1_3_5_7_9_11/B_Qfiltered/quality_plots\"\n",
    "# os.makedirs(output_csv_folder, exist_ok=True)\n",
    "# os.makedirs(output_plot_folder, exist_ok=True)\n",
    "\n",
    "# # ğŸ” í’ˆì§ˆ í†µê³„ ì¶”ì¶œ í•¨ìˆ˜\n",
    "# def compute_quality_stats(file_path):\n",
    "#     position_qualities = {}\n",
    "#     open_func = gzip.open if file_path.endswith(\".gz\") else open\n",
    "\n",
    "#     with open_func(file_path, \"rt\") as handle:\n",
    "#         for record in SeqIO.parse(handle, \"fastq\"):\n",
    "#             for i, q in enumerate(record.letter_annotations[\"phred_quality\"]):\n",
    "#                 position_qualities.setdefault(i, []).append(q)\n",
    "\n",
    "#     stats = []\n",
    "#     for pos in sorted(position_qualities):\n",
    "#         scores = np.array(position_qualities[pos])\n",
    "#         stats.append({\n",
    "#             \"position\": pos + 1,\n",
    "#             \"mean\": np.mean(scores),\n",
    "#             \"q1\": np.percentile(scores, 25),\n",
    "#             \"median\": np.median(scores),\n",
    "#             \"q3\": np.percentile(scores, 75),\n",
    "#             \"min\": np.min(scores),\n",
    "#             \"max\": np.max(scores)\n",
    "#         })\n",
    "#     return pd.DataFrame(stats)\n",
    "\n",
    "# # ğŸ“Š ë°°ê²½ ìƒ‰ìƒ í•¨ìˆ˜ (fastp ìŠ¤íƒ€ì¼)\n",
    "# def add_quality_background(ax):\n",
    "#     ax.axhspan(30, 40, facecolor='lightgreen', alpha=0.5)\n",
    "#     ax.axhspan(25, 30, facecolor='khaki', alpha=0.5)\n",
    "#     ax.axhspan(20, 25, facecolor='moccasin', alpha=0.5)\n",
    "#     ax.axhspan(0, 20, facecolor='lightcoral', alpha=0.5)\n",
    "\n",
    "# # ğŸ“‚ í´ë” ë‚´ ëª¨ë“  FASTQ(.gz í¬í•¨) ì²˜ë¦¬\n",
    "# for filename in os.listdir(input_folder):\n",
    "#     if filename.endswith(\".fastq\") or filename.endswith(\".fastq.gz\"):\n",
    "#         input_path = os.path.join(input_folder, filename)\n",
    "#         sample_name = os.path.splitext(filename)[0].replace(\".fastq\", \"\").replace(\".gz\", \"\")\n",
    "\n",
    "#         print(f\"ğŸ“Œ Processing: {sample_name}\")\n",
    "#         df = compute_quality_stats(input_path)\n",
    "\n",
    "#         # CSV ì €ì¥\n",
    "#         csv_path = os.path.join(output_csv_folder, f\"{sample_name}_quality.csv\")\n",
    "#         df.to_csv(csv_path, index=False)\n",
    "\n",
    "#         # ê·¸ë˜í”„ ì €ì¥\n",
    "#         plt.figure(figsize=(18, 8))\n",
    "#         ax = plt.gca()\n",
    "#         add_quality_background(ax)\n",
    "#         plt.plot(df[\"position\"], df[\"mean\"], color=\"blue\", linewidth=1.5, label=\"Mean Quality\")\n",
    "\n",
    "#         for i in range(len(df)):\n",
    "#             x = df.loc[i, \"position\"]\n",
    "#             q1 = df.loc[i, \"q1\"]\n",
    "#             q3 = df.loc[i, \"q3\"]\n",
    "#             plt.fill_between([x - 0.4, x + 0.4], [q1, q1], [q3, q3], color=\"yellow\", edgecolor=\"black\")\n",
    "\n",
    "#         plt.vlines(df[\"position\"], df[\"min\"], df[\"max\"], color=\"black\", linewidth=0.5)\n",
    "#         plt.title(f\"Quality scores across all bases: {sample_name}\", fontsize=14)\n",
    "#         plt.xlabel(\"Position in read (bp)\", fontsize=12)\n",
    "#         plt.ylabel(\"Quality score\", fontsize=12)\n",
    "#         plt.ylim(0, 40)\n",
    "#         plt.xlim(1, df[\"position\"].max())\n",
    "#         plt.legend()\n",
    "#         plt.tight_layout()\n",
    "#         plot_path = os.path.join(output_plot_folder, f\"{sample_name}_quality_plot.png\")\n",
    "#         plt.savefig(plot_path, dpi=300)\n",
    "#         plt.close()\n",
    "\n",
    "#         print(f\"âœ… Saved: {sample_name}_quality.csv and quality_plot.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ced46fb",
   "metadata": {},
   "source": [
    "# read count check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "92d17355",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import gzip\n",
    "# from Bio import SeqIO\n",
    "\n",
    "# # ë¶„ì„ ëŒ€ìƒ í´ë”\n",
    "# input_folder = \"fastq_step/1_3_5_7_9_11/B_Qfiltered\"  # ì—¬ê¸°ì— ëŒ€ìƒ í´ë” ê²½ë¡œë¥¼ ì…ë ¥í•˜ì„¸ìš”\n",
    "\n",
    "# # í—ˆìš© í™•ì¥ì\n",
    "# valid_extensions = [\".fastq\", \".fastq.gz\", \".fasta\", \".fasta.gz\"]\n",
    "\n",
    "# # í¬ë§· ê²°ì • í•¨ìˆ˜\n",
    "# def get_format(filename):\n",
    "#     if filename.endswith(\".fastq\") or filename.endswith(\".fastq.gz\"):\n",
    "#         return \"fastq\"\n",
    "#     elif filename.endswith(\".fasta\") or filename.endswith(\".fasta.gz\"):\n",
    "#         return \"fasta\"\n",
    "#     else:\n",
    "#         return None\n",
    "\n",
    "# # ê²°ê³¼ ì €ì¥ ë¦¬ìŠ¤íŠ¸\n",
    "# read_counts = []\n",
    "\n",
    "# # íŒŒì¼ ìˆœíšŒ ë° read ìˆ˜ ì¹´ìš´íŠ¸\n",
    "# for filename in os.listdir(input_folder):\n",
    "#     if any(filename.endswith(ext) for ext in valid_extensions):\n",
    "#         file_path = os.path.join(input_folder, filename)\n",
    "#         file_format = get_format(filename)\n",
    "#         open_func = gzip.open if filename.endswith(\".gz\") else open\n",
    "\n",
    "#         try:\n",
    "#             with open_func(file_path, \"rt\") as handle:\n",
    "#                 count = sum(1 for _ in SeqIO.parse(handle, file_format))\n",
    "#             read_counts.append((filename, count))\n",
    "#         except Exception as e:\n",
    "#             print(f\"âŒ Error processing {filename}: {e}\")\n",
    "\n",
    "# # ğŸ“„ íŒŒì¼ëª… ê¸°ì¤€ ì •ë ¬ í›„ ì¶œë ¥\n",
    "# read_counts.sort(key=lambda x: x[0].lower())  # íŒŒì¼ëª… ê¸°ì¤€ (ëŒ€ì†Œë¬¸ì êµ¬ë¶„ ì—†ì´) ì •ë ¬\n",
    "# for fname, count in read_counts:\n",
    "#     print(f\"{fname:40} : {count} reads\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34270d38",
   "metadata": {},
   "source": [
    "# ID matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0f915a10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 250910_batch20_10step_R1_Qfiltered.fastq.gz and 250910_batch20_10step_R2_Qfiltered.fastq.gz\n",
      "Total R1 IDs: 572, Total R2 IDs: 430, Matching IDs: 349\n",
      "IDs only in R1: 223, IDs only in R2: 81\n",
      "\n",
      "Processing 250910_batch20_08step_R1_Qfiltered.fastq.gz and 250910_batch20_08step_R2_Qfiltered.fastq.gz\n",
      "Total R1 IDs: 838, Total R2 IDs: 696, Matching IDs: 590\n",
      "IDs only in R1: 248, IDs only in R2: 106\n",
      "\n",
      "Processing 250910_batch20_07step_R1_Qfiltered.fastq.gz and 250910_batch20_07step_R2_Qfiltered.fastq.gz\n",
      "Total R1 IDs: 1042, Total R2 IDs: 909, Matching IDs: 814\n",
      "IDs only in R1: 228, IDs only in R2: 95\n",
      "\n",
      "Processing 250910_batch20_09step_R1_Qfiltered.fastq.gz and 250910_batch20_09step_R2_Qfiltered.fastq.gz\n",
      "Total R1 IDs: 852, Total R2 IDs: 692, Matching IDs: 605\n",
      "IDs only in R1: 247, IDs only in R2: 87\n",
      "\n",
      "Processing 250905_batch19_08step_R1_Qfiltered.fastq.gz and 250905_batch19_08step_R2_Qfiltered.fastq.gz\n",
      "Total R1 IDs: 1167, Total R2 IDs: 899, Matching IDs: 839\n",
      "IDs only in R1: 328, IDs only in R2: 60\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "import glob\n",
    "import os\n",
    "\n",
    "def extract_matching_reads(r1_path, r2_path, out_r1_path, out_r2_path):\n",
    "    def get_read_id(header):\n",
    "        # FASTQ headerì—ì„œ ID ì¶”ì¶œ\n",
    "        return header.split()[0].replace('/1', '').replace('/2', '')\n",
    "\n",
    "    r1_ids = set()\n",
    "    r2_ids = set()\n",
    "\n",
    "    with gzip.open(r1_path, 'rt') as r1_file:\n",
    "        while True:\n",
    "            header = r1_file.readline()\n",
    "            if not header:\n",
    "                break\n",
    "            r1_ids.add(get_read_id(header.strip()))\n",
    "            [r1_file.readline() for _ in range(3)]  # read ë‚˜ë¨¸ì§€ 3ì¤„ skip\n",
    "\n",
    "    with gzip.open(r2_path, 'rt') as r2_file:\n",
    "        while True:\n",
    "            header = r2_file.readline()\n",
    "            if not header:\n",
    "                break\n",
    "            r2_ids.add(get_read_id(header.strip()))\n",
    "            [r2_file.readline() for _ in range(3)]\n",
    "\n",
    "    matching_ids = r1_ids & r2_ids\n",
    "    r1_only = r1_ids - r2_ids\n",
    "    r2_only = r2_ids - r1_ids\n",
    "\n",
    "    print(f\"Processing {os.path.basename(r1_path)} and {os.path.basename(r2_path)}\")\n",
    "    print(f\"Total R1 IDs: {len(r1_ids)}, Total R2 IDs: {len(r2_ids)}, Matching IDs: {len(matching_ids)}\")\n",
    "    print(f\"IDs only in R1: {len(r1_only)}, IDs only in R2: {len(r2_only)}\\n\")\n",
    "\n",
    "    # ê²°ê³¼ í´ë” ìƒì„±\n",
    "    for out_path in [out_r1_path, out_r2_path]:\n",
    "        os.makedirs(os.path.dirname(out_path), exist_ok=True)\n",
    "\n",
    "    def write_matching_reads(input_path, output_path, matching_ids):\n",
    "        with gzip.open(input_path, 'rt') as infile, gzip.open(output_path, 'wt') as outfile:\n",
    "            while True:\n",
    "                lines = [infile.readline() for _ in range(4)]\n",
    "                if not lines[0]:\n",
    "                    break\n",
    "                read_id = get_read_id(lines[0].strip())\n",
    "                if read_id in matching_ids:\n",
    "                    outfile.writelines(lines)\n",
    "\n",
    "    write_matching_reads(r1_path, out_r1_path, matching_ids)\n",
    "    write_matching_reads(r2_path, out_r2_path, matching_ids)\n",
    "\n",
    "# ----------------------\n",
    "# ì „ì²´ íŒŒì¼ì— ëŒ€í•´ ì ìš©\n",
    "# ----------------------\n",
    "\n",
    "input_folder = \"fastq_7_8_9_10_11_12/B_Qfiltered\"\n",
    "output_folder = \"fastq_7_8_9_10_11_12/C_ID_matched\"\n",
    "\n",
    "# ëª¨ë“  R1 íŒŒì¼ ì°¾ê¸°\n",
    "r1_files = glob.glob(os.path.join(input_folder, \"*_R1_Qfiltered.fastq.gz\"))\n",
    "\n",
    "# ê° R1ì— ëŒ€í•´ ì§ì´ ë§ëŠ” R2ë¥¼ ì°¾ê³  ì‘ì—… ì‹¤í–‰\n",
    "for r1_file in r1_files:\n",
    "    r2_file = r1_file.replace(\"_R1_Qfiltered.fastq.gz\", \"_R2_Qfiltered.fastq.gz\")\n",
    "    \n",
    "    if os.path.exists(r2_file):\n",
    "        # ê²°ê³¼ output ê²½ë¡œ ì„¤ì •\n",
    "        base_name = os.path.basename(r1_file).replace(\"_R1_Qfiltered.fastq.gz\", \"\")\n",
    "        out_r1 = os.path.join(output_folder, f\"{base_name}_ID_match_R1.fastq.gz\")\n",
    "        out_r2 = os.path.join(output_folder, f\"{base_name}_ID_match_R2.fastq.gz\")\n",
    "        \n",
    "        # í•¨ìˆ˜ ì‹¤í–‰\n",
    "        extract_matching_reads(r1_file, r2_file, out_r1, out_r2)\n",
    "    else:\n",
    "        print(f\"Warning: {r2_file} not found. Skipping.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925bb690",
   "metadata": {},
   "source": [
    "# DNA Fragmentation R1(Front, Back), R2(Front, Back)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "80291728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ë¶„ë¦¬ ì™„ë£Œ: 250910_batch20_09step â†’ fastq_7_8_9_10_11_12/D_split_reads (N=102)\n",
      "âœ… ë¶„ë¦¬ ì™„ë£Œ: 250910_batch20_08step â†’ fastq_7_8_9_10_11_12/D_split_reads (N=124)\n",
      "âœ… ë¶„ë¦¬ ì™„ë£Œ: 250910_batch20_10step â†’ fastq_7_8_9_10_11_12/D_split_reads (N=82)\n",
      "âœ… ë¶„ë¦¬ ì™„ë£Œ: 250910_batch20_07step â†’ fastq_7_8_9_10_11_12/D_split_reads (N=144)\n",
      "âœ… ë¶„ë¦¬ ì™„ë£Œ: 250905_batch19_08step â†’ fastq_7_8_9_10_11_12/D_split_reads (N=124)\n"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "import glob\n",
    "import os\n",
    "\n",
    "def split_fastq_by_position(r1_path, r2_path, n, output_dir):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    sample_base = os.path.basename(r1_path).replace(\"_ID_match_R1.fastq.gz\", \"\")\n",
    "    r1_f_path = os.path.join(output_dir, f\"{sample_base}_R1_F.fastq.gz\")\n",
    "    r1_b_path = os.path.join(output_dir, f\"{sample_base}_R1_B.fastq.gz\")\n",
    "    r2_f_path = os.path.join(output_dir, f\"{sample_base}_R2_F.fastq.gz\")\n",
    "    r2_b_path = os.path.join(output_dir, f\"{sample_base}_R2_B.fastq.gz\")\n",
    "\n",
    "    with gzip.open(r1_path, 'rt') as r1_file, \\\n",
    "         gzip.open(r2_path, 'rt') as r2_file, \\\n",
    "         gzip.open(r1_f_path, 'wt') as r1_f_out, \\\n",
    "         gzip.open(r1_b_path, 'wt') as r1_b_out, \\\n",
    "         gzip.open(r2_f_path, 'wt') as r2_f_out, \\\n",
    "         gzip.open(r2_b_path, 'wt') as r2_b_out:\n",
    "\n",
    "        while True:\n",
    "            r1_lines = [r1_file.readline() for _ in range(4)]\n",
    "            r2_lines = [r2_file.readline() for _ in range(4)]\n",
    "\n",
    "            if not r1_lines[0] or not r2_lines[0]:\n",
    "                break\n",
    "\n",
    "            header1, seq1, plus1, qual1 = [line.strip() for line in r1_lines]\n",
    "            header2, seq2, plus2, qual2 = [line.strip() for line in r2_lines]\n",
    "\n",
    "            r1_f_out.write(f\"{header1}\\n{seq1[:151-n]}\\n{plus1}\\n{qual1[:151-n]}\\n\")\n",
    "            r1_b_out.write(f\"{header1}\\n{seq1[-n:]}\\n{plus1}\\n{qual1[-n:]}\\n\")\n",
    "            r2_f_out.write(f\"{header2}\\n{seq2[:151-n]}\\n{plus2}\\n{qual2[:151-n]}\\n\")\n",
    "            r2_b_out.write(f\"{header2}\\n{seq2[-n:]}\\n{plus2}\\n{qual2[-n:]}\\n\")\n",
    "\n",
    "    print(f\"âœ… ë¶„ë¦¬ ì™„ë£Œ: {sample_base} â†’ {output_dir} (N={n})\")\n",
    "\n",
    "# -----------------------------------\n",
    "# ì „ì²´ íŒŒì¼ì— ëŒ€í•´ split ì ìš©í•˜ëŠ” ì½”ë“œ\n",
    "# -----------------------------------\n",
    "\n",
    "input_folder = \"fastq_7_8_9_10_11_12/C_id_matched\"\n",
    "output_folder = \"fastq_7_8_9_10_11_12/D_split_reads\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# prefixë³„ Nê°’ ì„¤ì •\n",
    "sample_n_mapping = {\n",
    "    \"07step\": 144,\n",
    "    \"08step\": 124,\n",
    "    \"09step\": 102,\n",
    "    \"10step\": 82,\n",
    "    \"11step\": 60,\n",
    "    \"12step\": 40, \n",
    "}\n",
    "\n",
    "\n",
    "# ëª¨ë“  R1 íŒŒì¼ ë¦¬ìŠ¤íŠ¸ ì°¾ê¸°\n",
    "r1_files = glob.glob(os.path.join(input_folder, \"*_ID_match_R1.fastq.gz\"))\n",
    "\n",
    "for r1_file in r1_files:\n",
    "    r2_file = r1_file.replace(\"_R1.fastq.gz\", \"_R2.fastq.gz\")\n",
    "\n",
    "    if not os.path.exists(r2_file):\n",
    "        print(f\"âš ï¸ ì§ì´ ë§ëŠ” R2 íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {r2_file}\")\n",
    "        continue\n",
    "\n",
    "    # íŒŒì¼ ì´ë¦„ì— ë§ëŠ” Nê°’ ì°¾ê¸°\n",
    "    matched_n = None\n",
    "    for prefix, n_value in sample_n_mapping.items():\n",
    "        if prefix in os.path.basename(r1_file):\n",
    "            matched_n = n_value\n",
    "            break\n",
    "\n",
    "    if matched_n is None:\n",
    "        print(f\"âš ï¸ Nê°’ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {r1_file} â†’ ìŠ¤í‚µ\")\n",
    "        continue\n",
    "\n",
    "    # split ì‹¤í–‰\n",
    "    split_fastq_by_position(r1_file, r2_file, matched_n, output_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f8f8da",
   "metadata": {},
   "source": [
    "# R2 DNA reverse complementary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "bb8d70a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Reverse complemented: 250910_batch20_08step_R2_B_revcomp.fastq.gz\n",
      "âœ… Reverse complemented: 250910_batch20_10step_R2_B_revcomp.fastq.gz\n",
      "âœ… Reverse complemented: 250910_batch20_09step_R2_B_revcomp.fastq.gz\n",
      "âœ… Reverse complemented: 250910_batch20_07step_R2_F_revcomp.fastq.gz\n",
      "âœ… Reverse complemented: 250905_batch19_08step_R2_B_revcomp.fastq.gz\n",
      "âœ… Reverse complemented: 250905_batch19_08step_R2_F_revcomp.fastq.gz\n",
      "âœ… Reverse complemented: 250910_batch20_07step_R2_B_revcomp.fastq.gz\n",
      "âœ… Reverse complemented: 250910_batch20_08step_R2_F_revcomp.fastq.gz\n",
      "âœ… Reverse complemented: 250910_batch20_09step_R2_F_revcomp.fastq.gz\n",
      "âœ… Reverse complemented: 250910_batch20_10step_R2_F_revcomp.fastq.gz\n"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "import glob\n",
    "import os\n",
    "from Bio import SeqIO\n",
    "\n",
    "def reverse_complement_fastq(input_fastq_path, output_fastq_path):\n",
    "    with gzip.open(input_fastq_path, \"rt\") as infile, gzip.open(output_fastq_path, \"wt\") as outfile:\n",
    "        for record in SeqIO.parse(infile, \"fastq\"):\n",
    "            record.seq = record.seq.reverse_complement()\n",
    "            record.letter_annotations[\"phred_quality\"] = record.letter_annotations[\"phred_quality\"][::-1]\n",
    "            SeqIO.write(record, outfile, \"fastq\")\n",
    "    print(f\"âœ… Reverse complemented: {os.path.basename(output_fastq_path)}\")\n",
    "\n",
    "# --------------------------------------\n",
    "# ì „ì²´ íŒŒì¼ì— ëŒ€í•´ reverse complement ìˆ˜í–‰\n",
    "# --------------------------------------\n",
    "\n",
    "input_folder = \"fastq_7_8_9_10_11_12/D_split_reads\"\n",
    "os.makedirs(input_folder, exist_ok=True)\n",
    "\n",
    "# _R2_B.fastq.gz ë˜ëŠ” _R2_F.fastq.gzë¡œ ëë‚˜ëŠ” íŒŒì¼ë§Œ ì°¾ê¸°\n",
    "input_files = glob.glob(os.path.join(input_folder, \"*_R2_[BF].fastq.gz\"))\n",
    "\n",
    "for input_path in input_files:\n",
    "    base = os.path.basename(input_path)\n",
    "    name_without_ext = base.replace(\".fastq.gz\", \"\")  # .fastq.gz ì œê±°\n",
    "    output_path = os.path.join(input_folder, f\"{name_without_ext}_revcomp.fastq.gz\")\n",
    "    \n",
    "    reverse_complement_fastq(input_path, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a96d866a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Reverse complemented: 250910_batch20_08step_R2_B_revcomp.fastq.gz\n",
      "âœ… Reverse complemented: 250910_batch20_10step_R2_B_revcomp.fastq.gz\n",
      "âœ… Reverse complemented: 250910_batch20_09step_R2_B_revcomp.fastq.gz\n",
      "âœ… Reverse complemented: 250910_batch20_07step_R2_F_revcomp.fastq.gz\n",
      "âœ… Reverse complemented: 250905_batch19_08step_R2_B_revcomp.fastq.gz\n",
      "âœ… Reverse complemented: 250905_batch19_08step_R2_F_revcomp.fastq.gz\n",
      "âœ… Reverse complemented: 250910_batch20_07step_R2_B_revcomp.fastq.gz\n",
      "âœ… Reverse complemented: 250910_batch20_08step_R2_F_revcomp.fastq.gz\n",
      "âœ… Reverse complemented: 250910_batch20_09step_R2_F_revcomp.fastq.gz\n",
      "âœ… Reverse complemented: 250910_batch20_10step_R2_F_revcomp.fastq.gz\n"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "import glob\n",
    "import os\n",
    "from Bio import SeqIO\n",
    "\n",
    "def reverse_complement_fastq(input_fastq_path, output_fastq_path):\n",
    "    with gzip.open(input_fastq_path, \"rt\") as infile, gzip.open(output_fastq_path, \"wt\") as outfile:\n",
    "        for record in SeqIO.parse(infile, \"fastq\"):\n",
    "            record.seq = record.seq.reverse_complement()\n",
    "            record.letter_annotations[\"phred_quality\"] = record.letter_annotations[\"phred_quality\"][::-1]\n",
    "            SeqIO.write(record, outfile, \"fastq\")\n",
    "    print(f\"âœ… Reverse complemented: {os.path.basename(output_fastq_path)}\")\n",
    "\n",
    "# --------------------------------------\n",
    "# ì „ì²´ íŒŒì¼ì— ëŒ€í•´ reverse complement ìˆ˜í–‰\n",
    "# --------------------------------------\n",
    "\n",
    "input_folder = \"fastq_7_8_9_10_11_12/D_split_reads\"\n",
    "os.makedirs(input_folder, exist_ok=True)\n",
    "\n",
    "# _R2_B.fastq.gz ë˜ëŠ” _R2_F.fastq.gzë¡œ ëë‚˜ëŠ” íŒŒì¼ë§Œ ì°¾ê¸°\n",
    "input_files = glob.glob(os.path.join(input_folder, \"*_R2_[BF].fastq.gz\"))\n",
    "\n",
    "for input_path in input_files:\n",
    "    base = os.path.basename(input_path)\n",
    "    name_without_ext = base.replace(\".fastq.gz\", \"\")  # .fastq.gz ì œê±°\n",
    "    output_path = os.path.join(input_folder, f\"{name_without_ext}_revcomp.fastq.gz\")\n",
    "    \n",
    "    reverse_complement_fastq(input_path, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d5cee727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Found 5 R1_B files.\n",
      "ğŸ”µ Running FLASH for sample: 250910_batch20_07step (N=144)\n",
      "[FLASH] Starting FLASH v1.2.11\n",
      "[FLASH] Fast Length Adjustment of SHort reads\n",
      "[FLASH]  \n",
      "[FLASH] Input files:\n",
      "[FLASH]     fastq_7_8_9_10_11_12/D_split_reads/250910_batch20_07step_R1_B.fastq.gz\n",
      "[FLASH]     fastq_7_8_9_10_11_12/D_split_reads/250910_batch20_07step_R2_B.fastq.gz\n",
      "[FLASH]  \n",
      "[FLASH] Output files:\n",
      "[FLASH]     fastq_7_8_9_10_11_12/E_merged_output/250910_batch20_07step_FLASH.extendedFrags.fastq\n",
      "[FLASH]     fastq_7_8_9_10_11_12/E_merged_output/250910_batch20_07step_FLASH.notCombined_1.fastq\n",
      "[FLASH]     fastq_7_8_9_10_11_12/E_merged_output/250910_batch20_07step_FLASH.notCombined_2.fastq\n",
      "[FLASH]     fastq_7_8_9_10_11_12/E_merged_output/250910_batch20_07step_FLASH.hist\n",
      "[FLASH]     fastq_7_8_9_10_11_12/E_merged_output/250910_batch20_07step_FLASH.histogram\n",
      "[FLASH]  \n",
      "[FLASH] Parameters:\n",
      "[FLASH]     Min overlap:           144\n",
      "[FLASH]     Max overlap:           144\n",
      "[FLASH]     Max mismatch density:  0.250000\n",
      "[FLASH]     Allow \"outie\" pairs:   false\n",
      "[FLASH]     Cap mismatch quals:    false\n",
      "[FLASH]     Combiner threads:      4\n",
      "[FLASH]     Input format:          FASTQ, phred_offset=33\n",
      "[FLASH]     Output format:         FASTQ, phred_offset=33\n",
      "[FLASH]  \n",
      "[FLASH] Starting reader and writer threads\n",
      "[FLASH] Starting 4 combiner threads\n",
      "[FLASH] Processed 814 read pairs\n",
      "[FLASH]  \n",
      "[FLASH] Read combination statistics:\n",
      "[FLASH]     Total pairs:      814\n",
      "[FLASH]     Combined pairs:   437\n",
      "[FLASH]     Uncombined pairs: 377\n",
      "[FLASH]     Percent combined: 53.69%\n",
      "[FLASH]  \n",
      "[FLASH] Writing histogram files.\n",
      "[FLASH]  \n",
      "[FLASH] FLASH v1.2.11 complete!\n",
      "[FLASH] 0.032 seconds elapsed\n",
      "âœ… FLASH merging complete â†’ fastq_7_8_9_10_11_12/E_merged_output/250910_batch20_07step_FLASH.fastq\n",
      "ğŸ”µ Running FLASH for sample: 250905_batch19_08step (N=124)\n",
      "[FLASH] Starting FLASH v1.2.11\n",
      "[FLASH] Fast Length Adjustment of SHort reads\n",
      "[FLASH]  \n",
      "[FLASH] Input files:\n",
      "[FLASH]     fastq_7_8_9_10_11_12/D_split_reads/250905_batch19_08step_R1_B.fastq.gz\n",
      "[FLASH]     fastq_7_8_9_10_11_12/D_split_reads/250905_batch19_08step_R2_B.fastq.gz\n",
      "[FLASH]  \n",
      "[FLASH] Output files:\n",
      "[FLASH]     fastq_7_8_9_10_11_12/E_merged_output/250905_batch19_08step_FLASH.extendedFrags.fastq\n",
      "[FLASH]     fastq_7_8_9_10_11_12/E_merged_output/250905_batch19_08step_FLASH.notCombined_1.fastq\n",
      "[FLASH]     fastq_7_8_9_10_11_12/E_merged_output/250905_batch19_08step_FLASH.notCombined_2.fastq\n",
      "[FLASH]     fastq_7_8_9_10_11_12/E_merged_output/250905_batch19_08step_FLASH.hist\n",
      "[FLASH]     fastq_7_8_9_10_11_12/E_merged_output/250905_batch19_08step_FLASH.histogram\n",
      "[FLASH]  \n",
      "[FLASH] Parameters:\n",
      "[FLASH]     Min overlap:           124\n",
      "[FLASH]     Max overlap:           124\n",
      "[FLASH]     Max mismatch density:  0.250000\n",
      "[FLASH]     Allow \"outie\" pairs:   false\n",
      "[FLASH]     Cap mismatch quals:    false\n",
      "[FLASH]     Combiner threads:      4\n",
      "[FLASH]     Input format:          FASTQ, phred_offset=33\n",
      "[FLASH]     Output format:         FASTQ, phred_offset=33\n",
      "[FLASH]  \n",
      "[FLASH] Starting reader and writer threads\n",
      "[FLASH] Starting 4 combiner threads\n",
      "[FLASH] Processed 839 read pairs\n",
      "[FLASH]  \n",
      "[FLASH] Read combination statistics:\n",
      "[FLASH]     Total pairs:      839\n",
      "[FLASH]     Combined pairs:   290\n",
      "[FLASH]     Uncombined pairs: 549\n",
      "[FLASH]     Percent combined: 34.56%\n",
      "[FLASH]  \n",
      "[FLASH] Writing histogram files.\n",
      "[FLASH]  \n",
      "[FLASH] FLASH v1.2.11 complete!\n",
      "[FLASH] 0.026 seconds elapsed\n",
      "âœ… FLASH merging complete â†’ fastq_7_8_9_10_11_12/E_merged_output/250905_batch19_08step_FLASH.fastq\n",
      "ğŸ”µ Running FLASH for sample: 250910_batch20_10step (N=82)\n",
      "[FLASH] Starting FLASH v1.2.11\n",
      "[FLASH] Fast Length Adjustment of SHort reads\n",
      "[FLASH]  \n",
      "[FLASH] Input files:\n",
      "[FLASH]     fastq_7_8_9_10_11_12/D_split_reads/250910_batch20_10step_R1_B.fastq.gz\n",
      "[FLASH]     fastq_7_8_9_10_11_12/D_split_reads/250910_batch20_10step_R2_B.fastq.gz\n",
      "[FLASH]  \n",
      "[FLASH] Output files:\n",
      "[FLASH]     fastq_7_8_9_10_11_12/E_merged_output/250910_batch20_10step_FLASH.extendedFrags.fastq\n",
      "[FLASH]     fastq_7_8_9_10_11_12/E_merged_output/250910_batch20_10step_FLASH.notCombined_1.fastq\n",
      "[FLASH]     fastq_7_8_9_10_11_12/E_merged_output/250910_batch20_10step_FLASH.notCombined_2.fastq\n",
      "[FLASH]     fastq_7_8_9_10_11_12/E_merged_output/250910_batch20_10step_FLASH.hist\n",
      "[FLASH]     fastq_7_8_9_10_11_12/E_merged_output/250910_batch20_10step_FLASH.histogram\n",
      "[FLASH]  \n",
      "[FLASH] Parameters:\n",
      "[FLASH]     Min overlap:           82\n",
      "[FLASH]     Max overlap:           82\n",
      "[FLASH]     Max mismatch density:  0.250000\n",
      "[FLASH]     Allow \"outie\" pairs:   false\n",
      "[FLASH]     Cap mismatch quals:    false\n",
      "[FLASH]     Combiner threads:      4\n",
      "[FLASH]     Input format:          FASTQ, phred_offset=33\n",
      "[FLASH]     Output format:         FASTQ, phred_offset=33\n",
      "[FLASH]  \n",
      "[FLASH] Starting reader and writer threads\n",
      "[FLASH] Starting 4 combiner threads\n",
      "[FLASH] Processed 349 read pairs\n",
      "[FLASH]  \n",
      "[FLASH] Read combination statistics:\n",
      "[FLASH]     Total pairs:      349\n",
      "[FLASH]     Combined pairs:   44\n",
      "[FLASH]     Uncombined pairs: 305\n",
      "[FLASH]     Percent combined: 12.61%\n",
      "[FLASH]  \n",
      "[FLASH] Writing histogram files.\n",
      "[FLASH]  \n",
      "[FLASH] FLASH v1.2.11 complete!\n",
      "[FLASH] 0.019 seconds elapsed\n",
      "âœ… FLASH merging complete â†’ fastq_7_8_9_10_11_12/E_merged_output/250910_batch20_10step_FLASH.fastq\n",
      "ğŸ”µ Running FLASH for sample: 250910_batch20_09step (N=102)\n",
      "[FLASH] Starting FLASH v1.2.11\n",
      "[FLASH] Fast Length Adjustment of SHort reads\n",
      "[FLASH]  \n",
      "[FLASH] Input files:\n",
      "[FLASH]     fastq_7_8_9_10_11_12/D_split_reads/250910_batch20_09step_R1_B.fastq.gz\n",
      "[FLASH]     fastq_7_8_9_10_11_12/D_split_reads/250910_batch20_09step_R2_B.fastq.gz\n",
      "[FLASH]  \n",
      "[FLASH] Output files:\n",
      "[FLASH]     fastq_7_8_9_10_11_12/E_merged_output/250910_batch20_09step_FLASH.extendedFrags.fastq\n",
      "[FLASH]     fastq_7_8_9_10_11_12/E_merged_output/250910_batch20_09step_FLASH.notCombined_1.fastq\n",
      "[FLASH]     fastq_7_8_9_10_11_12/E_merged_output/250910_batch20_09step_FLASH.notCombined_2.fastq\n",
      "[FLASH]     fastq_7_8_9_10_11_12/E_merged_output/250910_batch20_09step_FLASH.hist\n",
      "[FLASH]     fastq_7_8_9_10_11_12/E_merged_output/250910_batch20_09step_FLASH.histogram\n",
      "[FLASH]  \n",
      "[FLASH] Parameters:\n",
      "[FLASH]     Min overlap:           102\n",
      "[FLASH]     Max overlap:           102\n",
      "[FLASH]     Max mismatch density:  0.250000\n",
      "[FLASH]     Allow \"outie\" pairs:   false\n",
      "[FLASH]     Cap mismatch quals:    false\n",
      "[FLASH]     Combiner threads:      4\n",
      "[FLASH]     Input format:          FASTQ, phred_offset=33\n",
      "[FLASH]     Output format:         FASTQ, phred_offset=33\n",
      "[FLASH]  \n",
      "[FLASH] Starting reader and writer threads\n",
      "[FLASH] Starting 4 combiner threads\n",
      "[FLASH] Processed 605 read pairs\n",
      "[FLASH]  \n",
      "[FLASH] Read combination statistics:\n",
      "[FLASH]     Total pairs:      605\n",
      "[FLASH]     Combined pairs:   161\n",
      "[FLASH]     Uncombined pairs: 444\n",
      "[FLASH]     Percent combined: 26.61%\n",
      "[FLASH]  \n",
      "[FLASH] Writing histogram files.\n",
      "[FLASH]  \n",
      "[FLASH] FLASH v1.2.11 complete!\n",
      "[FLASH] 0.020 seconds elapsed\n",
      "âœ… FLASH merging complete â†’ fastq_7_8_9_10_11_12/E_merged_output/250910_batch20_09step_FLASH.fastq\n",
      "ğŸ”µ Running FLASH for sample: 250910_batch20_08step (N=124)\n",
      "[FLASH] Starting FLASH v1.2.11\n",
      "[FLASH] Fast Length Adjustment of SHort reads\n",
      "[FLASH]  \n",
      "[FLASH] Input files:\n",
      "[FLASH]     fastq_7_8_9_10_11_12/D_split_reads/250910_batch20_08step_R1_B.fastq.gz\n",
      "[FLASH]     fastq_7_8_9_10_11_12/D_split_reads/250910_batch20_08step_R2_B.fastq.gz\n",
      "[FLASH]  \n",
      "[FLASH] Output files:\n",
      "[FLASH]     fastq_7_8_9_10_11_12/E_merged_output/250910_batch20_08step_FLASH.extendedFrags.fastq\n",
      "[FLASH]     fastq_7_8_9_10_11_12/E_merged_output/250910_batch20_08step_FLASH.notCombined_1.fastq\n",
      "[FLASH]     fastq_7_8_9_10_11_12/E_merged_output/250910_batch20_08step_FLASH.notCombined_2.fastq\n",
      "[FLASH]     fastq_7_8_9_10_11_12/E_merged_output/250910_batch20_08step_FLASH.hist\n",
      "[FLASH]     fastq_7_8_9_10_11_12/E_merged_output/250910_batch20_08step_FLASH.histogram\n",
      "[FLASH]  \n",
      "[FLASH] Parameters:\n",
      "[FLASH]     Min overlap:           124\n",
      "[FLASH]     Max overlap:           124\n",
      "[FLASH]     Max mismatch density:  0.250000\n",
      "[FLASH]     Allow \"outie\" pairs:   false\n",
      "[FLASH]     Cap mismatch quals:    false\n",
      "[FLASH]     Combiner threads:      4\n",
      "[FLASH]     Input format:          FASTQ, phred_offset=33\n",
      "[FLASH]     Output format:         FASTQ, phred_offset=33\n",
      "[FLASH]  \n",
      "[FLASH] Starting reader and writer threads\n",
      "[FLASH] Starting 4 combiner threads\n",
      "[FLASH] Processed 590 read pairs\n",
      "[FLASH]  \n",
      "[FLASH] Read combination statistics:\n",
      "[FLASH]     Total pairs:      590\n",
      "[FLASH]     Combined pairs:   127\n",
      "[FLASH]     Uncombined pairs: 463\n",
      "[FLASH]     Percent combined: 21.53%\n",
      "[FLASH]  \n",
      "[FLASH] Writing histogram files.\n",
      "[FLASH]  \n",
      "[FLASH] FLASH v1.2.11 complete!\n",
      "[FLASH] 0.026 seconds elapsed\n",
      "âœ… FLASH merging complete â†’ fastq_7_8_9_10_11_12/E_merged_output/250910_batch20_08step_FLASH.fastq\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import subprocess\n",
    "\n",
    "# === í´ë” ì„¤ì • ===\n",
    "input_folder = \"fastq_7_8_9_10_11_12/D_split_reads\"\n",
    "output_folder = \"fastq_7_8_9_10_11_12/E_merged_output\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# === Prefixë³„ Nê°’ ì„¤ì • ===\n",
    "sample_n_mapping = {\n",
    "    \"07step\": 144,\n",
    "    \"08step\": 124,\n",
    "    \"09step\": 102,\n",
    "    \"10step\": 82,\n",
    "    \"11step\": 60,\n",
    "    \"12step\": 40, \n",
    "}\n",
    "\n",
    "# === R1_B íŒŒì¼ ë¦¬ìŠ¤íŠ¸ ì°¾ê¸° ===\n",
    "r1_files = glob.glob(os.path.join(input_folder, \"*_R1_B.fastq.gz\"))\n",
    "\n",
    "print(f\"ğŸ” Found {len(r1_files)} R1_B files.\")\n",
    "\n",
    "# === ê° R1_B íŒŒì¼ì— ëŒ€í•´ ===\n",
    "for r1_path in r1_files:\n",
    "    sample_base = os.path.basename(r1_path).replace(\"_R1_B.fastq.gz\", \"\")\n",
    "    r2_path = os.path.join(input_folder, f\"{sample_base}_R2_B.fastq.gz\")\n",
    "\n",
    "    if not os.path.exists(r2_path):\n",
    "        print(f\"âš ï¸ Matching R2_B file not found for {sample_base} â†’ Skipping.\")\n",
    "        continue\n",
    "\n",
    "    # íŒŒì¼ ì´ë¦„ì— ë§ëŠ” Nê°’ ì°¾ê¸°\n",
    "    matched_n = None\n",
    "    for prefix, n_value in sample_n_mapping.items():\n",
    "        if prefix in sample_base:\n",
    "            matched_n = n_value\n",
    "            break\n",
    "\n",
    "    if matched_n is None:\n",
    "        print(f\"âš ï¸ No N value matched for {sample_base} â†’ Skipping.\")\n",
    "        continue\n",
    "\n",
    "    output_name = f\"{sample_base}_FLASH\"\n",
    "\n",
    "    print(f\"ğŸ”µ Running FLASH for sample: {sample_base} (N={matched_n})\")\n",
    "\n",
    "    try:\n",
    "        subprocess.check_call([\n",
    "            \"flash\",\n",
    "            \"-m\", str(matched_n),   # ìµœì†Œ overlap\n",
    "            \"-M\", str(matched_n),   # ìµœëŒ€ overlap\n",
    "            \"-o\", output_name,      # ê²°ê³¼ íŒŒì¼ prefix\n",
    "            \"-d\", output_folder,    # ê²°ê³¼ ì €ì¥ í´ë”\n",
    "            r1_path,\n",
    "            r2_path\n",
    "        ])\n",
    "        print(f\"âœ… FLASH merging complete â†’ {os.path.join(output_folder, output_name)}.fastq\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"âŒ FLASH merging failed for {sample_base}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "32be38d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Found 5 merged samples to assemble.\n",
      "ğŸ”„ Assembling for sample: 250910_batch20_08step_assemble.fastq.gz\n",
      "âœ… Assembled FASTQ saved: fastq_7_8_9_10_11_12/1_assemble/250910_batch20_08step_assemble.fastq.gz\n",
      "ğŸ”„ Assembling for sample: 250910_batch20_07step_assemble.fastq.gz\n",
      "âœ… Assembled FASTQ saved: fastq_7_8_9_10_11_12/1_assemble/250910_batch20_07step_assemble.fastq.gz\n",
      "ğŸ”„ Assembling for sample: 250905_batch19_08step_assemble.fastq.gz\n",
      "âœ… Assembled FASTQ saved: fastq_7_8_9_10_11_12/1_assemble/250905_batch19_08step_assemble.fastq.gz\n",
      "ğŸ”„ Assembling for sample: 250910_batch20_09step_assemble.fastq.gz\n",
      "âœ… Assembled FASTQ saved: fastq_7_8_9_10_11_12/1_assemble/250910_batch20_09step_assemble.fastq.gz\n",
      "ğŸ”„ Assembling for sample: 250910_batch20_10step_assemble.fastq.gz\n",
      "âœ… Assembled FASTQ saved: fastq_7_8_9_10_11_12/1_assemble/250910_batch20_10step_assemble.fastq.gz\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gzip\n",
    "import glob\n",
    "from Bio import SeqIO\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "\n",
    "def load_fastq_to_dict(file_path):\n",
    "    \"\"\"FASTQ íŒŒì¼ì„ dictë¡œ ë¶ˆëŸ¬ì˜¤ê¸°: key=read_id, value=(seq, qual)\"\"\"\n",
    "    data = {}\n",
    "    open_func = gzip.open if file_path.endswith(\".gz\") else open\n",
    "\n",
    "    with open_func(file_path, \"rt\") as handle:\n",
    "        for record in SeqIO.parse(handle, \"fastq\"):\n",
    "            seq = str(record.seq)\n",
    "            qual = record.letter_annotations[\"phred_quality\"]\n",
    "            data[record.id] = (seq, qual)\n",
    "    return data\n",
    "\n",
    "def assemble_fastq(r1_path, merged_path, r2_path, output_path):\n",
    "    print(f\"ğŸ”„ Assembling for sample: {os.path.basename(output_path)}\")\n",
    "    r1_dict = load_fastq_to_dict(r1_path)\n",
    "    r2_dict = load_fastq_to_dict(r2_path)\n",
    "\n",
    "    with open(merged_path, \"r\") as merged_file, gzip.open(output_path, \"wt\") as output_file:\n",
    "        for record in SeqIO.parse(merged_file, \"fastq\"):\n",
    "            read_id = record.id\n",
    "            merged_seq = str(record.seq)\n",
    "            merged_qual = record.letter_annotations[\"phred_quality\"]\n",
    "\n",
    "            if read_id not in r1_dict or read_id not in r2_dict:\n",
    "                continue  # ë‘˜ ë‹¤ ìˆì–´ì•¼ í•©ì¹¨\n",
    "\n",
    "            r1_seq, r1_qual = r1_dict[read_id]\n",
    "            r2_seq, r2_qual = r2_dict[read_id]\n",
    "\n",
    "            # ìˆœì„œëŒ€ë¡œ ì´ì–´ë¶™ì´ê¸°: R1_F â†’ FLASH â†’ R2_F_revcomp\n",
    "            full_seq = r1_seq + merged_seq + r2_seq\n",
    "            full_qual = r1_qual + merged_qual + r2_qual\n",
    "\n",
    "            new_record = SeqRecord(\n",
    "                Seq(full_seq),\n",
    "                id=read_id,\n",
    "                description=\"\",\n",
    "                letter_annotations={\"phred_quality\": full_qual}\n",
    "            )\n",
    "\n",
    "            SeqIO.write(new_record, output_file, \"fastq\")\n",
    "\n",
    "    print(f\"âœ… Assembled FASTQ saved: {output_path}\")\n",
    "\n",
    "# ===== ì „ì²´ ì²˜ë¦¬ ìë™í™” =====\n",
    "\n",
    "# ê²½ë¡œ ì„¤ì •\n",
    "input_merged_folder = \"fastq_7_8_9_10_11_12/E_merged_output\"\n",
    "input_split_folder = \"fastq_7_8_9_10_11_12/D_split_reads\"\n",
    "output_folder = \"fastq_7_8_9_10_11_12/1_assemble\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# ëª¨ë“  merged íŒŒì¼ ë¦¬ìŠ¤íŠ¸\n",
    "merged_files = glob.glob(os.path.join(input_merged_folder, \"*_FLASH.extendedFrags.fastq\"))\n",
    "\n",
    "print(f\"ğŸ” Found {len(merged_files)} merged samples to assemble.\")\n",
    "\n",
    "for merged_file in merged_files:\n",
    "    sample_base = os.path.basename(merged_file).replace(\"_FLASH.extendedFrags.fastq\", \"\")\n",
    "\n",
    "    r1_path = os.path.join(input_split_folder, f\"{sample_base}_R1_F.fastq.gz\")\n",
    "    r2_path = os.path.join(input_split_folder, f\"{sample_base}_R2_F_revcomp.fastq.gz\")\n",
    "    output_path = os.path.join(output_folder, f\"{sample_base}_assemble.fastq.gz\")\n",
    "\n",
    "    if os.path.exists(r1_path) and os.path.exists(r2_path):\n",
    "        assemble_fastq(r1_path, merged_file, r2_path, output_path)\n",
    "    else:\n",
    "        print(f\"âš ï¸ Missing split files for {sample_base}, skipping.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e38b8fc4",
   "metadata": {},
   "source": [
    "# Convert fastq â” csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d9d1ad29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Converted: 250910_batch20_07step_assemble.fastq.gz â†’ 250910_batch20_07step_assemble.csv\n",
      "âœ… Converted: 250910_batch20_09step_assemble.fastq.gz â†’ 250910_batch20_09step_assemble.csv\n",
      "âœ… Converted: 250910_batch20_10step_assemble.fastq.gz â†’ 250910_batch20_10step_assemble.csv\n",
      "âœ… Converted: 250905_batch19_08step_assemble.fastq.gz â†’ 250905_batch19_08step_assemble.csv\n",
      "âœ… Converted: 250910_batch20_08step_assemble.fastq.gz â†’ 250910_batch20_08step_assemble.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gzip\n",
    "import pandas as pd\n",
    "from Bio import SeqIO\n",
    "\n",
    "def fastq_to_csv(fastq_path, csv_path):\n",
    "    data = []\n",
    "\n",
    "    # .gz í™•ì¥ì ì—¬ë¶€ì— ë”°ë¼ open ë°©ì‹ ì„ íƒ\n",
    "    open_func = gzip.open if fastq_path.endswith(\".gz\") else open\n",
    "\n",
    "    with open_func(fastq_path, \"rt\") as handle:\n",
    "        for record in SeqIO.parse(handle, \"fastq\"):\n",
    "            read_id = record.id\n",
    "            sequence = str(record.seq)\n",
    "            quality = \"\".join(chr(q + 33) for q in record.letter_annotations[\"phred_quality\"])\n",
    "            data.append([read_id, sequence, quality])\n",
    "\n",
    "    df = pd.DataFrame(data, columns=[\"Read_ID\", \"Sequence\", \"Quality_Score\"])\n",
    "    df.to_csv(csv_path, index=False)\n",
    "    print(f\"âœ… Converted: {os.path.basename(fastq_path)} â†’ {os.path.basename(csv_path)}\")\n",
    "\n",
    "def convert_all_fastq_in_folder(input_folder, output_folder):\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    for filename in os.listdir(input_folder):\n",
    "        if filename.endswith(\".fastq\") or filename.endswith(\".fastq.gz\"):\n",
    "            input_path = os.path.join(input_folder, filename)\n",
    "            csv_filename = filename.replace(\".fastq.gz\", \".csv\").replace(\".fastq\", \".csv\")\n",
    "            output_path = os.path.join(output_folder, csv_filename)\n",
    "\n",
    "            fastq_to_csv(input_path, output_path)\n",
    "\n",
    "# ğŸ“Œ ì‚¬ìš© ì˜ˆì‹œ\n",
    "input_folder = \"fastq_7_8_9_10_11_12/1_assemble\"\n",
    "output_folder = \"fastq_7_8_9_10_11_12/1_assemble/csv\"\n",
    "\n",
    "convert_all_fastq_in_folder(input_folder, output_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66072f7f",
   "metadata": {},
   "source": [
    "# fastq -> fasta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e99c04de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversion from 250910_batch20_07step_assemble.fastq.gz â†’ 250910_batch20_07step_assemble.fasta is complete.\n",
      "Conversion from 250910_batch20_09step_assemble.fastq.gz â†’ 250910_batch20_09step_assemble.fasta is complete.\n",
      "Conversion from 250910_batch20_10step_assemble.fastq.gz â†’ 250910_batch20_10step_assemble.fasta is complete.\n",
      "Conversion from 250905_batch19_08step_assemble.fastq.gz â†’ 250905_batch19_08step_assemble.fasta is complete.\n",
      "Conversion from 250910_batch20_08step_assemble.fastq.gz â†’ 250910_batch20_08step_assemble.fasta is complete.\n",
      "All conversions are done.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gzip\n",
    "from Bio import SeqIO\n",
    "\n",
    "# í•„í„°ë§ëœ FASTQ.GZ íŒŒì¼ì´ ìœ„ì¹˜í•œ í´ë”\n",
    "# ë³€í™˜ëœ FASTA íŒŒì¼ì„ ì €ì¥í•  í´ë”\n",
    "\n",
    "input_folder = \"fastq_7_8_9_10_11_12/1_assemble\"\n",
    "output_folder = \"fastq_7_8_9_10_11_12/2_fastq_to_fasta\"\n",
    "os.makedirs(output_folder, exist_ok=True)  # ì¶œë ¥ í´ë” ìƒì„±\n",
    "\n",
    "for filename in os.listdir(input_folder):\n",
    "    # ì˜ˆ: \"_filtered.fastq.gz\"ë¡œ ëë‚˜ëŠ” íŒŒì¼ë§Œ ë³€í™˜\n",
    "    if filename.endswith(\"_assemble.fastq.gz\"):\n",
    "        # ì…ë ¥ FASTQ.GZ íŒŒì¼ ê²½ë¡œ\n",
    "        input_file = os.path.join(input_folder, filename)\n",
    "        \n",
    "        # ì¶œë ¥ FASTA íŒŒì¼ ê²½ë¡œ (í™•ì¥ìë§Œ .fastaë¡œ ë³€ê²½)\n",
    "        output_file = os.path.join(\n",
    "            output_folder,\n",
    "            filename.replace(\"_assemble.fastq.gz\", \"_assemble.fasta\")\n",
    "        )\n",
    "\n",
    "        # FASTQ.GZ íŒŒì¼ì„ ì½ì–´ì„œ FASTAë¡œ ë³€í™˜\n",
    "        records = []\n",
    "        with gzip.open(input_file, \"rt\") as fastq_file:  # \"rt\" = read text mode\n",
    "            for record in SeqIO.parse(fastq_file, \"fastq\"):\n",
    "                records.append(record)\n",
    "\n",
    "        # ë³€í™˜ëœ ì‹œí€€ìŠ¤ë¥¼ FASTAë¡œ ì €ì¥\n",
    "        with open(output_file, \"w\") as fasta_file:\n",
    "            SeqIO.write(records, fasta_file, \"fasta\")\n",
    "\n",
    "        print(f\"Conversion from {filename} â†’ {os.path.basename(output_file)} is complete.\")\n",
    "\n",
    "print(\"All conversions are done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679101a1",
   "metadata": {},
   "source": [
    "# Answer sequence - Sample matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "98bf7bd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”„ Aligning: 250905_batch19_08step_assemble.fasta â†’ 08step_reference.fasta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[bwa_index] Pack FASTA... 0.00 sec\n",
      "[bwa_index] Construct BWT for the packed sequence...\n",
      "[bwa_index] 0.00 seconds elapse.\n",
      "[bwa_index] Update BWT... 0.00 sec\n",
      "[bwa_index] Pack forward-only FASTA... 0.00 sec\n",
      "[bwa_index] Construct SA from BWT and Occ... 0.00 sec\n",
      "[main] Version: 0.7.17-r1188\n",
      "[main] CMD: bwa index step_reference/08step_reference.fasta\n",
      "[main] Real time: 0.073 sec; CPU: 0.011 sec\n",
      "[M::bwa_idx_load_from_disk] read 0 ALT contigs\n",
      "[M::process] read 290 sequences (51620 bp)...\n",
      "[M::mem_process_seqs] Processed 290 reads in 0.113 CPU sec, 0.041 real sec\n",
      "[main] Version: 0.7.17-r1188\n",
      "[main] CMD: bwa mem -M -t 4 step_reference/08step_reference.fasta fastq_7_8_9_10_11_12/2_fastq_to_fasta/250905_batch19_08step_assemble.fasta\n",
      "[main] Real time: 0.076 sec; CPU: 0.118 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Done: fastq_7_8_9_10_11_12/3_align_sam/250905_batch19_08step_assemble.sam\n",
      "ğŸ”„ Aligning: 250910_batch20_07step_assemble.fasta â†’ 07step_reference.fasta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[bwa_index] Pack FASTA... 0.00 sec\n",
      "[bwa_index] Construct BWT for the packed sequence...\n",
      "[bwa_index] 0.00 seconds elapse.\n",
      "[bwa_index] Update BWT... 0.00 sec\n",
      "[bwa_index] Pack forward-only FASTA... 0.00 sec\n",
      "[bwa_index] Construct SA from BWT and Occ... 0.00 sec\n",
      "[main] Version: 0.7.17-r1188\n",
      "[main] CMD: bwa index step_reference/07step_reference.fasta\n",
      "[main] Real time: 0.052 sec; CPU: 0.006 sec\n",
      "[M::bwa_idx_load_from_disk] read 0 ALT contigs\n",
      "[M::process] read 437 sequences (69046 bp)...\n",
      "[M::mem_process_seqs] Processed 437 reads in 0.101 CPU sec, 0.037 real sec\n",
      "[main] Version: 0.7.17-r1188\n",
      "[main] CMD: bwa mem -M -t 4 step_reference/07step_reference.fasta fastq_7_8_9_10_11_12/2_fastq_to_fasta/250910_batch20_07step_assemble.fasta\n",
      "[main] Real time: 0.073 sec; CPU: 0.105 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Done: fastq_7_8_9_10_11_12/3_align_sam/250910_batch20_07step_assemble.sam\n",
      "ğŸ”„ Aligning: 250910_batch20_08step_assemble.fasta â†’ 08step_reference.fasta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[M::bwa_idx_load_from_disk] read 0 ALT contigs\n",
      "[M::process] read 127 sequences (22606 bp)...\n",
      "[M::mem_process_seqs] Processed 127 reads in 0.033 CPU sec, 0.014 real sec\n",
      "[main] Version: 0.7.17-r1188\n",
      "[main] CMD: bwa mem -M -t 4 step_reference/08step_reference.fasta fastq_7_8_9_10_11_12/2_fastq_to_fasta/250910_batch20_08step_assemble.fasta\n",
      "[main] Real time: 0.039 sec; CPU: 0.037 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Done: fastq_7_8_9_10_11_12/3_align_sam/250910_batch20_08step_assemble.sam\n",
      "ğŸ”„ Aligning: 250910_batch20_09step_assemble.fasta â†’ 09step_reference.fasta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[bwa_index] Pack FASTA... 0.00 sec\n",
      "[bwa_index] Construct BWT for the packed sequence...\n",
      "[bwa_index] 0.01 seconds elapse.\n",
      "[bwa_index] Update BWT... 0.00 sec\n",
      "[bwa_index] Pack forward-only FASTA... 0.00 sec\n",
      "[bwa_index] Construct SA from BWT and Occ... 0.00 sec\n",
      "[main] Version: 0.7.17-r1188\n",
      "[main] CMD: bwa index step_reference/09step_reference.fasta\n",
      "[main] Real time: 0.083 sec; CPU: 0.016 sec\n",
      "[M::bwa_idx_load_from_disk] read 0 ALT contigs\n",
      "[M::process] read 161 sequences (32200 bp)...\n",
      "[M::mem_process_seqs] Processed 161 reads in 0.261 CPU sec, 0.083 real sec\n",
      "[main] Version: 0.7.17-r1188\n",
      "[main] CMD: bwa mem -M -t 4 step_reference/09step_reference.fasta fastq_7_8_9_10_11_12/2_fastq_to_fasta/250910_batch20_09step_assemble.fasta\n",
      "[main] Real time: 0.120 sec; CPU: 0.266 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Done: fastq_7_8_9_10_11_12/3_align_sam/250910_batch20_09step_assemble.sam\n",
      "ğŸ”„ Aligning: 250910_batch20_10step_assemble.fasta â†’ 10step_reference.fasta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[bwa_index] Pack FASTA... 0.00 sec\n",
      "[bwa_index] Construct BWT for the packed sequence...\n",
      "[bwa_index] 0.01 seconds elapse.\n",
      "[bwa_index] Update BWT... 0.00 sec\n",
      "[bwa_index] Pack forward-only FASTA... 0.00 sec\n",
      "[bwa_index] Construct SA from BWT and Occ... 0.01 sec\n",
      "[main] Version: 0.7.17-r1188\n",
      "[main] CMD: bwa index step_reference/10step_reference.fasta\n",
      "[main] Real time: 0.114 sec; CPU: 0.029 sec\n",
      "[M::bwa_idx_load_from_disk] read 0 ALT contigs\n",
      "[M::process] read 44 sequences (9680 bp)...\n",
      "[M::mem_process_seqs] Processed 44 reads in 0.109 CPU sec, 0.035 real sec\n",
      "[main] Version: 0.7.17-r1188\n",
      "[main] CMD: bwa mem -M -t 4 step_reference/10step_reference.fasta fastq_7_8_9_10_11_12/2_fastq_to_fasta/250910_batch20_10step_assemble.fasta\n",
      "[main] Real time: 0.075 sec; CPU: 0.114 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Done: fastq_7_8_9_10_11_12/3_align_sam/250910_batch20_10step_assemble.sam\n",
      "ğŸ”„ Aligning: 250905_batch19_08step_assemble.fasta â†’ 08step_reference.fasta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[M::bwa_idx_load_from_disk] read 0 ALT contigs\n",
      "[M::process] read 290 sequences (51620 bp)...\n",
      "[M::mem_process_seqs] Processed 290 reads in 0.112 CPU sec, 0.037 real sec\n",
      "[main] Version: 0.7.17-r1188\n",
      "[main] CMD: bwa mem -M -t 4 step_reference/08step_reference.fasta fastq_7_8_9_10_11_12/2_fastq_to_fasta/250905_batch19_08step_assemble.fasta\n",
      "[main] Real time: 0.074 sec; CPU: 0.116 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Done: fastq_7_8_9_10_11_12/3_align_sam/250905_batch19_08step_assemble.sam\n",
      "ğŸ”„ Aligning: 250910_batch20_07step_assemble.fasta â†’ 07step_reference.fasta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[M::bwa_idx_load_from_disk] read 0 ALT contigs\n",
      "[M::process] read 437 sequences (69046 bp)...\n",
      "[M::mem_process_seqs] Processed 437 reads in 0.111 CPU sec, 0.036 real sec\n",
      "[main] Version: 0.7.17-r1188\n",
      "[main] CMD: bwa mem -M -t 4 step_reference/07step_reference.fasta fastq_7_8_9_10_11_12/2_fastq_to_fasta/250910_batch20_07step_assemble.fasta\n",
      "[main] Real time: 0.063 sec; CPU: 0.115 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Done: fastq_7_8_9_10_11_12/3_align_sam/250910_batch20_07step_assemble.sam\n",
      "ğŸ”„ Aligning: 250910_batch20_08step_assemble.fasta â†’ 08step_reference.fasta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[M::bwa_idx_load_from_disk] read 0 ALT contigs\n",
      "[M::process] read 127 sequences (22606 bp)...\n",
      "[M::mem_process_seqs] Processed 127 reads in 0.035 CPU sec, 0.018 real sec\n",
      "[main] Version: 0.7.17-r1188\n",
      "[main] CMD: bwa mem -M -t 4 step_reference/08step_reference.fasta fastq_7_8_9_10_11_12/2_fastq_to_fasta/250910_batch20_08step_assemble.fasta\n",
      "[main] Real time: 0.047 sec; CPU: 0.039 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Done: fastq_7_8_9_10_11_12/3_align_sam/250910_batch20_08step_assemble.sam\n",
      "ğŸ”„ Aligning: 250910_batch20_09step_assemble.fasta â†’ 09step_reference.fasta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[M::bwa_idx_load_from_disk] read 0 ALT contigs\n",
      "[M::process] read 161 sequences (32200 bp)...\n",
      "[M::mem_process_seqs] Processed 161 reads in 0.233 CPU sec, 0.074 real sec\n",
      "[main] Version: 0.7.17-r1188\n",
      "[main] CMD: bwa mem -M -t 4 step_reference/09step_reference.fasta fastq_7_8_9_10_11_12/2_fastq_to_fasta/250910_batch20_09step_assemble.fasta\n",
      "[main] Real time: 0.107 sec; CPU: 0.237 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Done: fastq_7_8_9_10_11_12/3_align_sam/250910_batch20_09step_assemble.sam\n",
      "ğŸ”„ Aligning: 250910_batch20_10step_assemble.fasta â†’ 10step_reference.fasta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[M::bwa_idx_load_from_disk] read 0 ALT contigs\n",
      "[M::process] read 44 sequences (9680 bp)...\n",
      "[M::mem_process_seqs] Processed 44 reads in 0.107 CPU sec, 0.040 real sec\n",
      "[main] Version: 0.7.17-r1188\n",
      "[main] CMD: bwa mem -M -t 4 step_reference/10step_reference.fasta fastq_7_8_9_10_11_12/2_fastq_to_fasta/250910_batch20_10step_assemble.fasta\n",
      "[main] Real time: 0.073 sec; CPU: 0.112 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Done: fastq_7_8_9_10_11_12/3_align_sam/250910_batch20_10step_assemble.sam\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "set -euo pipefail\n",
    "shopt -s nullglob\n",
    "\n",
    "# ë””ë ‰í† ë¦¬ ì„¤ì •\n",
    "ref_dir=\"step_reference\"\n",
    "query_dir=\"fastq_7_8_9_10_11_12/2_fastq_to_fasta\"\n",
    "output_dir=\"fastq_7_8_9_10_11_12/3_align_sam\"\n",
    "mkdir -p \"$output_dir\"\n",
    "\n",
    "# ê°™ì€ ì°¸ì¡°ëŠ” í•œ ë²ˆë§Œ index\n",
    "declare -A indexed\n",
    "\n",
    "# *_07step_assemble.fasta ê°™ì€ ì¼€ì´ìŠ¤ ìš°ì„ , ì—†ìœ¼ë©´ ì¼ë°˜ *_07step_*.fasta ë„ ìˆ˜ì§‘\n",
    "for query_file in \"$query_dir\"/*step*assemble.fasta \"$query_dir\"/*step*.fasta; do\n",
    "  filename=\"$(basename \"$query_file\")\"\n",
    "\n",
    "  # íŒŒì¼ëª…ì—ì„œ ë‘ ìë¦¬ step ì¶”ì¶œ (ì˜ˆ: _07step_, _12step_)\n",
    "  if [[ \"$filename\" =~ _([0-9]{2})step_ ]]; then\n",
    "    step=\"${BASH_REMATCH[1]}\"\n",
    "  else\n",
    "    echo \"âš ï¸ Skipping (no '_NNstep_' pattern): $filename\"\n",
    "    continue\n",
    "  fi\n",
    "\n",
    "  # 07~12ë§Œ ì²˜ë¦¬\n",
    "  case \"$step\" in\n",
    "    07|08|09|10|11|12) ;;\n",
    "    *) echo \"âš ï¸ Skipping (step not in 07â€“12): $filename\"; continue ;;\n",
    "  esac\n",
    "\n",
    "  reference_file=\"${ref_dir}/${step}step_reference.fasta\"\n",
    "  if [[ ! -f \"$reference_file\" ]]; then\n",
    "    echo \"âš ï¸ Missing reference: $reference_file\"\n",
    "    continue\n",
    "  fi\n",
    "\n",
    "  out=\"${output_dir}/${filename%.fasta}.sam\"\n",
    "\n",
    "  echo \"ğŸ”„ Aligning: $filename â†’ $(basename \"$reference_file\")\"\n",
    "  if [[ -z \"${indexed[$reference_file]:-}\" ]]; then\n",
    "    bwa index \"$reference_file\"\n",
    "    indexed[$reference_file]=1\n",
    "  fi\n",
    "\n",
    "  bwa mem -M -t 4 \"$reference_file\" \"$query_file\" > \"$out\"\n",
    "  echo \"âœ… Done: $out\"\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41fdcc51",
   "metadata": {},
   "source": [
    "# sam to bam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d4a6079c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversion from fastq_7_8_9_10_11_12/3_align_sam/250905_batch19_08step_assemble.sam to fastq_7_8_9_10_11_12/4_align_bam/250905_batch19_08step_assemble.bam is complete.\n",
      "Conversion from fastq_7_8_9_10_11_12/3_align_sam/250910_batch20_07step_assemble.sam to fastq_7_8_9_10_11_12/4_align_bam/250910_batch20_07step_assemble.bam is complete.\n",
      "Conversion from fastq_7_8_9_10_11_12/3_align_sam/250910_batch20_08step_assemble.sam to fastq_7_8_9_10_11_12/4_align_bam/250910_batch20_08step_assemble.bam is complete.\n",
      "Conversion from fastq_7_8_9_10_11_12/3_align_sam/250910_batch20_09step_assemble.sam to fastq_7_8_9_10_11_12/4_align_bam/250910_batch20_09step_assemble.bam is complete.\n",
      "Conversion from fastq_7_8_9_10_11_12/3_align_sam/250910_batch20_10step_assemble.sam to fastq_7_8_9_10_11_12/4_align_bam/250910_batch20_10step_assemble.bam is complete.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "# Set the path to the directory containing SAM files\n",
    "sam_dir=\"fastq_7_8_9_10_11_12/3_align_sam\"\n",
    "# Set the output directory for BAM files\n",
    "bam_dir=\"fastq_7_8_9_10_11_12/4_align_bam\"\n",
    "\n",
    "\n",
    "# Make sure the output directory exists or create it if necessary\n",
    "mkdir -p \"$bam_dir\"\n",
    "\n",
    "# Convert SAM files to BAM\n",
    "for sam_file in \"$sam_dir\"/*.sam; do\n",
    "    bam_file=\"$bam_dir/$(basename \"$sam_file\" .sam).bam\"\n",
    "    samtools view -bS \"$sam_file\" -o \"$bam_file\"\n",
    "    echo \"Conversion from $sam_file to $bam_file is complete.\"\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1ff9fb",
   "metadata": {},
   "source": [
    "# bam to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e10dffcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fastq_7_8_9_10_11_12/4_align_bam/csv/250910_batch20_10step_assemble.csv',\n",
       " 'fastq_7_8_9_10_11_12/4_align_bam/csv/250910_batch20_08step_assemble.csv',\n",
       " 'fastq_7_8_9_10_11_12/4_align_bam/csv/250910_batch20_07step_assemble.csv',\n",
       " 'fastq_7_8_9_10_11_12/4_align_bam/csv/250905_batch19_08step_assemble.csv',\n",
       " 'fastq_7_8_9_10_11_12/4_align_bam/csv/250910_batch20_09step_assemble.csv']"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pysam\n",
    "import pandas as pd\n",
    "\n",
    "# ì…ë ¥ í´ë” (BAM íŒŒì¼ì´ ìœ„ì¹˜í•œ ê²½ë¡œ)\n",
    "input_folder = \"fastq_7_8_9_10_11_12/4_align_bam\"\n",
    "# ì¶œë ¥ í´ë” (CSV íŒŒì¼ì„ ì €ì¥í•  ê²½ë¡œ, í•„ìš”í•˜ë©´ ë³€ê²½)\n",
    "output_folder = \"fastq_7_8_9_10_11_12/4_align_bam/csv\"\n",
    "\n",
    "\n",
    "# ì¶œë ¥ í´ë”ê°€ ì—†ìœ¼ë©´ ìƒì„±\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# BAM -> CSV ë³€í™˜ í•¨ìˆ˜ (ì˜µì…˜ í•„ë“œ í¬í•¨)\n",
    "def bam_to_csv(bam_file, output_folder):\n",
    "    output_csv = os.path.join(output_folder, os.path.basename(bam_file).replace(\".bam\", \".csv\"))\n",
    "    \n",
    "    # BAM íŒŒì¼ ì½ê¸°\n",
    "    with pysam.AlignmentFile(bam_file, \"rb\") as bam:\n",
    "        records = []\n",
    "        all_tags = set()  # ì˜µì…˜ í•„ë“œë¥¼ ì €ì¥í•  ì§‘í•©\n",
    "        \n",
    "        for read in bam:\n",
    "            # ê¸°ë³¸ í•„ë“œ\n",
    "            record = {\n",
    "                \"QNAME\": read.query_name,\n",
    "                \"FLAG\": read.flag,\n",
    "                \"RNAME\": bam.get_reference_name(read.reference_id) if read.reference_id >= 0 else \"*\",\n",
    "                \"POS\": read.reference_start + 1,\n",
    "                \"MAPQ\": read.mapping_quality,\n",
    "                \"CIGAR\": read.cigarstring if read.cigarstring else \"*\",\n",
    "                \"RNEXT\": bam.get_reference_name(read.next_reference_id) if read.next_reference_id >= 0 else \"*\",\n",
    "                \"PNEXT\": read.next_reference_start + 1 if read.next_reference_start >= 0 else 0,\n",
    "                \"TLEN\": read.template_length,\n",
    "                \"SEQ\": read.query_sequence if read.query_sequence else \"*\",\n",
    "                \"QUAL\": read.qual if read.qual else \"*\",\n",
    "            }\n",
    "            \n",
    "            # ì˜µì…˜ í•„ë“œ ì¶”ê°€\n",
    "            for tag, value in read.tags:\n",
    "                record[tag] = value\n",
    "                all_tags.add(tag)\n",
    "\n",
    "            records.append(record)\n",
    "    \n",
    "    # ë°ì´í„°í”„ë ˆì„ ìƒì„±\n",
    "    df = pd.DataFrame(records)\n",
    "\n",
    "    # ì˜µì…˜ í•„ë“œê°€ ì—†ëŠ” ê²½ìš° NaNìœ¼ë¡œ ì²˜ë¦¬\n",
    "    df = df.fillna(\"*\")\n",
    "\n",
    "    # CSV ì €ì¥\n",
    "    df.to_csv(output_csv, index=False)\n",
    "    return output_csv\n",
    "\n",
    "# í´ë”ì—ì„œ ëª¨ë“  BAM íŒŒì¼ ì°¾ê¸°\n",
    "bam_files = [os.path.join(input_folder, f) for f in os.listdir(input_folder) if f.endswith(\".bam\")]\n",
    "\n",
    "# ëª¨ë“  BAM íŒŒì¼ì„ CSVë¡œ ë³€í™˜\n",
    "csv_files = []\n",
    "for bam_file in bam_files:\n",
    "    csv_file = bam_to_csv(bam_file, output_folder)\n",
    "    csv_files.append(csv_file)\n",
    "\n",
    "# ë³€í™˜ëœ CSV íŒŒì¼ ëª©ë¡ ì¶œë ¥\n",
    "csv_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c1258073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… 250905_batch19_08step_assemble.csv -> kept=271, removed=19, saved: 250905_batch19_08step_assemble.csv\n",
      "âœ… 250910_batch20_07step_assemble.csv -> kept=425, removed=12, saved: 250910_batch20_07step_assemble.csv\n",
      "âœ… 250910_batch20_08step_assemble.csv -> kept=120, removed=7, saved: 250910_batch20_08step_assemble.csv\n",
      "âœ… 250910_batch20_09step_assemble.csv -> kept=136, removed=25, saved: 250910_batch20_09step_assemble.csv\n",
      "âœ… 250910_batch20_10step_assemble.csv -> kept=27, removed=17, saved: 250910_batch20_10step_assemble.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# ì…ë ¥/ì¶œë ¥ í´ë”\n",
    "csv_dir = Path(\"fastq_7_8_9_10_11_12/4_align_bam/csv\")\n",
    "out_dir = csv_dir / \"MAPQ_removed\"\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ===== ì„ê³„ê°’ (ì´í•˜ â‰¤ ëŠ” ì œê±°) =====\n",
    "MAPQ_THRESHOLD = 10\n",
    "# =================================\n",
    "\n",
    "for in_path in sorted(csv_dir.glob(\"*.csv\")):\n",
    "    try:\n",
    "        df = pd.read_csv(in_path)\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸  Read fail: {in_path.name} -> {e}\")\n",
    "        continue\n",
    "\n",
    "    if \"MAPQ\" not in df.columns:\n",
    "        print(f\"âš ï¸  Skip (no MAPQ column): {in_path.name}\")\n",
    "        continue\n",
    "\n",
    "    m = pd.to_numeric(df[\"MAPQ\"], errors=\"coerce\")\n",
    "    # keep: MAPQ > cutoff (NaNì€ ê¸°ë³¸ì ìœ¼ë¡œ keep; NaNë„ ì œê±°í•˜ë ¤ë©´ .isna() ë¹¼ì„¸ìš”)\n",
    "    keep_mask = (m > MAPQ_THRESHOLD) | m.isna()\n",
    "    kept = int(keep_mask.sum())\n",
    "    removed = int((~keep_mask).sum())\n",
    "\n",
    "    out_path = out_dir / in_path.name\n",
    "    df.loc[keep_mask].to_csv(out_path, index=False)\n",
    "    print(f\"âœ… {in_path.name} -> kept={kept}, removed={removed}, saved: {out_path.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4a0c21",
   "metadata": {},
   "source": [
    "# Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "5c4724b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Saved cleaned RNAME histogram: fastq_7_8_9_10_11_12/5_align_histogram/histogram_250910_batch20_09step_.csv\n",
      "âœ… Saved cleaned RNAME histogram: fastq_7_8_9_10_11_12/5_align_histogram/histogram_250905_batch19_08step_.csv\n",
      "âœ… Saved cleaned RNAME histogram: fastq_7_8_9_10_11_12/5_align_histogram/histogram_250910_batch20_07step_.csv\n",
      "âœ… Saved cleaned RNAME histogram: fastq_7_8_9_10_11_12/5_align_histogram/histogram_250910_batch20_08step_.csv\n",
      "âœ… Saved cleaned RNAME histogram: fastq_7_8_9_10_11_12/5_align_histogram/histogram_250910_batch20_10step_.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# ğŸ“ í´ë” ì„¤ì •\n",
    "input_folder = \"fastq_7_8_9_10_11_12/4_align_bam/csv/MAPQ_removed\"\n",
    "histogram_folder = \"fastq_7_8_9_10_11_12/5_align_histogram\"\n",
    "os.makedirs(histogram_folder, exist_ok=True)\n",
    "\n",
    "# ğŸ“„ ëª¨ë“  CSV íŒŒì¼ ì²˜ë¦¬\n",
    "files = [f for f in os.listdir(input_folder) if f.endswith('.csv')]\n",
    "\n",
    "for file_name in files:\n",
    "    file_path = os.path.join(input_folder, file_name)\n",
    "\n",
    "    # ğŸ”§ íŒŒì¼ëª… í´ë Œì§• (íŠ¹ì • ë¬¸ìì—´ ì œê±°)\n",
    "    clean_name = file_name\n",
    "    clean_name = clean_name.replace(\"assemble\", \"\")\n",
    "    clean_name = clean_name.replace(\"ID_match_FLASH.extendedFrags\", \"\")\n",
    "    clean_name = clean_name.replace(\"__\", \"_\").strip(\"_\")  # ì¤‘ë³µ/ë _ ì œê±°\n",
    "    output_csv = os.path.join(histogram_folder, f\"histogram_{clean_name}\")\n",
    "\n",
    "    try:\n",
    "        df = pd.read_csv(file_path, dtype=str)\n",
    "        if 'RNAME' not in df.columns:\n",
    "            print(f\"âš ï¸ Skipping file: {file_name} (no 'RNAME' column found)\")\n",
    "            continue\n",
    "\n",
    "        # RNAME ì§‘ê³„ ë° ì •ê·œí™”\n",
    "        rname_counts = df['RNAME'].value_counts().reset_index()\n",
    "        rname_counts.columns = ['RNAME', 'Count']\n",
    "        rname_counts.insert(0, 'File_Name', clean_name)\n",
    "        rname_counts['Count'] = rname_counts['Count'].astype(int)\n",
    "        total_count = rname_counts['Count'].sum()\n",
    "        rname_counts['Normalized_Count'] = rname_counts['Count'] / total_count\n",
    "\n",
    "        rname_counts.to_csv(output_csv, index=False)\n",
    "        print(f\"âœ… Saved cleaned RNAME histogram: {output_csv}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error processing file '{file_name}': {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "3b663461",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Saved plot: fastq_7_8_9_10_11_12/5_align_histogram/graph_top5/histogram_250910_batch20_08step_.png, fastq_7_8_9_10_11_12/5_align_histogram/graph_top5/histogram_250910_batch20_08step_.svg\n",
      "âœ… Saved plot: fastq_7_8_9_10_11_12/5_align_histogram/graph_top5/histogram_250910_batch20_09step_.png, fastq_7_8_9_10_11_12/5_align_histogram/graph_top5/histogram_250910_batch20_09step_.svg\n",
      "âœ… Saved plot: fastq_7_8_9_10_11_12/5_align_histogram/graph_top5/histogram_250910_batch20_07step_.png, fastq_7_8_9_10_11_12/5_align_histogram/graph_top5/histogram_250910_batch20_07step_.svg\n",
      "âœ… Saved plot: fastq_7_8_9_10_11_12/5_align_histogram/graph_top5/histogram_250910_batch20_10step_.png, fastq_7_8_9_10_11_12/5_align_histogram/graph_top5/histogram_250910_batch20_10step_.svg\n",
      "âœ… Saved plot: fastq_7_8_9_10_11_12/5_align_histogram/graph_top5/histogram_250905_batch19_08step_.png, fastq_7_8_9_10_11_12/5_align_histogram/graph_top5/histogram_250905_batch19_08step_.svg\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ğŸ“ í´ë” ì„¤ì •\n",
    "histogram_folder = \"fastq_7_8_9_10_11_12/5_align_histogram\"\n",
    "summary_folder = \"fastq_7_8_9_10_11_12/5_align_histogram/graph_top5\"\n",
    "os.makedirs(summary_folder, exist_ok=True)\n",
    "\n",
    "# ğŸ”´ í•˜ì´ë¼ì´íŠ¸ ë§¤í•‘ (suffix ê¸°ë°˜)\n",
    "highlight_mapping = {\n",
    "    \"_01step\": \"seq_0001_1\",\n",
    "    \"_02step\": \"seq_0002_10\",\n",
    "    \"_03step\": \"seq_0005_101\",\n",
    "    \"_04step\": \"seq_0010_1010\",\n",
    "    \"_05step\": \"seq_0021_10101\",\n",
    "    \"_06step\": \"seq_0042_101010\",\n",
    "    \"_07step\": \"seq_0085_1010101\",\n",
    "    \"_08step\": \"seq_0170_10101010\",\n",
    "    \"_09step\": \"seq_0341_101010101\",\n",
    "    \"_10step\": \"seq_0682_1010101010\",\n",
    "    \"_11step\": \"seq_1365_10101010101\",\n",
    "    \"_12step\": \"seq_2730_101010101010\",\n",
    "}\n",
    "\n",
    "# ğŸ“„ CSV íŒŒì¼ ë¦¬ìŠ¤íŠ¸\n",
    "csv_files = [f for f in os.listdir(histogram_folder) if f.startswith(\"histogram_\") and f.endswith(\".csv\")]\n",
    "\n",
    "# ğŸ” íŒŒì¼ ë°˜ë³µ ì²˜ë¦¬\n",
    "for file_name in csv_files:\n",
    "    file_path = os.path.join(histogram_folder, file_name)\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        if 'RNAME' not in df.columns or 'Normalized_Count' not in df.columns:\n",
    "            print(f\"âš ï¸ Skipping file: {file_name} (missing column)\")\n",
    "            continue\n",
    "\n",
    "        # Top 5 RNAME ì¶”ì¶œ\n",
    "        top_df = df.sort_values(by=\"Count\", ascending=False).head(5).reset_index(drop=True)\n",
    "        sample_name = file_name.replace(\"histogram_\", \"\").replace(\".csv\", \"\")\n",
    "\n",
    "        # ğŸ” suffix ê¸°ë°˜ í•˜ì´ë¼ì´íŠ¸ RNAME ì°¾ê¸°\n",
    "        highlight_rname = None\n",
    "        for suffix, rname in highlight_mapping.items():\n",
    "            if suffix in file_name:\n",
    "                highlight_rname = rname\n",
    "                break\n",
    "\n",
    "        # ğŸ“Š ê·¸ë˜í”„ ìƒì„±\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        bars = plt.bar(top_df[\"RNAME\"], top_df[\"Normalized_Count\"], color='blue')\n",
    "\n",
    "        # ğŸ”´ ë§¤ì¹­ë˜ëŠ” RNAMEì€ ë¹¨ê°•ìƒ‰ìœ¼ë¡œ\n",
    "        for bar, rname in zip(bars, top_df[\"RNAME\"]):\n",
    "            if rname == highlight_rname:\n",
    "                bar.set_color('red')\n",
    "\n",
    "        plt.title(f\"Top 5 RNAME Histogram - {sample_name}\")\n",
    "        plt.xlabel(\"RNAME\")\n",
    "        plt.ylabel(\"Normalized Count\")\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.ylim(0, 1)\n",
    "        plt.tight_layout()\n",
    "\n",
    "        # ğŸ’¾ ì €ì¥\n",
    "        output_png = os.path.join(summary_folder, file_name.replace(\".csv\", \".png\"))\n",
    "        output_svg = os.path.join(summary_folder, file_name.replace(\".csv\", \".svg\"))\n",
    "        plt.savefig(output_png)\n",
    "        plt.savefig(output_svg)\n",
    "        plt.close()\n",
    "\n",
    "        print(f\"âœ… Saved plot: {output_png}, {output_svg}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error processing {file_name}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "75ae5f74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ì €ì¥ ì™„ë£Œ:\n",
      " - PNG: fastq_7_8_9_10_11_12/6_align_summary/stacked_bar_top5_gray_rest_white_box.png\n",
      " - SVG: fastq_7_8_9_10_11_12/6_align_summary/stacked_bar_top5_gray_rest_white_box.svg\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# í´ë” ì„¤ì •\n",
    "histogram_folder = \"fastq_7_8_9_10_11_12/5_align_histogram\"\n",
    "summary_folder = \"fastq_7_8_9_10_11_12/6_align_summary\"\n",
    "os.makedirs(summary_folder, exist_ok=True)\n",
    "\n",
    "# highlight ë§¤í•‘ (ì ‘ë¯¸ì‚¬ ê¸°ì¤€)\n",
    "highlight_mapping = {\n",
    "    \"_01step\": \"seq_0001_1\",\n",
    "    \"_02step\": \"seq_0002_10\",\n",
    "    \"_03step\": \"seq_0005_101\",\n",
    "    \"_04step\": \"seq_0010_1010\",\n",
    "    \"_05step\": \"seq_0021_10101\",\n",
    "    \"_06step\": \"seq_0042_101010\",\n",
    "    \"_07step\": \"seq_0085_1010101\",\n",
    "    \"_08step\": \"seq_0170_10101010\",\n",
    "    \"_09step\": \"seq_0341_101010101\",\n",
    "    \"_10step\": \"seq_0682_1010101010\",\n",
    "    \"_11step\": \"seq_1365_10101010101\",\n",
    "    \"_12step\": \"seq_2730_101010101010\",\n",
    "}\n",
    "\n",
    "# íšŒìƒ‰ â†’ í°ìƒ‰ ê·¸ë¼ë°ì´ì…˜ ìƒ‰ìƒ í•¨ìˆ˜\n",
    "def blend_color(base_rgb, t):\n",
    "    white = np.array([255, 255, 255])\n",
    "    base = np.array(base_rgb)\n",
    "    blended = (1 - t) * base + t * white\n",
    "    return tuple(blended / 255)\n",
    "\n",
    "base_rgb = (137, 137, 138)\n",
    "\n",
    "# step ë²ˆí˜¸ë¥¼ ì¶”ì¶œí•˜ì—¬ ì˜¤ë¦„ì°¨ìˆœ ì •ë ¬ì„ ìœ„í•œ í•¨ìˆ˜\n",
    "def extract_step_number(name):\n",
    "    match = re.search(r'_(\\d+)step', name)\n",
    "    return int(match.group(1)) if match else float('inf')\n",
    "\n",
    "# sampleë³„ ë°ì´í„° ë¡œë”©\n",
    "sample_rname_dfs = {}\n",
    "for file_name in os.listdir(histogram_folder):\n",
    "    if file_name.startswith(\"histogram_\") and file_name.endswith(\".csv\"):\n",
    "        sample_name = file_name.replace(\"histogram_\", \"\").replace(\".csv\", \"\")\n",
    "        df = pd.read_csv(os.path.join(histogram_folder, file_name))\n",
    "        if 'RNAME' not in df.columns or 'Count' not in df.columns:\n",
    "            continue\n",
    "        df['Sample'] = sample_name\n",
    "        df['Count'] = df['Count'].astype(int)\n",
    "        df['Normalized_Count'] = df['Count'] / df['Count'].sum()\n",
    "        df = df.sort_values(by='Count', ascending=False).reset_index(drop=True)\n",
    "        sample_rname_dfs[sample_name] = df\n",
    "\n",
    "# sample_nameì„ step ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬\n",
    "sorted_samples = sorted(sample_rname_dfs.items(), key=lambda x: extract_step_number(x[0]))\n",
    "\n",
    "# ì‹œê°í™”\n",
    "fig, ax = plt.subplots(figsize=(24, 12))\n",
    "\n",
    "for sample_idx, (sample_name, df) in enumerate(sorted_samples):\n",
    "    # highlight RNAME ì°¾ê¸°\n",
    "    highlight_rname = None\n",
    "    for suffix, rname in highlight_mapping.items():\n",
    "        if suffix in sample_name:  # ì •í™•í•œ ëì´ ì•„ë‹ˆë¼ í¬í•¨ ì—¬ë¶€ë¡œ ìˆ˜ì •\n",
    "            highlight_rname = rname\n",
    "            break\n",
    "\n",
    "    bottom = 0\n",
    "    top_n = 5\n",
    "    rest_sum = 0\n",
    "\n",
    "    for rank, row in df.iterrows():\n",
    "        rname = row['RNAME']\n",
    "        height = row['Normalized_Count']\n",
    "\n",
    "        if rname == highlight_rname:\n",
    "            ax.bar(sample_name, height, bottom=bottom, color='red', edgecolor='black', linewidth=0.2)\n",
    "            bottom += height\n",
    "        elif rank < top_n:\n",
    "            t = rank / (top_n - 1) if top_n > 1 else 0\n",
    "            color = blend_color(base_rgb, t)\n",
    "            ax.bar(sample_name, height, bottom=bottom, color=color, edgecolor='black', linewidth=0.2)\n",
    "            bottom += height\n",
    "        else:\n",
    "            rest_sum += height\n",
    "\n",
    "    if rest_sum > 0:\n",
    "        ax.bar(sample_name, rest_sum, bottom=bottom, color='white', edgecolor='black', linewidth=0.2)\n",
    "\n",
    "# ë³´ì¡°ì„ , ìŠ¤íƒ€ì¼\n",
    "ax.axhline(y=0.5, color='gray', linestyle='--', linewidth=1, label='y = 0.5')\n",
    "ax.set_ylabel(\"Normalized Count\", fontsize=20)\n",
    "ax.set_xlabel(\"Sample\", fontsize=20)\n",
    "ax.set_title(\"Stacked Bar Chart (Red = Highlight, Grayâ†’White = Top 5, Rest = One White Box)\", fontsize=16)\n",
    "ax.tick_params(axis='x', labelsize=20)\n",
    "ax.tick_params(axis='y', labelsize=20)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "\n",
    "# ì €ì¥\n",
    "png_path = os.path.join(summary_folder, \"stacked_bar_top5_gray_rest_white_box.png\")\n",
    "svg_path = os.path.join(summary_folder, \"stacked_bar_top5_gray_rest_white_box.svg\")\n",
    "plt.savefig(png_path)\n",
    "plt.savefig(svg_path)\n",
    "plt.close()\n",
    "\n",
    "print(f\"âœ… ì €ì¥ ì™„ë£Œ:\\n - PNG: {png_path}\\n - SVG: {svg_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "4c241be4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Œ Highlight summary saved to: fastq_7_8_9_10_11_12/6_align_summary/highlight_result.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# === Highlight mapping (suffix -> RNAME) ===\n",
    "highlight_mapping = {\n",
    "    \"_01step\": \"seq_0001_1\",\n",
    "    \"_02step\": \"seq_0002_10\",\n",
    "    \"_03step\": \"seq_0005_101\",\n",
    "    \"_04step\": \"seq_0010_1010\",\n",
    "    \"_05step\": \"seq_0021_10101\",\n",
    "    \"_06step\": \"seq_0042_101010\",\n",
    "    \"_07step\": \"seq_0085_1010101\",\n",
    "    \"_08step\": \"seq_0170_10101010\",\n",
    "    \"_09step\": \"seq_0341_101010101\",\n",
    "    \"_10step\": \"seq_0682_1010101010\",\n",
    "    \"_11step\": \"seq_1365_10101010101\",\n",
    "    \"_12step\": \"seq_2730_101010101010\",\n",
    "}\n",
    "\n",
    "# === í´ë” ì„¤ì • ===\n",
    "histogram_folder = \"fastq_7_8_9_10_11_12/5_align_histogram\"\n",
    "summary_folder = \"fastq_7_8_9_10_11_12/6_align_summary\"\n",
    "os.makedirs(summary_folder, exist_ok=True)\n",
    "highlight_result_csv = os.path.join(summary_folder, \"highlight_result.csv\")\n",
    "\n",
    "# === step ë²ˆí˜¸ ì¶”ì¶œ í•¨ìˆ˜ ===\n",
    "def extract_step_number(filename):\n",
    "    match = re.search(r\"_(\\d+)step\", filename)\n",
    "    return int(match.group(1)) if match else float(\"inf\")\n",
    "\n",
    "# === Highlight ìš”ì•½ ì •ë³´ ìˆ˜ì§‘ ===\n",
    "highlight_data = []\n",
    "csv_files = [f for f in os.listdir(histogram_folder) if f.startswith(\"histogram_\") and f.endswith(\".csv\")]\n",
    "\n",
    "for file in csv_files:\n",
    "    file_path = os.path.join(histogram_folder, file)\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        file_name = file.replace(\"histogram_\", \"\")\n",
    "\n",
    "        # suffix ê¸°ë°˜ highlight_rname ì¶”ì¶œ\n",
    "        highlight_rname = \"\"\n",
    "        for suffix, rname in highlight_mapping.items():\n",
    "            if suffix in file_name:\n",
    "                highlight_rname = rname\n",
    "                break\n",
    "\n",
    "        df['Count'] = df['Count'].astype(int)\n",
    "        total_count = df['Count'].sum()\n",
    "\n",
    "        highlight_count = df[df['RNAME'] == highlight_rname]['Count'].sum() if highlight_rname else 0\n",
    "        highlight_percentage = (highlight_count / total_count) * 100 if total_count > 0 else 0\n",
    "\n",
    "        sorted_counts = df['Count'].sort_values(ascending=False).values\n",
    "        second_max_count = sorted_counts[1] if len(sorted_counts) >= 2 else (sorted_counts[0] if len(sorted_counts) == 1 else 0)\n",
    "        highlight_vs_second_ratio = (highlight_count / second_max_count) if second_max_count > 0 else 0\n",
    "\n",
    "        highlight_data.append([\n",
    "            file_name,\n",
    "            highlight_count,\n",
    "            total_count,\n",
    "            round(highlight_percentage, 2),\n",
    "            highlight_rname,\n",
    "            round(highlight_vs_second_ratio, 3),\n",
    "            extract_step_number(file_name)\n",
    "        ])\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error processing file '{file}': {e}\")\n",
    "\n",
    "# === DataFrame ìƒì„± ë° step ê¸°ì¤€ ì •ë ¬ í›„ ì €ì¥ ===\n",
    "highlight_df = pd.DataFrame(highlight_data, columns=[\n",
    "    'File',\n",
    "    'Highlight_Count',\n",
    "    'Total_Count',\n",
    "    'Highlight_Percentage',\n",
    "    'Highlight_RNAMEs',\n",
    "    'Highlight_vs_SecondTop_Ratio',\n",
    "    'Step_Number'\n",
    "])\n",
    "\n",
    "highlight_df = highlight_df.sort_values(by='Step_Number').drop(columns='Step_Number')\n",
    "highlight_df.to_csv(highlight_result_csv, index=False)\n",
    "\n",
    "print(f\"ğŸ“Œ Highlight summary saved to: {highlight_result_csv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d973acc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85419b19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
