{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39189dfb",
   "metadata": {},
   "source": [
    "# **Install modules**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e906fe9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: biopython in /usr/local/lib/python3.12/dist-packages (1.84)\n",
      "Requirement already satisfied: numpy in /usr/lib/python3/dist-packages (from biopython) (1.26.4)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "fastp is already the newest version (0.23.4+dfsg-1).\n",
      "The following packages were automatically installed and are no longer required:\n",
      "  pigz python3-xopen\n",
      "Use 'sudo apt autoremove' to remove them.\n",
      "0 upgraded, 0 newly installed, 0 to remove and 265 not upgraded.\n",
      "Hit:1 https://packages.microsoft.com/repos/code stable InRelease               \n",
      "Hit:2 http://ports.ubuntu.com/ubuntu-ports noble InRelease                     \n",
      "Get:3 http://ports.ubuntu.com/ubuntu-ports noble-updates InRelease [126 kB]    \n",
      "Hit:4 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu noble InRelease   \n",
      "Get:5 http://ports.ubuntu.com/ubuntu-ports noble-backports InRelease [126 kB]\n",
      "Get:6 http://ports.ubuntu.com/ubuntu-ports noble-security InRelease [126 kB]\n",
      "Get:7 http://ports.ubuntu.com/ubuntu-ports noble-updates/main arm64 Components [172 kB]\n",
      "Get:8 http://ports.ubuntu.com/ubuntu-ports noble-updates/restricted arm64 Components [212 B]\n",
      "Get:9 http://ports.ubuntu.com/ubuntu-ports noble-updates/universe arm64 Components [375 kB]\n",
      "Get:10 http://ports.ubuntu.com/ubuntu-ports noble-updates/multiverse arm64 Components [212 B]\n",
      "Get:11 http://ports.ubuntu.com/ubuntu-ports noble-backports/main arm64 Components [3,568 B]\n",
      "Get:12 http://ports.ubuntu.com/ubuntu-ports noble-backports/restricted arm64 Components [216 B]\n",
      "Get:13 http://ports.ubuntu.com/ubuntu-ports noble-backports/universe arm64 Components [19.2 kB]\n",
      "Get:14 http://ports.ubuntu.com/ubuntu-ports noble-backports/multiverse arm64 Components [212 B]\n",
      "Get:15 http://ports.ubuntu.com/ubuntu-ports noble-security/main arm64 Components [18.4 kB]\n",
      "Get:16 http://ports.ubuntu.com/ubuntu-ports noble-security/restricted arm64 Components [212 B]\n",
      "Get:17 http://ports.ubuntu.com/ubuntu-ports noble-security/universe arm64 Components [52.3 kB]\n",
      "Get:18 http://ports.ubuntu.com/ubuntu-ports noble-security/multiverse arm64 Components [212 B]\n",
      "Fetched 1,021 kB in 5s (189 kB/s)          \n",
      "Reading package lists... Done\n",
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "flash is already the newest version (1.2.11-2).\n",
      "The following packages were automatically installed and are no longer required:\n",
      "  pigz python3-xopen\n",
      "Use 'sudo apt autoremove' to remove them.\n",
      "0 upgraded, 0 newly installed, 0 to remove and 265 not upgraded.\n",
      "Requirement already satisfied: cutadapt in /usr/local/lib/python3.12/dist-packages (5.0)\n",
      "Requirement already satisfied: dnaio>=1.2.3 in /usr/local/lib/python3.12/dist-packages (from cutadapt) (1.2.3)\n",
      "Requirement already satisfied: xopen>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from cutadapt) (2.0.2)\n",
      "Requirement already satisfied: isal>=1.6.1 in /usr/local/lib/python3.12/dist-packages (from xopen>=1.6.0->cutadapt) (1.7.1)\n",
      "Requirement already satisfied: zlib-ng>=0.4.1 in /usr/local/lib/python3.12/dist-packages (from xopen>=1.6.0->cutadapt) (0.5.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "bwa is already the newest version (0.7.17-7).\n",
      "The following packages were automatically installed and are no longer required:\n",
      "  pigz python3-xopen\n",
      "Use 'sudo apt autoremove' to remove them.\n",
      "0 upgraded, 0 newly installed, 0 to remove and 265 not upgraded.\n",
      "Requirement already satisfied: pysam in /usr/local/lib/python3.12/dist-packages (0.22.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "samtools is already the newest version (1.19.2-1build2).\n",
      "The following packages were automatically installed and are no longer required:\n",
      "  pigz python3-xopen\n",
      "Use 'sudo apt autoremove' to remove them.\n",
      "0 upgraded, 0 newly installed, 0 to remove and 265 not upgraded.\n"
     ]
    }
   ],
   "source": [
    "# Install modules\n",
    "!sudo pip3 install biopython --break-system-packages\n",
    "!sudo apt-get install fastp \n",
    "!sudo apt-get update \n",
    "!sudo apt-get install flash\n",
    "!sudo pip3 install cutadapt --break-system-packages\n",
    "!sudo apt-get install bwa \n",
    "!sudo pip3 install pysam --break-system-packages\n",
    "!sudo apt-get install samtools "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd54a0a6",
   "metadata": {},
   "source": [
    "# Trimming and Discard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8ac5eda6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Untrimmed sequences saved: fastq_1_2_3_4_5_6/A_Untrimmed_output/250905_batch19_01step_R1_untrimmed.fastq.gz, fastq_1_2_3_4_5_6/A_Untrimmed_output/250905_batch19_01step_R2_untrimmed.fastq.gz\n",
      "Untrimmed sequences saved: fastq_1_2_3_4_5_6/A_Untrimmed_output/250910_batch20_06step_R1_untrimmed.fastq.gz, fastq_1_2_3_4_5_6/A_Untrimmed_output/250910_batch20_06step_R2_untrimmed.fastq.gz\n",
      "Untrimmed sequences saved: fastq_1_2_3_4_5_6/A_Untrimmed_output/250910_batch20_05step_R1_untrimmed.fastq.gz, fastq_1_2_3_4_5_6/A_Untrimmed_output/250910_batch20_05step_R2_untrimmed.fastq.gz\n",
      "Untrimmed sequences saved: fastq_1_2_3_4_5_6/A_Untrimmed_output/250905_batch19_02step_R1_untrimmed.fastq.gz, fastq_1_2_3_4_5_6/A_Untrimmed_output/250905_batch19_02step_R2_untrimmed.fastq.gz\n",
      "Untrimmed sequences saved: fastq_1_2_3_4_5_6/A_Untrimmed_output/250905_batch19_03step_R1_untrimmed.fastq.gz, fastq_1_2_3_4_5_6/A_Untrimmed_output/250905_batch19_03step_R2_untrimmed.fastq.gz\n",
      "Untrimmed sequences saved: fastq_1_2_3_4_5_6/A_Untrimmed_output/250905_batch19_04step_R1_untrimmed.fastq.gz, fastq_1_2_3_4_5_6/A_Untrimmed_output/250905_batch19_04step_R2_untrimmed.fastq.gz\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# Specify the folder containing your input files\n",
    "# Specify the folder where you want to save the untrimmed sequences (adapter-free sequences)\n",
    "\n",
    "input_folder = \"fastq_1_2_3_4_5_6\"\n",
    "untrimmed_output_folder = \"fastq_1_2_3_4_5_6/A_Untrimmed_output\"\n",
    "\n",
    "# Define the adapter sequences for R1 and R2\n",
    "adapter_sequence_r1 = \"AGATCGGAAGAGCACACGTCTGAACTCCAGTCAC\"\n",
    "adapter_sequence_r2 = \"AGATCGGAAGAGCGTCGTGTAGGGAAAGAGTGT\"\n",
    "\n",
    "# Use glob to get a list of all input file pairs (R1 and R2) in the folder\n",
    "input_file_pairs = []\n",
    "for input_r1 in glob.glob(os.path.join(input_folder, \"*_R1.fastq.gz\")):\n",
    "    # Assuming R2 files have the same naming format as R1 files\n",
    "    input_r2 = input_r1.replace(\"_R1.fastq.gz\", \"_R2.fastq.gz\")\n",
    "    if os.path.exists(input_r2):  # Ensure R2 file exists\n",
    "        input_file_pairs.append({\"r1\": input_r1, \"r2\": input_r2})\n",
    "\n",
    "# Create the output folder if it doesn't exist\n",
    "os.makedirs(untrimmed_output_folder, exist_ok=True)\n",
    "\n",
    "for input_files in input_file_pairs:\n",
    "    input_r1 = input_files[\"r1\"]\n",
    "    input_r2 = input_files[\"r2\"]\n",
    "\n",
    "    # Define output file paths for untrimmed (clean, adapter-free) sequences\n",
    "    untrimmed_r1 = os.path.join(untrimmed_output_folder, os.path.basename(input_r1).replace(\".fastq.gz\", \"_untrimmed.fastq.gz\"))\n",
    "    untrimmed_r2 = os.path.join(untrimmed_output_folder, os.path.basename(input_r2).replace(\".fastq.gz\", \"_untrimmed.fastq.gz\"))\n",
    "\n",
    "    # Use cutadapt to keep only untrimmed sequences (completely adapter-free)\n",
    "    result = subprocess.run([\n",
    "        \"cutadapt\",\n",
    "        \"-a\", adapter_sequence_r1,  # Adapter for R1\n",
    "        \"-A\", adapter_sequence_r2,  # Adapter for R2\n",
    "        \"-O\", \"15\",  # Minimum overlap for adapter trimming\n",
    "        #\"--discard-trimmed\",  # Discard sequences where trimming occurred\n",
    "        \"-o\", untrimmed_r1,  # Save only untrimmed R1 reads\n",
    "        \"-p\", untrimmed_r2,  # Save only untrimmed R2 reads\n",
    "        input_r1, input_r2\n",
    "    ], capture_output=True, text=True)\n",
    "\n",
    "    # Log result\n",
    "    if result.returncode == 0:\n",
    "        print(f\"Untrimmed sequences saved: {untrimmed_r1}, {untrimmed_r2}\")\n",
    "    else:\n",
    "        print(f\"Error processing {input_r1} and {input_r2}:\\n{result.stderr}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7feb2152",
   "metadata": {},
   "source": [
    "# Quality check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8377e270",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import gzip\n",
    "# from Bio import SeqIO\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # ğŸ“ ì…ë ¥ í´ë”ì™€ ì¶œë ¥ í´ë” ì„¤ì •\n",
    "# input_folder = \"fastq_step/1_3_5_7_9_11/A_Untrimmed_output\"\n",
    "# output_csv_folder = \"fastq_step/1_3_5_7_9_11/A_Untrimmed_output/quality_stats_csv\"\n",
    "# output_plot_folder = \"fastq_step/1_3_5_7_9_11/A_Untrimmed_output/quality_plots\"\n",
    "\n",
    "# os.makedirs(output_csv_folder, exist_ok=True)\n",
    "# os.makedirs(output_plot_folder, exist_ok=True)\n",
    "\n",
    "# # ğŸ” í’ˆì§ˆ í†µê³„ ì¶”ì¶œ í•¨ìˆ˜\n",
    "# def compute_quality_stats(file_path):\n",
    "#     position_qualities = {}\n",
    "#     open_func = gzip.open if file_path.endswith(\".gz\") else open\n",
    "\n",
    "#     with open_func(file_path, \"rt\") as handle:\n",
    "#         for record in SeqIO.parse(handle, \"fastq\"):\n",
    "#             for i, q in enumerate(record.letter_annotations[\"phred_quality\"]):\n",
    "#                 position_qualities.setdefault(i, []).append(q)\n",
    "\n",
    "#     stats = []\n",
    "#     for pos in sorted(position_qualities):\n",
    "#         scores = np.array(position_qualities[pos])\n",
    "#         stats.append({\n",
    "#             \"position\": pos + 1,\n",
    "#             \"mean\": np.mean(scores),\n",
    "#             \"q1\": np.percentile(scores, 25),\n",
    "#             \"median\": np.median(scores),\n",
    "#             \"q3\": np.percentile(scores, 75),\n",
    "#             \"min\": np.min(scores),\n",
    "#             \"max\": np.max(scores)\n",
    "#         })\n",
    "#     return pd.DataFrame(stats)\n",
    "\n",
    "# # ğŸ“Š ë°°ê²½ ìƒ‰ìƒ í•¨ìˆ˜ (fastp ìŠ¤íƒ€ì¼)\n",
    "# def add_quality_background(ax):\n",
    "#     ax.axhspan(30, 40, facecolor='lightgreen', alpha=0.5)\n",
    "#     ax.axhspan(25, 30, facecolor='khaki', alpha=0.5)\n",
    "#     ax.axhspan(20, 25, facecolor='moccasin', alpha=0.5)\n",
    "#     ax.axhspan(0, 20, facecolor='lightcoral', alpha=0.5)\n",
    "\n",
    "# # ğŸ“‚ í´ë” ë‚´ ëª¨ë“  FASTQ(.gz í¬í•¨) ì²˜ë¦¬\n",
    "# for filename in os.listdir(input_folder):\n",
    "#     if filename.endswith(\".fastq\") or filename.endswith(\".fastq.gz\"):\n",
    "#         input_path = os.path.join(input_folder, filename)\n",
    "#         sample_name = os.path.splitext(filename)[0].replace(\".fastq\", \"\").replace(\".gz\", \"\")\n",
    "\n",
    "#         print(f\"ğŸ“Œ Processing: {sample_name}\")\n",
    "#         df = compute_quality_stats(input_path)\n",
    "\n",
    "#         # CSV ì €ì¥\n",
    "#         csv_path = os.path.join(output_csv_folder, f\"{sample_name}_quality.csv\")\n",
    "#         df.to_csv(csv_path, index=False)\n",
    "\n",
    "#         # ê·¸ë˜í”„ ì €ì¥\n",
    "#         plt.figure(figsize=(18, 8))\n",
    "#         ax = plt.gca()\n",
    "#         add_quality_background(ax)\n",
    "#         plt.plot(df[\"position\"], df[\"mean\"], color=\"blue\", linewidth=1.5, label=\"Mean Quality\")\n",
    "\n",
    "#         for i in range(len(df)):\n",
    "#             x = df.loc[i, \"position\"]\n",
    "#             q1 = df.loc[i, \"q1\"]\n",
    "#             q3 = df.loc[i, \"q3\"]\n",
    "#             plt.fill_between([x - 0.4, x + 0.4], [q1, q1], [q3, q3], color=\"yellow\", edgecolor=\"black\")\n",
    "\n",
    "#         plt.vlines(df[\"position\"], df[\"min\"], df[\"max\"], color=\"black\", linewidth=0.5)\n",
    "#         plt.title(f\"Quality scores across all bases: {sample_name}\", fontsize=14)\n",
    "#         plt.xlabel(\"Position in read (bp)\", fontsize=12)\n",
    "#         plt.ylabel(\"Quality score\", fontsize=12)\n",
    "#         plt.ylim(0, 40)\n",
    "#         plt.xlim(1, df[\"position\"].max())\n",
    "#         plt.legend()\n",
    "#         plt.tight_layout()\n",
    "#         plot_path = os.path.join(output_plot_folder, f\"{sample_name}_quality_plot.png\")\n",
    "#         plt.savefig(plot_path, dpi=300)\n",
    "#         plt.close()\n",
    "\n",
    "#         print(f\"âœ… Saved: {sample_name}_quality.csv and quality_plot.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90408c7",
   "metadata": {},
   "source": [
    "# read count check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3bc6daeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import gzip\n",
    "# from Bio import SeqIO\n",
    "\n",
    "# # ë¶„ì„ ëŒ€ìƒ í´ë”\n",
    "# input_folder = \"fastq_step/1_3_5_7_9_11/A_Untrimmed_output\"  # ì—¬ê¸°ì— ëŒ€ìƒ í´ë” ê²½ë¡œë¥¼ ì…ë ¥í•˜ì„¸ìš”\n",
    "\n",
    "# # í—ˆìš© í™•ì¥ì\n",
    "# valid_extensions = [\".fastq\", \".fastq.gz\", \".fasta\", \".fasta.gz\"]\n",
    "\n",
    "# # í¬ë§· ê²°ì • í•¨ìˆ˜\n",
    "# def get_format(filename):\n",
    "#     if filename.endswith(\".fastq\") or filename.endswith(\".fastq.gz\"):\n",
    "#         return \"fastq\"\n",
    "#     elif filename.endswith(\".fasta\") or filename.endswith(\".fasta.gz\"):\n",
    "#         return \"fasta\"\n",
    "#     else:\n",
    "#         return None\n",
    "\n",
    "# # ê²°ê³¼ ì €ì¥ ë¦¬ìŠ¤íŠ¸\n",
    "# read_counts = []\n",
    "\n",
    "# # íŒŒì¼ ìˆœíšŒ ë° read ìˆ˜ ì¹´ìš´íŠ¸\n",
    "# for filename in os.listdir(input_folder):\n",
    "#     if any(filename.endswith(ext) for ext in valid_extensions):\n",
    "#         file_path = os.path.join(input_folder, filename)\n",
    "#         file_format = get_format(filename)\n",
    "#         open_func = gzip.open if filename.endswith(\".gz\") else open\n",
    "\n",
    "#         try:\n",
    "#             with open_func(file_path, \"rt\") as handle:\n",
    "#                 count = sum(1 for _ in SeqIO.parse(handle, file_format))\n",
    "#             read_counts.append((filename, count))\n",
    "#         except Exception as e:\n",
    "#             print(f\"âŒ Error processing {filename}: {e}\")\n",
    "\n",
    "# # ğŸ“„ íŒŒì¼ëª… ê¸°ì¤€ ì •ë ¬ í›„ ì¶œë ¥\n",
    "# read_counts.sort(key=lambda x: x[0].lower())  # íŒŒì¼ëª… ê¸°ì¤€ (ëŒ€ì†Œë¬¸ì êµ¬ë¶„ ì—†ì´) ì •ë ¬\n",
    "# for fname, count in read_counts:\n",
    "#     print(f\"{fname:40} : {count} reads\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a68943",
   "metadata": {},
   "source": [
    "# length check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f9023132",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250905_batch19_01step_R1_untrimmed.fastq.gz :   3219 reads, Avg Length =  31.55 bp\n",
      "250905_batch19_01step_R2_untrimmed.fastq.gz :   3219 reads, Avg Length =   45.7 bp\n",
      "250905_batch19_02step_R1_untrimmed.fastq.gz :   2632 reads, Avg Length =  50.84 bp\n",
      "250905_batch19_02step_R2_untrimmed.fastq.gz :   2632 reads, Avg Length =  62.08 bp\n",
      "250905_batch19_03step_R1_untrimmed.fastq.gz :   2706 reads, Avg Length =  71.72 bp\n",
      "250905_batch19_03step_R2_untrimmed.fastq.gz :   2706 reads, Avg Length =  81.03 bp\n",
      "250905_batch19_04step_R1_untrimmed.fastq.gz :   2741 reads, Avg Length =  92.04 bp\n",
      "250905_batch19_04step_R2_untrimmed.fastq.gz :   2741 reads, Avg Length =  97.58 bp\n",
      "250910_batch20_05step_R1_untrimmed.fastq.gz :   2468 reads, Avg Length = 109.94 bp\n",
      "250910_batch20_05step_R2_untrimmed.fastq.gz :   2468 reads, Avg Length = 114.66 bp\n",
      "250910_batch20_06step_R1_untrimmed.fastq.gz :   2387 reads, Avg Length = 131.44 bp\n",
      "250910_batch20_06step_R2_untrimmed.fastq.gz :   2387 reads, Avg Length = 133.51 bp\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gzip\n",
    "from Bio import SeqIO\n",
    "\n",
    "# ë¶„ì„ ëŒ€ìƒ í´ë”\n",
    "input_folder = \"fastq_1_2_3_4_5_6/A_Untrimmed_output\"  # ì—¬ê¸°ì— ëŒ€ìƒ í´ë” ê²½ë¡œë¥¼ ì…ë ¥í•˜ì„¸ìš”\n",
    "\n",
    "# í—ˆìš© í™•ì¥ì\n",
    "valid_extensions = [\".fastq\", \".fastq.gz\"]\n",
    "\n",
    "# íŒŒì¼ í¬ë§· ê²°ì • í•¨ìˆ˜\n",
    "def get_format(filename):\n",
    "    if filename.endswith(\".fastq\") or filename.endswith(\".fastq.gz\"):\n",
    "        return \"fastq\"\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# ê²°ê³¼ ì €ì¥ ë¦¬ìŠ¤íŠ¸\n",
    "read_stats = []\n",
    "\n",
    "# íŒŒì¼ ìˆœíšŒ ë° ë¶„ì„\n",
    "for filename in os.listdir(input_folder):\n",
    "    if any(filename.endswith(ext) for ext in valid_extensions):\n",
    "        file_path = os.path.join(input_folder, filename)\n",
    "        file_format = get_format(filename)\n",
    "        open_func = gzip.open if filename.endswith(\".gz\") else open\n",
    "\n",
    "        try:\n",
    "            total_len = 0\n",
    "            read_count = 0\n",
    "            with open_func(file_path, \"rt\") as handle:\n",
    "                for record in SeqIO.parse(handle, file_format):\n",
    "                    total_len += len(record.seq)\n",
    "                    read_count += 1\n",
    "            avg_length = total_len / read_count if read_count > 0 else 0\n",
    "            read_stats.append((filename, read_count, round(avg_length, 2)))\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Error processing {filename}: {e}\")\n",
    "\n",
    "# ì •ë ¬ í›„ ì¶œë ¥\n",
    "read_stats.sort(key=lambda x: x[0].lower())\n",
    "for fname, count, avg_len in read_stats:\n",
    "    print(f\"{fname:40} : {count:6} reads, Avg Length = {avg_len:6} bp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d43590a",
   "metadata": {},
   "source": [
    "# Q filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "330bc19f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: you specified the options for cutting by quality, but forogt to enable any of cut_front/cut_tail/cut_right. This will have no effect.\n",
      "Detecting adapter sequence for read1...\n",
      "No adapter detected for read1\n",
      "\n",
      "Read1 before filtering:\n",
      "total reads: 2387\n",
      "total bases: 318681\n",
      "Q20 bases: 295857(92.838%)\n",
      "Q30 bases: 274463(86.1247%)\n",
      "\n",
      "Read1 after filtering:\n",
      "total reads: 1654\n",
      "total bases: 214977\n",
      "Q20 bases: 210076(97.7202%)\n",
      "Q30 bases: 200235(93.1425%)\n",
      "\n",
      "Filtering result:\n",
      "reads passed filter: 1654\n",
      "reads failed due to low quality: 732\n",
      "reads failed due to too many N: 0\n",
      "reads failed due to too short: 1\n",
      "reads with adapter trimmed: 0\n",
      "bases trimmed due to adapters: 0\n",
      "\n",
      "Duplication rate (may be overestimated since this is SE data): 51.9062%\n",
      "\n",
      "JSON report: fastq_1_2_3_4_5_6/B_Qfiltered/250910_batch20_06step_R2_Qfiltered.fastq.gz.json\n",
      "HTML report: fastq_1_2_3_4_5_6/B_Qfiltered/250910_batch20_06step_R2_Qfiltered.fastq.gz.html\n",
      "\n",
      "fastp -i fastq_1_2_3_4_5_6/A_Untrimmed_output/250910_batch20_06step_R2_untrimmed.fastq.gz -o fastq_1_2_3_4_5_6/B_Qfiltered/250910_batch20_06step_R2_Qfiltered.fastq.gz -q 30 -u 15 --cut_mean_quality 30 --html fastq_1_2_3_4_5_6/B_Qfiltered/250910_batch20_06step_R2_Qfiltered.fastq.gz.html --json fastq_1_2_3_4_5_6/B_Qfiltered/250910_batch20_06step_R2_Qfiltered.fastq.gz.json \n",
      "fastp v0.23.4, time used: 1 seconds\n",
      "WARNING: you specified the options for cutting by quality, but forogt to enable any of cut_front/cut_tail/cut_right. This will have no effect.\n",
      "Detecting adapter sequence for read1...\n",
      "No adapter detected for read1\n",
      "\n",
      "Read1 before filtering:\n",
      "total reads: 2632\n",
      "total bases: 163402\n",
      "Q20 bases: 151694(92.8348%)\n",
      "Q30 bases: 145564(89.0834%)\n",
      "\n",
      "Read1 after filtering:\n",
      "total reads: 2254\n",
      "total bases: 118174\n",
      "Q20 bases: 117972(99.8291%)\n",
      "Q30 bases: 117090(99.0827%)\n",
      "\n",
      "Filtering result:\n",
      "reads passed filter: 2254\n",
      "reads failed due to low quality: 355\n",
      "reads failed due to too many N: 0\n",
      "reads failed due to too short: 23\n",
      "reads with adapter trimmed: 0\n",
      "bases trimmed due to adapters: 0\n",
      "\n",
      "Duplication rate (may be overestimated since this is SE data): 85.9043%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering for 250910_batch20_06step_R2_untrimmed.fastq.gz is complete.\n",
      "Output FASTQ : fastq_1_2_3_4_5_6/B_Qfiltered/250910_batch20_06step_R2_Qfiltered.fastq.gz\n",
      "Reports      : fastq_1_2_3_4_5_6/B_Qfiltered/250910_batch20_06step_R2_Qfiltered.fastq.gz.html / fastq_1_2_3_4_5_6/B_Qfiltered/250910_batch20_06step_R2_Qfiltered.fastq.gz.json\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "JSON report: fastq_1_2_3_4_5_6/B_Qfiltered/250905_batch19_02step_R2_Qfiltered.fastq.gz.json\n",
      "HTML report: fastq_1_2_3_4_5_6/B_Qfiltered/250905_batch19_02step_R2_Qfiltered.fastq.gz.html\n",
      "\n",
      "fastp -i fastq_1_2_3_4_5_6/A_Untrimmed_output/250905_batch19_02step_R2_untrimmed.fastq.gz -o fastq_1_2_3_4_5_6/B_Qfiltered/250905_batch19_02step_R2_Qfiltered.fastq.gz -q 30 -u 15 --cut_mean_quality 30 --html fastq_1_2_3_4_5_6/B_Qfiltered/250905_batch19_02step_R2_Qfiltered.fastq.gz.html --json fastq_1_2_3_4_5_6/B_Qfiltered/250905_batch19_02step_R2_Qfiltered.fastq.gz.json \n",
      "fastp v0.23.4, time used: 0 seconds\n",
      "WARNING: you specified the options for cutting by quality, but forogt to enable any of cut_front/cut_tail/cut_right. This will have no effect.\n",
      "Detecting adapter sequence for read1...\n",
      "No adapter detected for read1\n",
      "\n",
      "Read1 before filtering:\n",
      "total reads: 2387\n",
      "total bases: 313755\n",
      "Q20 bases: 296656(94.5502%)\n",
      "Q30 bases: 279793(89.1756%)\n",
      "\n",
      "Read1 after filtering:\n",
      "total reads: 1802\n",
      "total bases: 232772\n",
      "Q20 bases: 230093(98.8491%)\n",
      "Q30 bases: 223168(95.8741%)\n",
      "\n",
      "Filtering result:\n",
      "reads passed filter: 1802\n",
      "reads failed due to low quality: 584\n",
      "reads failed due to too many N: 0\n",
      "reads failed due to too short: 1\n",
      "reads with adapter trimmed: 0\n",
      "bases trimmed due to adapters: 0\n",
      "\n",
      "Duplication rate (may be overestimated since this is SE data): 59.2375%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering for 250905_batch19_02step_R2_untrimmed.fastq.gz is complete.\n",
      "Output FASTQ : fastq_1_2_3_4_5_6/B_Qfiltered/250905_batch19_02step_R2_Qfiltered.fastq.gz\n",
      "Reports      : fastq_1_2_3_4_5_6/B_Qfiltered/250905_batch19_02step_R2_Qfiltered.fastq.gz.html / fastq_1_2_3_4_5_6/B_Qfiltered/250905_batch19_02step_R2_Qfiltered.fastq.gz.json\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "JSON report: fastq_1_2_3_4_5_6/B_Qfiltered/250910_batch20_06step_R1_Qfiltered.fastq.gz.json\n",
      "HTML report: fastq_1_2_3_4_5_6/B_Qfiltered/250910_batch20_06step_R1_Qfiltered.fastq.gz.html\n",
      "\n",
      "fastp -i fastq_1_2_3_4_5_6/A_Untrimmed_output/250910_batch20_06step_R1_untrimmed.fastq.gz -o fastq_1_2_3_4_5_6/B_Qfiltered/250910_batch20_06step_R1_Qfiltered.fastq.gz -q 30 -u 15 --cut_mean_quality 30 --html fastq_1_2_3_4_5_6/B_Qfiltered/250910_batch20_06step_R1_Qfiltered.fastq.gz.html --json fastq_1_2_3_4_5_6/B_Qfiltered/250910_batch20_06step_R1_Qfiltered.fastq.gz.json \n",
      "fastp v0.23.4, time used: 0 seconds\n",
      "WARNING: you specified the options for cutting by quality, but forogt to enable any of cut_front/cut_tail/cut_right. This will have no effect.\n",
      "Detecting adapter sequence for read1...\n",
      "No adapter detected for read1\n",
      "\n",
      "Read1 before filtering:\n",
      "total reads: 2632\n",
      "total bases: 133821\n",
      "Q20 bases: 132480(98.9979%)\n",
      "Q30 bases: 130150(97.2568%)\n",
      "\n",
      "Read1 after filtering:\n",
      "total reads: 2457\n",
      "total bases: 125363\n",
      "Q20 bases: 125152(99.8317%)\n",
      "Q30 bases: 124202(99.0739%)\n",
      "\n",
      "Filtering result:\n",
      "reads passed filter: 2457\n",
      "reads failed due to low quality: 150\n",
      "reads failed due to too many N: 0\n",
      "reads failed due to too short: 25\n",
      "reads with adapter trimmed: 0\n",
      "bases trimmed due to adapters: 0\n",
      "\n",
      "Duplication rate (may be overestimated since this is SE data): 94.5289%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering for 250910_batch20_06step_R1_untrimmed.fastq.gz is complete.\n",
      "Output FASTQ : fastq_1_2_3_4_5_6/B_Qfiltered/250910_batch20_06step_R1_Qfiltered.fastq.gz\n",
      "Reports      : fastq_1_2_3_4_5_6/B_Qfiltered/250910_batch20_06step_R1_Qfiltered.fastq.gz.html / fastq_1_2_3_4_5_6/B_Qfiltered/250910_batch20_06step_R1_Qfiltered.fastq.gz.json\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "JSON report: fastq_1_2_3_4_5_6/B_Qfiltered/250905_batch19_02step_R1_Qfiltered.fastq.gz.json\n",
      "HTML report: fastq_1_2_3_4_5_6/B_Qfiltered/250905_batch19_02step_R1_Qfiltered.fastq.gz.html\n",
      "\n",
      "fastp -i fastq_1_2_3_4_5_6/A_Untrimmed_output/250905_batch19_02step_R1_untrimmed.fastq.gz -o fastq_1_2_3_4_5_6/B_Qfiltered/250905_batch19_02step_R1_Qfiltered.fastq.gz -q 30 -u 15 --cut_mean_quality 30 --html fastq_1_2_3_4_5_6/B_Qfiltered/250905_batch19_02step_R1_Qfiltered.fastq.gz.html --json fastq_1_2_3_4_5_6/B_Qfiltered/250905_batch19_02step_R1_Qfiltered.fastq.gz.json \n",
      "fastp v0.23.4, time used: 1 seconds\n",
      "WARNING: you specified the options for cutting by quality, but forogt to enable any of cut_front/cut_tail/cut_right. This will have no effect.\n",
      "Detecting adapter sequence for read1...\n",
      "No adapter detected for read1\n",
      "\n",
      "Read1 before filtering:\n",
      "total reads: 2468\n",
      "total bases: 271323\n",
      "Q20 bases: 262966(96.9199%)\n",
      "Q30 bases: 252892(93.207%)\n",
      "\n",
      "Read1 after filtering:\n",
      "total reads: 2144\n",
      "total bases: 232413\n",
      "Q20 bases: 230924(99.3593%)\n",
      "Q30 bases: 226129(97.2962%)\n",
      "\n",
      "Filtering result:\n",
      "reads passed filter: 2144\n",
      "reads failed due to low quality: 323\n",
      "reads failed due to too many N: 0\n",
      "reads failed due to too short: 1\n",
      "reads with adapter trimmed: 0\n",
      "bases trimmed due to adapters: 0\n",
      "\n",
      "Duplication rate (may be overestimated since this is SE data): 78.6872%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering for 250905_batch19_02step_R1_untrimmed.fastq.gz is complete.\n",
      "Output FASTQ : fastq_1_2_3_4_5_6/B_Qfiltered/250905_batch19_02step_R1_Qfiltered.fastq.gz\n",
      "Reports      : fastq_1_2_3_4_5_6/B_Qfiltered/250905_batch19_02step_R1_Qfiltered.fastq.gz.html / fastq_1_2_3_4_5_6/B_Qfiltered/250905_batch19_02step_R1_Qfiltered.fastq.gz.json\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "JSON report: fastq_1_2_3_4_5_6/B_Qfiltered/250910_batch20_05step_R1_Qfiltered.fastq.gz.json\n",
      "HTML report: fastq_1_2_3_4_5_6/B_Qfiltered/250910_batch20_05step_R1_Qfiltered.fastq.gz.html\n",
      "\n",
      "fastp -i fastq_1_2_3_4_5_6/A_Untrimmed_output/250910_batch20_05step_R1_untrimmed.fastq.gz -o fastq_1_2_3_4_5_6/B_Qfiltered/250910_batch20_05step_R1_Qfiltered.fastq.gz -q 30 -u 15 --cut_mean_quality 30 --html fastq_1_2_3_4_5_6/B_Qfiltered/250910_batch20_05step_R1_Qfiltered.fastq.gz.html --json fastq_1_2_3_4_5_6/B_Qfiltered/250910_batch20_05step_R1_Qfiltered.fastq.gz.json \n",
      "fastp v0.23.4, time used: 0 seconds\n",
      "WARNING: you specified the options for cutting by quality, but forogt to enable any of cut_front/cut_tail/cut_right. This will have no effect.\n",
      "Detecting adapter sequence for read1...\n",
      "No adapter detected for read1\n",
      "\n",
      "Read1 before filtering:\n",
      "total reads: 3219\n",
      "total bases: 101569\n",
      "Q20 bases: 100677(99.1218%)\n",
      "Q30 bases: 98934(97.4057%)\n",
      "\n",
      "Read1 after filtering:\n",
      "total reads: 2960\n",
      "total bases: 94847\n",
      "Q20 bases: 94645(99.787%)\n",
      "Q30 bases: 93971(99.0764%)\n",
      "\n",
      "Filtering result:\n",
      "reads passed filter: 2960\n",
      "reads failed due to low quality: 190\n",
      "reads failed due to too many N: 0\n",
      "reads failed due to too short: 69\n",
      "reads with adapter trimmed: 0\n",
      "bases trimmed due to adapters: 0\n",
      "\n",
      "Duplication rate (may be overestimated since this is SE data): 97.2041%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering for 250910_batch20_05step_R1_untrimmed.fastq.gz is complete.\n",
      "Output FASTQ : fastq_1_2_3_4_5_6/B_Qfiltered/250910_batch20_05step_R1_Qfiltered.fastq.gz\n",
      "Reports      : fastq_1_2_3_4_5_6/B_Qfiltered/250910_batch20_05step_R1_Qfiltered.fastq.gz.html / fastq_1_2_3_4_5_6/B_Qfiltered/250910_batch20_05step_R1_Qfiltered.fastq.gz.json\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "JSON report: fastq_1_2_3_4_5_6/B_Qfiltered/250905_batch19_01step_R1_Qfiltered.fastq.gz.json\n",
      "HTML report: fastq_1_2_3_4_5_6/B_Qfiltered/250905_batch19_01step_R1_Qfiltered.fastq.gz.html\n",
      "\n",
      "fastp -i fastq_1_2_3_4_5_6/A_Untrimmed_output/250905_batch19_01step_R1_untrimmed.fastq.gz -o fastq_1_2_3_4_5_6/B_Qfiltered/250905_batch19_01step_R1_Qfiltered.fastq.gz -q 30 -u 15 --cut_mean_quality 30 --html fastq_1_2_3_4_5_6/B_Qfiltered/250905_batch19_01step_R1_Qfiltered.fastq.gz.html --json fastq_1_2_3_4_5_6/B_Qfiltered/250905_batch19_01step_R1_Qfiltered.fastq.gz.json \n",
      "fastp v0.23.4, time used: 0 seconds\n",
      "WARNING: you specified the options for cutting by quality, but forogt to enable any of cut_front/cut_tail/cut_right. This will have no effect.\n",
      "Detecting adapter sequence for read1...\n",
      "No adapter detected for read1\n",
      "\n",
      "Read1 before filtering:\n",
      "total reads: 2468\n",
      "total bases: 282991\n",
      "Q20 bases: 267052(94.3677%)\n",
      "Q30 bases: 252250(89.1371%)\n",
      "\n",
      "Read1 after filtering:\n",
      "total reads: 1954\n",
      "total bases: 214165\n",
      "Q20 bases: 210956(98.5016%)\n",
      "Q30 bases: 203983(95.2457%)\n",
      "\n",
      "Filtering result:\n",
      "reads passed filter: 1954\n",
      "reads failed due to low quality: 513\n",
      "reads failed due to too many N: 0\n",
      "reads failed due to too short: 1\n",
      "reads with adapter trimmed: 0\n",
      "bases trimmed due to adapters: 0\n",
      "\n",
      "Duplication rate (may be overestimated since this is SE data): 68.8817%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering for 250905_batch19_01step_R1_untrimmed.fastq.gz is complete.\n",
      "Output FASTQ : fastq_1_2_3_4_5_6/B_Qfiltered/250905_batch19_01step_R1_Qfiltered.fastq.gz\n",
      "Reports      : fastq_1_2_3_4_5_6/B_Qfiltered/250905_batch19_01step_R1_Qfiltered.fastq.gz.html / fastq_1_2_3_4_5_6/B_Qfiltered/250905_batch19_01step_R1_Qfiltered.fastq.gz.json\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "JSON report: fastq_1_2_3_4_5_6/B_Qfiltered/250910_batch20_05step_R2_Qfiltered.fastq.gz.json\n",
      "HTML report: fastq_1_2_3_4_5_6/B_Qfiltered/250910_batch20_05step_R2_Qfiltered.fastq.gz.html\n",
      "\n",
      "fastp -i fastq_1_2_3_4_5_6/A_Untrimmed_output/250910_batch20_05step_R2_untrimmed.fastq.gz -o fastq_1_2_3_4_5_6/B_Qfiltered/250910_batch20_05step_R2_Qfiltered.fastq.gz -q 30 -u 15 --cut_mean_quality 30 --html fastq_1_2_3_4_5_6/B_Qfiltered/250910_batch20_05step_R2_Qfiltered.fastq.gz.html --json fastq_1_2_3_4_5_6/B_Qfiltered/250910_batch20_05step_R2_Qfiltered.fastq.gz.json \n",
      "fastp v0.23.4, time used: 0 seconds\n",
      "WARNING: you specified the options for cutting by quality, but forogt to enable any of cut_front/cut_tail/cut_right. This will have no effect.\n",
      "Detecting adapter sequence for read1...\n",
      "No adapter detected for read1\n",
      "\n",
      "Read1 before filtering:\n",
      "total reads: 3219\n",
      "total bases: 147116\n",
      "Q20 bases: 132119(89.806%)\n",
      "Q30 bases: 125160(85.0757%)\n",
      "\n",
      "Read1 after filtering:\n",
      "total reads: 2724\n",
      "total bases: 95886\n",
      "Q20 bases: 95762(99.8707%)\n",
      "Q30 bases: 95123(99.2043%)\n",
      "\n",
      "Filtering result:\n",
      "reads passed filter: 2724\n",
      "reads failed due to low quality: 430\n",
      "reads failed due to too many N: 0\n",
      "reads failed due to too short: 65\n",
      "reads with adapter trimmed: 0\n",
      "bases trimmed due to adapters: 0\n",
      "\n",
      "Duplication rate (may be overestimated since this is SE data): 88.5057%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering for 250910_batch20_05step_R2_untrimmed.fastq.gz is complete.\n",
      "Output FASTQ : fastq_1_2_3_4_5_6/B_Qfiltered/250910_batch20_05step_R2_Qfiltered.fastq.gz\n",
      "Reports      : fastq_1_2_3_4_5_6/B_Qfiltered/250910_batch20_05step_R2_Qfiltered.fastq.gz.html / fastq_1_2_3_4_5_6/B_Qfiltered/250910_batch20_05step_R2_Qfiltered.fastq.gz.json\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "JSON report: fastq_1_2_3_4_5_6/B_Qfiltered/250905_batch19_01step_R2_Qfiltered.fastq.gz.json\n",
      "HTML report: fastq_1_2_3_4_5_6/B_Qfiltered/250905_batch19_01step_R2_Qfiltered.fastq.gz.html\n",
      "\n",
      "fastp -i fastq_1_2_3_4_5_6/A_Untrimmed_output/250905_batch19_01step_R2_untrimmed.fastq.gz -o fastq_1_2_3_4_5_6/B_Qfiltered/250905_batch19_01step_R2_Qfiltered.fastq.gz -q 30 -u 15 --cut_mean_quality 30 --html fastq_1_2_3_4_5_6/B_Qfiltered/250905_batch19_01step_R2_Qfiltered.fastq.gz.html --json fastq_1_2_3_4_5_6/B_Qfiltered/250905_batch19_01step_R2_Qfiltered.fastq.gz.json \n",
      "fastp v0.23.4, time used: 1 seconds\n",
      "WARNING: you specified the options for cutting by quality, but forogt to enable any of cut_front/cut_tail/cut_right. This will have no effect.\n",
      "Detecting adapter sequence for read1...\n",
      "No adapter detected for read1\n",
      "\n",
      "Read1 before filtering:\n",
      "total reads: 2741\n",
      "total bases: 267462\n",
      "Q20 bases: 255423(95.4988%)\n",
      "Q30 bases: 247215(92.43%)\n",
      "\n",
      "Read1 after filtering:\n",
      "total reads: 2374\n",
      "total bases: 219665\n",
      "Q20 bases: 218813(99.6121%)\n",
      "Q30 bases: 215981(98.3229%)\n",
      "\n",
      "Filtering result:\n",
      "reads passed filter: 2374\n",
      "reads failed due to low quality: 364\n",
      "reads failed due to too many N: 0\n",
      "reads failed due to too short: 3\n",
      "reads with adapter trimmed: 0\n",
      "bases trimmed due to adapters: 0\n",
      "\n",
      "Duplication rate (may be overestimated since this is SE data): 80.4816%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering for 250905_batch19_01step_R2_untrimmed.fastq.gz is complete.\n",
      "Output FASTQ : fastq_1_2_3_4_5_6/B_Qfiltered/250905_batch19_01step_R2_Qfiltered.fastq.gz\n",
      "Reports      : fastq_1_2_3_4_5_6/B_Qfiltered/250905_batch19_01step_R2_Qfiltered.fastq.gz.html / fastq_1_2_3_4_5_6/B_Qfiltered/250905_batch19_01step_R2_Qfiltered.fastq.gz.json\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "JSON report: fastq_1_2_3_4_5_6/B_Qfiltered/250905_batch19_04step_R2_Qfiltered.fastq.gz.json\n",
      "HTML report: fastq_1_2_3_4_5_6/B_Qfiltered/250905_batch19_04step_R2_Qfiltered.fastq.gz.html\n",
      "\n",
      "fastp -i fastq_1_2_3_4_5_6/A_Untrimmed_output/250905_batch19_04step_R2_untrimmed.fastq.gz -o fastq_1_2_3_4_5_6/B_Qfiltered/250905_batch19_04step_R2_Qfiltered.fastq.gz -q 30 -u 15 --cut_mean_quality 30 --html fastq_1_2_3_4_5_6/B_Qfiltered/250905_batch19_04step_R2_Qfiltered.fastq.gz.html --json fastq_1_2_3_4_5_6/B_Qfiltered/250905_batch19_04step_R2_Qfiltered.fastq.gz.json \n",
      "fastp v0.23.4, time used: 0 seconds\n",
      "WARNING: you specified the options for cutting by quality, but forogt to enable any of cut_front/cut_tail/cut_right. This will have no effect.\n",
      "Detecting adapter sequence for read1...\n",
      "No adapter detected for read1\n",
      "\n",
      "Read1 before filtering:\n",
      "total reads: 2706\n",
      "total bases: 194062\n",
      "Q20 bases: 191626(98.7447%)\n",
      "Q30 bases: 187949(96.85%)\n",
      "\n",
      "Read1 after filtering:\n",
      "total reads: 2530\n",
      "total bases: 181841\n",
      "Q20 bases: 181428(99.7729%)\n",
      "Q30 bases: 179808(98.882%)\n",
      "\n",
      "Filtering result:\n",
      "reads passed filter: 2530\n",
      "reads failed due to low quality: 159\n",
      "reads failed due to too many N: 0\n",
      "reads failed due to too short: 17\n",
      "reads with adapter trimmed: 0\n",
      "bases trimmed due to adapters: 0\n",
      "\n",
      "Duplication rate (may be overestimated since this is SE data): 91.4265%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering for 250905_batch19_04step_R2_untrimmed.fastq.gz is complete.\n",
      "Output FASTQ : fastq_1_2_3_4_5_6/B_Qfiltered/250905_batch19_04step_R2_Qfiltered.fastq.gz\n",
      "Reports      : fastq_1_2_3_4_5_6/B_Qfiltered/250905_batch19_04step_R2_Qfiltered.fastq.gz.html / fastq_1_2_3_4_5_6/B_Qfiltered/250905_batch19_04step_R2_Qfiltered.fastq.gz.json\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "JSON report: fastq_1_2_3_4_5_6/B_Qfiltered/250905_batch19_03step_R1_Qfiltered.fastq.gz.json\n",
      "HTML report: fastq_1_2_3_4_5_6/B_Qfiltered/250905_batch19_03step_R1_Qfiltered.fastq.gz.html\n",
      "\n",
      "fastp -i fastq_1_2_3_4_5_6/A_Untrimmed_output/250905_batch19_03step_R1_untrimmed.fastq.gz -o fastq_1_2_3_4_5_6/B_Qfiltered/250905_batch19_03step_R1_Qfiltered.fastq.gz -q 30 -u 15 --cut_mean_quality 30 --html fastq_1_2_3_4_5_6/B_Qfiltered/250905_batch19_03step_R1_Qfiltered.fastq.gz.html --json fastq_1_2_3_4_5_6/B_Qfiltered/250905_batch19_03step_R1_Qfiltered.fastq.gz.json \n",
      "fastp v0.23.4, time used: 0 seconds\n",
      "WARNING: you specified the options for cutting by quality, but forogt to enable any of cut_front/cut_tail/cut_right. This will have no effect.\n",
      "Detecting adapter sequence for read1...\n",
      "No adapter detected for read1\n",
      "\n",
      "Read1 before filtering:\n",
      "total reads: 2741\n",
      "total bases: 252271\n",
      "Q20 bases: 248474(98.4949%)\n",
      "Q30 bases: 243090(96.3607%)\n",
      "\n",
      "Read1 after filtering:\n",
      "total reads: 2543\n",
      "total bases: 233407\n",
      "Q20 bases: 232739(99.7138%)\n",
      "Q30 bases: 230134(98.5977%)\n",
      "\n",
      "Filtering result:\n",
      "reads passed filter: 2543\n",
      "reads failed due to low quality: 195\n",
      "reads failed due to too many N: 0\n",
      "reads failed due to too short: 3\n",
      "reads with adapter trimmed: 0\n",
      "bases trimmed due to adapters: 0\n",
      "\n",
      "Duplication rate (may be overestimated since this is SE data): 87.158%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering for 250905_batch19_03step_R1_untrimmed.fastq.gz is complete.\n",
      "Output FASTQ : fastq_1_2_3_4_5_6/B_Qfiltered/250905_batch19_03step_R1_Qfiltered.fastq.gz\n",
      "Reports      : fastq_1_2_3_4_5_6/B_Qfiltered/250905_batch19_03step_R1_Qfiltered.fastq.gz.html / fastq_1_2_3_4_5_6/B_Qfiltered/250905_batch19_03step_R1_Qfiltered.fastq.gz.json\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "JSON report: fastq_1_2_3_4_5_6/B_Qfiltered/250905_batch19_04step_R1_Qfiltered.fastq.gz.json\n",
      "HTML report: fastq_1_2_3_4_5_6/B_Qfiltered/250905_batch19_04step_R1_Qfiltered.fastq.gz.html\n",
      "\n",
      "fastp -i fastq_1_2_3_4_5_6/A_Untrimmed_output/250905_batch19_04step_R1_untrimmed.fastq.gz -o fastq_1_2_3_4_5_6/B_Qfiltered/250905_batch19_04step_R1_Qfiltered.fastq.gz -q 30 -u 15 --cut_mean_quality 30 --html fastq_1_2_3_4_5_6/B_Qfiltered/250905_batch19_04step_R1_Qfiltered.fastq.gz.html --json fastq_1_2_3_4_5_6/B_Qfiltered/250905_batch19_04step_R1_Qfiltered.fastq.gz.json \n",
      "fastp v0.23.4, time used: 1 seconds\n",
      "WARNING: you specified the options for cutting by quality, but forogt to enable any of cut_front/cut_tail/cut_right. This will have no effect.\n",
      "Detecting adapter sequence for read1...\n",
      "No adapter detected for read1\n",
      "\n",
      "Read1 before filtering:\n",
      "total reads: 2706\n",
      "total bases: 219279\n",
      "Q20 bases: 201488(91.8866%)\n",
      "Q30 bases: 193152(88.085%)\n",
      "\n",
      "Read1 after filtering:\n",
      "total reads: 2289\n",
      "total bases: 167242\n",
      "Q20 bases: 166915(99.8045%)\n",
      "Q30 bases: 165479(98.9458%)\n",
      "\n",
      "Filtering result:\n",
      "reads passed filter: 2289\n",
      "reads failed due to low quality: 402\n",
      "reads failed due to too many N: 0\n",
      "reads failed due to too short: 15\n",
      "reads with adapter trimmed: 0\n",
      "bases trimmed due to adapters: 0\n",
      "\n",
      "Duplication rate (may be overestimated since this is SE data): 82.3725%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering for 250905_batch19_04step_R1_untrimmed.fastq.gz is complete.\n",
      "Output FASTQ : fastq_1_2_3_4_5_6/B_Qfiltered/250905_batch19_04step_R1_Qfiltered.fastq.gz\n",
      "Reports      : fastq_1_2_3_4_5_6/B_Qfiltered/250905_batch19_04step_R1_Qfiltered.fastq.gz.html / fastq_1_2_3_4_5_6/B_Qfiltered/250905_batch19_04step_R1_Qfiltered.fastq.gz.json\n",
      "\n",
      "Filtering for 250905_batch19_03step_R2_untrimmed.fastq.gz is complete.\n",
      "Output FASTQ : fastq_1_2_3_4_5_6/B_Qfiltered/250905_batch19_03step_R2_Qfiltered.fastq.gz\n",
      "Reports      : fastq_1_2_3_4_5_6/B_Qfiltered/250905_batch19_03step_R2_Qfiltered.fastq.gz.html / fastq_1_2_3_4_5_6/B_Qfiltered/250905_batch19_03step_R2_Qfiltered.fastq.gz.json\n",
      "\n",
      "All filtering processes are done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "JSON report: fastq_1_2_3_4_5_6/B_Qfiltered/250905_batch19_03step_R2_Qfiltered.fastq.gz.json\n",
      "HTML report: fastq_1_2_3_4_5_6/B_Qfiltered/250905_batch19_03step_R2_Qfiltered.fastq.gz.html\n",
      "\n",
      "fastp -i fastq_1_2_3_4_5_6/A_Untrimmed_output/250905_batch19_03step_R2_untrimmed.fastq.gz -o fastq_1_2_3_4_5_6/B_Qfiltered/250905_batch19_03step_R2_Qfiltered.fastq.gz -q 30 -u 15 --cut_mean_quality 30 --html fastq_1_2_3_4_5_6/B_Qfiltered/250905_batch19_03step_R2_Qfiltered.fastq.gz.html --json fastq_1_2_3_4_5_6/B_Qfiltered/250905_batch19_03step_R2_Qfiltered.fastq.gz.json \n",
      "fastp v0.23.4, time used: 0 seconds\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "# í’ˆì§ˆ ê¸°ì¤€(Q30)\n",
    "quality_threshold = 30\n",
    "\n",
    "# ì…ë ¥ í´ë”ì™€ ì¶œë ¥ í´ë” ì„¤ì •\n",
    "\n",
    "input_folder = \"fastq_1_2_3_4_5_6/A_Untrimmed_output\"\n",
    "output_folder = \"fastq_1_2_3_4_5_6/B_Qfiltered\"\n",
    "\n",
    "os.makedirs(output_folder, exist_ok=True)  # ì¶œë ¥ í´ë”ê°€ ì—†ìœ¼ë©´ ìƒì„±\n",
    "\n",
    "# ì…ë ¥ í´ë” ë‚´ íŒŒì¼ë“¤ì„ ìˆœíšŒí•˜ë©°, \"_trimmed.fastq.gz\"ë¡œ ëë‚˜ëŠ” íŒŒì¼ë§Œ ì²˜ë¦¬\n",
    "for filename in os.listdir(input_folder):\n",
    "    if filename.endswith(\"_untrimmed.fastq.gz\"):\n",
    "        # ì…ë ¥ íŒŒì¼ ê²½ë¡œ\n",
    "        input_file = os.path.join(input_folder, filename)\n",
    "        \n",
    "        # ì¶œë ¥ íŒŒì¼ ì´ë¦„(ì˜ˆ: sample_trimmed.fastq.gz -> sample_trimmed_filtered.fastq.gz)\n",
    "        output_file = os.path.join(\n",
    "            output_folder, \n",
    "            filename.replace(\"_untrimmed.fastq.gz\", \"_Qfiltered.fastq.gz\")\n",
    "        )\n",
    "        \n",
    "        # fastp ì‹¤í–‰ (ì‹±ê¸€ ì—”ë“œ ëª¨ë“œ)\n",
    "        subprocess.call([\n",
    "            \"fastp\",\n",
    "            \"-i\", input_file,               # ì…ë ¥ íŒŒì¼\n",
    "            \"-o\", output_file,              # ì¶œë ¥ íŒŒì¼\n",
    "            \"-q\", str(quality_threshold),   # Q30 ë¯¸ë§Œ í’ˆì§ˆ ì œê±°\n",
    "            \"-u\", \"15\",                      # low-quality base ë¹„ìœ¨ 20% ì´ìƒì´ë©´ read ì œê±°\n",
    "            #\"-l\", \"151\",                      # ìµœì†Œ read ê¸¸ì´\n",
    "            \"--cut_mean_quality\", \"30\",     # í‰ê·  Q<30ì´ë©´ read ì œê±°\n",
    "            \"--html\", f\"{output_file}.html\",  # HTML ë¦¬í¬íŠ¸\n",
    "            \"--json\", f\"{output_file}.json\"   # JSON ë¦¬í¬íŠ¸\n",
    "        ])\n",
    "        \n",
    "        print(f\"Filtering for {filename} is complete.\\n\"\n",
    "              f\"Output FASTQ : {output_file}\\n\"\n",
    "              f\"Reports      : {output_file}.html / {output_file}.json\\n\")\n",
    "\n",
    "print(\"All filtering processes are done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02151d72",
   "metadata": {},
   "source": [
    "# Quality check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3647a597",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import gzip\n",
    "# from Bio import SeqIO\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # ğŸ“ ì…ë ¥ í´ë”ì™€ ì¶œë ¥ í´ë” ì„¤ì •\n",
    "# input_folder = \"fastq_step/1_3_5_7_9_11/B_Qfiltered\"\n",
    "# output_csv_folder = \"fastq_step/1_3_5_7_9_11/B_Qfiltered/quality_stats_csv\"\n",
    "# output_plot_folder = \"fastq_step/1_3_5_7_9_11/B_Qfiltered/quality_plots\"\n",
    "# os.makedirs(output_csv_folder, exist_ok=True)\n",
    "# os.makedirs(output_plot_folder, exist_ok=True)\n",
    "\n",
    "# # ğŸ” í’ˆì§ˆ í†µê³„ ì¶”ì¶œ í•¨ìˆ˜\n",
    "# def compute_quality_stats(file_path):\n",
    "#     position_qualities = {}\n",
    "#     open_func = gzip.open if file_path.endswith(\".gz\") else open\n",
    "\n",
    "#     with open_func(file_path, \"rt\") as handle:\n",
    "#         for record in SeqIO.parse(handle, \"fastq\"):\n",
    "#             for i, q in enumerate(record.letter_annotations[\"phred_quality\"]):\n",
    "#                 position_qualities.setdefault(i, []).append(q)\n",
    "\n",
    "#     stats = []\n",
    "#     for pos in sorted(position_qualities):\n",
    "#         scores = np.array(position_qualities[pos])\n",
    "#         stats.append({\n",
    "#             \"position\": pos + 1,\n",
    "#             \"mean\": np.mean(scores),\n",
    "#             \"q1\": np.percentile(scores, 25),\n",
    "#             \"median\": np.median(scores),\n",
    "#             \"q3\": np.percentile(scores, 75),\n",
    "#             \"min\": np.min(scores),\n",
    "#             \"max\": np.max(scores)\n",
    "#         })\n",
    "#     return pd.DataFrame(stats)\n",
    "\n",
    "# # ğŸ“Š ë°°ê²½ ìƒ‰ìƒ í•¨ìˆ˜ (fastp ìŠ¤íƒ€ì¼)\n",
    "# def add_quality_background(ax):\n",
    "#     ax.axhspan(30, 40, facecolor='lightgreen', alpha=0.5)\n",
    "#     ax.axhspan(25, 30, facecolor='khaki', alpha=0.5)\n",
    "#     ax.axhspan(20, 25, facecolor='moccasin', alpha=0.5)\n",
    "#     ax.axhspan(0, 20, facecolor='lightcoral', alpha=0.5)\n",
    "\n",
    "# # ğŸ“‚ í´ë” ë‚´ ëª¨ë“  FASTQ(.gz í¬í•¨) ì²˜ë¦¬\n",
    "# for filename in os.listdir(input_folder):\n",
    "#     if filename.endswith(\".fastq\") or filename.endswith(\".fastq.gz\"):\n",
    "#         input_path = os.path.join(input_folder, filename)\n",
    "#         sample_name = os.path.splitext(filename)[0].replace(\".fastq\", \"\").replace(\".gz\", \"\")\n",
    "\n",
    "#         print(f\"ğŸ“Œ Processing: {sample_name}\")\n",
    "#         df = compute_quality_stats(input_path)\n",
    "\n",
    "#         # CSV ì €ì¥\n",
    "#         csv_path = os.path.join(output_csv_folder, f\"{sample_name}_quality.csv\")\n",
    "#         df.to_csv(csv_path, index=False)\n",
    "\n",
    "#         # ê·¸ë˜í”„ ì €ì¥\n",
    "#         plt.figure(figsize=(18, 8))\n",
    "#         ax = plt.gca()\n",
    "#         add_quality_background(ax)\n",
    "#         plt.plot(df[\"position\"], df[\"mean\"], color=\"blue\", linewidth=1.5, label=\"Mean Quality\")\n",
    "\n",
    "#         for i in range(len(df)):\n",
    "#             x = df.loc[i, \"position\"]\n",
    "#             q1 = df.loc[i, \"q1\"]\n",
    "#             q3 = df.loc[i, \"q3\"]\n",
    "#             plt.fill_between([x - 0.4, x + 0.4], [q1, q1], [q3, q3], color=\"yellow\", edgecolor=\"black\")\n",
    "\n",
    "#         plt.vlines(df[\"position\"], df[\"min\"], df[\"max\"], color=\"black\", linewidth=0.5)\n",
    "#         plt.title(f\"Quality scores across all bases: {sample_name}\", fontsize=14)\n",
    "#         plt.xlabel(\"Position in read (bp)\", fontsize=12)\n",
    "#         plt.ylabel(\"Quality score\", fontsize=12)\n",
    "#         plt.ylim(0, 40)\n",
    "#         plt.xlim(1, df[\"position\"].max())\n",
    "#         plt.legend()\n",
    "#         plt.tight_layout()\n",
    "#         plot_path = os.path.join(output_plot_folder, f\"{sample_name}_quality_plot.png\")\n",
    "#         plt.savefig(plot_path, dpi=300)\n",
    "#         plt.close()\n",
    "\n",
    "#         print(f\"âœ… Saved: {sample_name}_quality.csv and quality_plot.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ced46fb",
   "metadata": {},
   "source": [
    "# read count check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "92d17355",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import gzip\n",
    "# from Bio import SeqIO\n",
    "\n",
    "# # ë¶„ì„ ëŒ€ìƒ í´ë”\n",
    "# input_folder = \"fastq_step/1_3_5_7_9_11/B_Qfiltered\"  # ì—¬ê¸°ì— ëŒ€ìƒ í´ë” ê²½ë¡œë¥¼ ì…ë ¥í•˜ì„¸ìš”\n",
    "\n",
    "# # í—ˆìš© í™•ì¥ì\n",
    "# valid_extensions = [\".fastq\", \".fastq.gz\", \".fasta\", \".fasta.gz\"]\n",
    "\n",
    "# # í¬ë§· ê²°ì • í•¨ìˆ˜\n",
    "# def get_format(filename):\n",
    "#     if filename.endswith(\".fastq\") or filename.endswith(\".fastq.gz\"):\n",
    "#         return \"fastq\"\n",
    "#     elif filename.endswith(\".fasta\") or filename.endswith(\".fasta.gz\"):\n",
    "#         return \"fasta\"\n",
    "#     else:\n",
    "#         return None\n",
    "\n",
    "# # ê²°ê³¼ ì €ì¥ ë¦¬ìŠ¤íŠ¸\n",
    "# read_counts = []\n",
    "\n",
    "# # íŒŒì¼ ìˆœíšŒ ë° read ìˆ˜ ì¹´ìš´íŠ¸\n",
    "# for filename in os.listdir(input_folder):\n",
    "#     if any(filename.endswith(ext) for ext in valid_extensions):\n",
    "#         file_path = os.path.join(input_folder, filename)\n",
    "#         file_format = get_format(filename)\n",
    "#         open_func = gzip.open if filename.endswith(\".gz\") else open\n",
    "\n",
    "#         try:\n",
    "#             with open_func(file_path, \"rt\") as handle:\n",
    "#                 count = sum(1 for _ in SeqIO.parse(handle, file_format))\n",
    "#             read_counts.append((filename, count))\n",
    "#         except Exception as e:\n",
    "#             print(f\"âŒ Error processing {filename}: {e}\")\n",
    "\n",
    "# # ğŸ“„ íŒŒì¼ëª… ê¸°ì¤€ ì •ë ¬ í›„ ì¶œë ¥\n",
    "# read_counts.sort(key=lambda x: x[0].lower())  # íŒŒì¼ëª… ê¸°ì¤€ (ëŒ€ì†Œë¬¸ì êµ¬ë¶„ ì—†ì´) ì •ë ¬\n",
    "# for fname, count in read_counts:\n",
    "#     print(f\"{fname:40} : {count} reads\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34270d38",
   "metadata": {},
   "source": [
    "# ID matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0f915a10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 250905_batch19_01step_R1_Qfiltered.fastq.gz and 250905_batch19_01step_R2_Qfiltered.fastq.gz\n",
      "Total R1 IDs: 2960, Total R2 IDs: 2724, Matching IDs: 2660\n",
      "IDs only in R1: 300, IDs only in R2: 64\n",
      "\n",
      "Processing 250910_batch20_05step_R1_Qfiltered.fastq.gz and 250910_batch20_05step_R2_Qfiltered.fastq.gz\n",
      "Total R1 IDs: 2144, Total R2 IDs: 1954, Matching IDs: 1898\n",
      "IDs only in R1: 246, IDs only in R2: 56\n",
      "\n",
      "Processing 250905_batch19_04step_R1_Qfiltered.fastq.gz and 250905_batch19_04step_R2_Qfiltered.fastq.gz\n",
      "Total R1 IDs: 2543, Total R2 IDs: 2374, Matching IDs: 2328\n",
      "IDs only in R1: 215, IDs only in R2: 46\n",
      "\n",
      "Processing 250905_batch19_03step_R1_Qfiltered.fastq.gz and 250905_batch19_03step_R2_Qfiltered.fastq.gz\n",
      "Total R1 IDs: 2530, Total R2 IDs: 2289, Matching IDs: 2239\n",
      "IDs only in R1: 291, IDs only in R2: 50\n",
      "\n",
      "Processing 250905_batch19_02step_R1_Qfiltered.fastq.gz and 250905_batch19_02step_R2_Qfiltered.fastq.gz\n",
      "Total R1 IDs: 2457, Total R2 IDs: 2254, Matching IDs: 2192\n",
      "IDs only in R1: 265, IDs only in R2: 62\n",
      "\n",
      "Processing 250910_batch20_06step_R1_Qfiltered.fastq.gz and 250910_batch20_06step_R2_Qfiltered.fastq.gz\n",
      "Total R1 IDs: 1802, Total R2 IDs: 1654, Matching IDs: 1551\n",
      "IDs only in R1: 251, IDs only in R2: 103\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "import glob\n",
    "import os\n",
    "\n",
    "def extract_matching_reads(r1_path, r2_path, out_r1_path, out_r2_path):\n",
    "    def get_read_id(header):\n",
    "        # FASTQ headerì—ì„œ ID ì¶”ì¶œ\n",
    "        return header.split()[0].replace('/1', '').replace('/2', '')\n",
    "\n",
    "    r1_ids = set()\n",
    "    r2_ids = set()\n",
    "\n",
    "    with gzip.open(r1_path, 'rt') as r1_file:\n",
    "        while True:\n",
    "            header = r1_file.readline()\n",
    "            if not header:\n",
    "                break\n",
    "            r1_ids.add(get_read_id(header.strip()))\n",
    "            [r1_file.readline() for _ in range(3)]  # read ë‚˜ë¨¸ì§€ 3ì¤„ skip\n",
    "\n",
    "    with gzip.open(r2_path, 'rt') as r2_file:\n",
    "        while True:\n",
    "            header = r2_file.readline()\n",
    "            if not header:\n",
    "                break\n",
    "            r2_ids.add(get_read_id(header.strip()))\n",
    "            [r2_file.readline() for _ in range(3)]\n",
    "\n",
    "    matching_ids = r1_ids & r2_ids\n",
    "    r1_only = r1_ids - r2_ids\n",
    "    r2_only = r2_ids - r1_ids\n",
    "\n",
    "    print(f\"Processing {os.path.basename(r1_path)} and {os.path.basename(r2_path)}\")\n",
    "    print(f\"Total R1 IDs: {len(r1_ids)}, Total R2 IDs: {len(r2_ids)}, Matching IDs: {len(matching_ids)}\")\n",
    "    print(f\"IDs only in R1: {len(r1_only)}, IDs only in R2: {len(r2_only)}\\n\")\n",
    "\n",
    "    # ê²°ê³¼ í´ë” ìƒì„±\n",
    "    for out_path in [out_r1_path, out_r2_path]:\n",
    "        os.makedirs(os.path.dirname(out_path), exist_ok=True)\n",
    "\n",
    "    def write_matching_reads(input_path, output_path, matching_ids):\n",
    "        with gzip.open(input_path, 'rt') as infile, gzip.open(output_path, 'wt') as outfile:\n",
    "            while True:\n",
    "                lines = [infile.readline() for _ in range(4)]\n",
    "                if not lines[0]:\n",
    "                    break\n",
    "                read_id = get_read_id(lines[0].strip())\n",
    "                if read_id in matching_ids:\n",
    "                    outfile.writelines(lines)\n",
    "\n",
    "    write_matching_reads(r1_path, out_r1_path, matching_ids)\n",
    "    write_matching_reads(r2_path, out_r2_path, matching_ids)\n",
    "\n",
    "# ----------------------\n",
    "# ì „ì²´ íŒŒì¼ì— ëŒ€í•´ ì ìš©\n",
    "# ----------------------\n",
    "\n",
    "input_folder = \"fastq_1_2_3_4_5_6/B_Qfiltered\"\n",
    "output_folder = \"fastq_1_2_3_4_5_6/C_ID_matched\"\n",
    "\n",
    "# ëª¨ë“  R1 íŒŒì¼ ì°¾ê¸°\n",
    "r1_files = glob.glob(os.path.join(input_folder, \"*_R1_Qfiltered.fastq.gz\"))\n",
    "\n",
    "# ê° R1ì— ëŒ€í•´ ì§ì´ ë§ëŠ” R2ë¥¼ ì°¾ê³  ì‘ì—… ì‹¤í–‰\n",
    "for r1_file in r1_files:\n",
    "    r2_file = r1_file.replace(\"_R1_Qfiltered.fastq.gz\", \"_R2_Qfiltered.fastq.gz\")\n",
    "    \n",
    "    if os.path.exists(r2_file):\n",
    "        # ê²°ê³¼ output ê²½ë¡œ ì„¤ì •\n",
    "        base_name = os.path.basename(r1_file).replace(\"_R1_Qfiltered.fastq.gz\", \"\")\n",
    "        out_r1 = os.path.join(output_folder, f\"{base_name}_ID_match_R1.fastq.gz\")\n",
    "        out_r2 = os.path.join(output_folder, f\"{base_name}_ID_match_R2.fastq.gz\")\n",
    "        \n",
    "        # í•¨ìˆ˜ ì‹¤í–‰\n",
    "        extract_matching_reads(r1_file, r2_file, out_r1, out_r2)\n",
    "    else:\n",
    "        print(f\"Warning: {r2_file} not found. Skipping.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c26852",
   "metadata": {},
   "source": [
    "# read count check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "589fc281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import gzip\n",
    "# from Bio import SeqIO\n",
    "\n",
    "# # ë¶„ì„ ëŒ€ìƒ í´ë”\n",
    "# input_folder = \"fastq_step/1_3_5_7_9_11/C_ID_matched\"  # ì—¬ê¸°ì— ëŒ€ìƒ í´ë” ê²½ë¡œë¥¼ ì…ë ¥í•˜ì„¸ìš”\n",
    "\n",
    "# # í—ˆìš© í™•ì¥ì\n",
    "# valid_extensions = [\".fastq\", \".fastq.gz\", \".fasta\", \".fasta.gz\"]\n",
    "\n",
    "# # í¬ë§· ê²°ì • í•¨ìˆ˜\n",
    "# def get_format(filename):\n",
    "#     if filename.endswith(\".fastq\") or filename.endswith(\".fastq.gz\"):\n",
    "#         return \"fastq\"\n",
    "#     elif filename.endswith(\".fasta\") or filename.endswith(\".fasta.gz\"):\n",
    "#         return \"fasta\"\n",
    "#     else:\n",
    "#         return None\n",
    "\n",
    "# # ê²°ê³¼ ì €ì¥ ë¦¬ìŠ¤íŠ¸\n",
    "# read_counts = []\n",
    "\n",
    "# # íŒŒì¼ ìˆœíšŒ ë° read ìˆ˜ ì¹´ìš´íŠ¸\n",
    "# for filename in os.listdir(input_folder):\n",
    "#     if any(filename.endswith(ext) for ext in valid_extensions):\n",
    "#         file_path = os.path.join(input_folder, filename)\n",
    "#         file_format = get_format(filename)\n",
    "#         open_func = gzip.open if filename.endswith(\".gz\") else open\n",
    "\n",
    "#         try:\n",
    "#             with open_func(file_path, \"rt\") as handle:\n",
    "#                 count = sum(1 for _ in SeqIO.parse(handle, file_format))\n",
    "#             read_counts.append((filename, count))\n",
    "#         except Exception as e:\n",
    "#             print(f\"âŒ Error processing {filename}: {e}\")\n",
    "\n",
    "# # ğŸ“„ íŒŒì¼ëª… ê¸°ì¤€ ì •ë ¬ í›„ ì¶œë ¥\n",
    "# read_counts.sort(key=lambda x: x[0].lower())  # íŒŒì¼ëª… ê¸°ì¤€ (ëŒ€ì†Œë¬¸ì êµ¬ë¶„ ì—†ì´) ì •ë ¬\n",
    "# for fname, count in read_counts:\n",
    "#     print(f\"{fname:40} : {count} reads\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c1bd29",
   "metadata": {},
   "source": [
    "# Merge(Flash)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7c9d0055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Found 6 R1 files.\n",
      "ğŸ”µ Running FLASH for sample: 250910_batch20_05step_ID_match (N=116)\n",
      "[FLASH] Starting FLASH v1.2.11\n",
      "[FLASH] Fast Length Adjustment of SHort reads\n",
      "[FLASH]  \n",
      "[FLASH] Input files:\n",
      "[FLASH]     fastq_1_2_3_4_5_6/C_ID_matched/250910_batch20_05step_ID_match_R1.fastq.gz\n",
      "[FLASH]     fastq_1_2_3_4_5_6/C_ID_matched/250910_batch20_05step_ID_match_R2.fastq.gz\n",
      "[FLASH]  \n",
      "[FLASH] Output files:\n",
      "[FLASH]     fastq_1_2_3_4_5_6/D_merged_output/250910_batch20_05step_ID_match_FLASH.extendedFrags.fastq\n",
      "[FLASH]     fastq_1_2_3_4_5_6/D_merged_output/250910_batch20_05step_ID_match_FLASH.notCombined_1.fastq\n",
      "[FLASH]     fastq_1_2_3_4_5_6/D_merged_output/250910_batch20_05step_ID_match_FLASH.notCombined_2.fastq\n",
      "[FLASH]     fastq_1_2_3_4_5_6/D_merged_output/250910_batch20_05step_ID_match_FLASH.hist\n",
      "[FLASH]     fastq_1_2_3_4_5_6/D_merged_output/250910_batch20_05step_ID_match_FLASH.histogram\n",
      "[FLASH]  \n",
      "[FLASH] Parameters:\n",
      "[FLASH]     Min overlap:           116\n",
      "[FLASH]     Max overlap:           116\n",
      "[FLASH]     Max mismatch density:  0.250000\n",
      "[FLASH]     Allow \"outie\" pairs:   false\n",
      "[FLASH]     Cap mismatch quals:    false\n",
      "[FLASH]     Combiner threads:      4\n",
      "[FLASH]     Input format:          FASTQ, phred_offset=33\n",
      "[FLASH]     Output format:         FASTQ, phred_offset=33\n",
      "[FLASH]  \n",
      "[FLASH] Starting reader and writer threads\n",
      "[FLASH] Starting 4 combiner threads\n",
      "[FLASH] Processed 1898 read pairs\n",
      "[FLASH]  \n",
      "[FLASH] Read combination statistics:\n",
      "[FLASH]     Total pairs:      1898\n",
      "[FLASH]     Combined pairs:   1178\n",
      "[FLASH]     Uncombined pairs: 720\n",
      "[FLASH]     Percent combined: 62.07%\n",
      "[FLASH]  \n",
      "[FLASH] Writing histogram files.\n",
      "[FLASH]  \n",
      "[FLASH] FLASH v1.2.11 complete!\n",
      "[FLASH] 0.033 seconds elapsed\n",
      "[FLASH] Finished with 1 warning (see above)\n",
      "âœ… FLASH merging complete â†’ fastq_1_2_3_4_5_6/D_merged_output/250910_batch20_05step_ID_match_FLASH.fastq\n",
      "ğŸ”µ Running FLASH for sample: 250905_batch19_02step_ID_match (N=52)\n",
      "[FLASH] Starting FLASH v1.2.11\n",
      "[FLASH] Fast Length Adjustment of SHort reads\n",
      "[FLASH]  \n",
      "[FLASH] Input files:\n",
      "[FLASH]     fastq_1_2_3_4_5_6/C_ID_matched/250905_batch19_02step_ID_match_R1.fastq.gz\n",
      "[FLASH]     fastq_1_2_3_4_5_6/C_ID_matched/250905_batch19_02step_ID_match_R2.fastq.gz\n",
      "[FLASH]  \n",
      "[FLASH] Output files:\n",
      "[FLASH]     fastq_1_2_3_4_5_6/D_merged_output/250905_batch19_02step_ID_match_FLASH.extendedFrags.fastq\n",
      "[FLASH]     fastq_1_2_3_4_5_6/D_merged_output/250905_batch19_02step_ID_match_FLASH.notCombined_1.fastq\n",
      "[FLASH]     fastq_1_2_3_4_5_6/D_merged_output/250905_batch19_02step_ID_match_FLASH.notCombined_2.fastq\n",
      "[FLASH]     fastq_1_2_3_4_5_6/D_merged_output/250905_batch19_02step_ID_match_FLASH.hist\n",
      "[FLASH]     fastq_1_2_3_4_5_6/D_merged_output/250905_batch19_02step_ID_match_FLASH.histogram\n",
      "[FLASH]  \n",
      "[FLASH] Parameters:\n",
      "[FLASH]     Min overlap:           52\n",
      "[FLASH]     Max overlap:           52\n",
      "[FLASH]     Max mismatch density:  0.250000\n",
      "[FLASH]     Allow \"outie\" pairs:   false\n",
      "[FLASH]     Cap mismatch quals:    false\n",
      "[FLASH]     Combiner threads:      4\n",
      "[FLASH]     Input format:          FASTQ, phred_offset=33\n",
      "[FLASH]     Output format:         FASTQ, phred_offset=33\n",
      "[FLASH]  \n",
      "[FLASH] Starting reader and writer threads\n",
      "[FLASH] Starting 4 combiner threads\n",
      "[FLASH] Processed 2192 read pairs\n",
      "[FLASH]  \n",
      "[FLASH] Read combination statistics:\n",
      "[FLASH]     Total pairs:      2192\n",
      "[FLASH]     Combined pairs:   1921\n",
      "[FLASH]     Uncombined pairs: 271\n",
      "[FLASH]     Percent combined: 87.64%\n",
      "[FLASH]  \n",
      "[FLASH] Writing histogram files.\n",
      "[FLASH]  \n",
      "[FLASH] FLASH v1.2.11 complete!\n",
      "[FLASH] 0.024 seconds elapsed\n",
      "âœ… FLASH merging complete â†’ fastq_1_2_3_4_5_6/D_merged_output/250905_batch19_02step_ID_match_FLASH.fastq\n",
      "ğŸ”µ Running FLASH for sample: 250905_batch19_03step_ID_match (N=74)\n",
      "[FLASH] Starting FLASH v1.2.11\n",
      "[FLASH] Fast Length Adjustment of SHort reads\n",
      "[FLASH]  \n",
      "[FLASH] Input files:\n",
      "[FLASH]     fastq_1_2_3_4_5_6/C_ID_matched/250905_batch19_03step_ID_match_R1.fastq.gz\n",
      "[FLASH]     fastq_1_2_3_4_5_6/C_ID_matched/250905_batch19_03step_ID_match_R2.fastq.gz\n",
      "[FLASH]  \n",
      "[FLASH] Output files:\n",
      "[FLASH]     fastq_1_2_3_4_5_6/D_merged_output/250905_batch19_03step_ID_match_FLASH.extendedFrags.fastq\n",
      "[FLASH]     fastq_1_2_3_4_5_6/D_merged_output/250905_batch19_03step_ID_match_FLASH.notCombined_1.fastq\n",
      "[FLASH]     fastq_1_2_3_4_5_6/D_merged_output/250905_batch19_03step_ID_match_FLASH.notCombined_2.fastq\n",
      "[FLASH]     fastq_1_2_3_4_5_6/D_merged_output/250905_batch19_03step_ID_match_FLASH.hist\n",
      "[FLASH]     fastq_1_2_3_4_5_6/D_merged_output/250905_batch19_03step_ID_match_FLASH.histogram\n",
      "[FLASH]  \n",
      "[FLASH] Parameters:\n",
      "[FLASH]     Min overlap:           74\n",
      "[FLASH]     Max overlap:           74\n",
      "[FLASH]     Max mismatch density:  0.250000\n",
      "[FLASH]     Allow \"outie\" pairs:   false\n",
      "[FLASH]     Cap mismatch quals:    false\n",
      "[FLASH]     Combiner threads:      4\n",
      "[FLASH]     Input format:          FASTQ, phred_offset=33\n",
      "[FLASH]     Output format:         FASTQ, phred_offset=33\n",
      "[FLASH]  \n",
      "[FLASH] Starting reader and writer threads\n",
      "[FLASH] Starting 4 combiner threads\n",
      "[FLASH] Processed 2239 read pairs\n",
      "[FLASH]  \n",
      "[FLASH] Read combination statistics:\n",
      "[FLASH]     Total pairs:      2239\n",
      "[FLASH]     Combined pairs:   1790\n",
      "[FLASH]     Uncombined pairs: 449\n",
      "[FLASH]     Percent combined: 79.95%\n",
      "[FLASH]  \n",
      "[FLASH] Writing histogram files.\n",
      "[FLASH]  \n",
      "[FLASH] FLASH v1.2.11 complete!\n",
      "[FLASH] 0.027 seconds elapsed\n",
      "âœ… FLASH merging complete â†’ fastq_1_2_3_4_5_6/D_merged_output/250905_batch19_03step_ID_match_FLASH.fastq\n",
      "ğŸ”µ Running FLASH for sample: 250905_batch19_01step_ID_match (N=32)\n",
      "[FLASH] Starting FLASH v1.2.11\n",
      "[FLASH] Fast Length Adjustment of SHort reads\n",
      "[FLASH]  \n",
      "[FLASH] Input files:\n",
      "[FLASH]     fastq_1_2_3_4_5_6/C_ID_matched/250905_batch19_01step_ID_match_R1.fastq.gz\n",
      "[FLASH]     fastq_1_2_3_4_5_6/C_ID_matched/250905_batch19_01step_ID_match_R2.fastq.gz\n",
      "[FLASH]  \n",
      "[FLASH] Output files:\n",
      "[FLASH]     fastq_1_2_3_4_5_6/D_merged_output/250905_batch19_01step_ID_match_FLASH.extendedFrags.fastq\n",
      "[FLASH]     fastq_1_2_3_4_5_6/D_merged_output/250905_batch19_01step_ID_match_FLASH.notCombined_1.fastq\n",
      "[FLASH]     fastq_1_2_3_4_5_6/D_merged_output/250905_batch19_01step_ID_match_FLASH.notCombined_2.fastq\n",
      "[FLASH]     fastq_1_2_3_4_5_6/D_merged_output/250905_batch19_01step_ID_match_FLASH.hist\n",
      "[FLASH]     fastq_1_2_3_4_5_6/D_merged_output/250905_batch19_01step_ID_match_FLASH.histogram\n",
      "[FLASH]  \n",
      "[FLASH] Parameters:\n",
      "[FLASH]     Min overlap:           32\n",
      "[FLASH]     Max overlap:           32\n",
      "[FLASH]     Max mismatch density:  0.250000\n",
      "[FLASH]     Allow \"outie\" pairs:   false\n",
      "[FLASH]     Cap mismatch quals:    false\n",
      "[FLASH]     Combiner threads:      4\n",
      "[FLASH]     Input format:          FASTQ, phred_offset=33\n",
      "[FLASH]     Output format:         FASTQ, phred_offset=33\n",
      "[FLASH]  \n",
      "[FLASH] Starting reader and writer threads\n",
      "[FLASH] Starting 4 combiner threads\n",
      "[FLASH] Processed 2660 read pairs\n",
      "[FLASH]  \n",
      "[FLASH] Read combination statistics:\n",
      "[FLASH]     Total pairs:      2660\n",
      "[FLASH]     Combined pairs:   2528\n",
      "[FLASH]     Uncombined pairs: 132\n",
      "[FLASH]     Percent combined: 95.04%\n",
      "[FLASH]  \n",
      "[FLASH] Writing histogram files.\n",
      "[FLASH]  \n",
      "[FLASH] FLASH v1.2.11 complete!\n",
      "[FLASH] 0.025 seconds elapsed\n",
      "âœ… FLASH merging complete â†’ fastq_1_2_3_4_5_6/D_merged_output/250905_batch19_01step_ID_match_FLASH.fastq\n",
      "ğŸ”µ Running FLASH for sample: 250910_batch20_06step_ID_match (N=136)\n",
      "[FLASH] Starting FLASH v1.2.11\n",
      "[FLASH] Fast Length Adjustment of SHort reads\n",
      "[FLASH]  \n",
      "[FLASH] Input files:\n",
      "[FLASH]     fastq_1_2_3_4_5_6/C_ID_matched/250910_batch20_06step_ID_match_R1.fastq.gz\n",
      "[FLASH]     fastq_1_2_3_4_5_6/C_ID_matched/250910_batch20_06step_ID_match_R2.fastq.gz\n",
      "[FLASH]  \n",
      "[FLASH] Output files:\n",
      "[FLASH]     fastq_1_2_3_4_5_6/D_merged_output/250910_batch20_06step_ID_match_FLASH.extendedFrags.fastq\n",
      "[FLASH]     fastq_1_2_3_4_5_6/D_merged_output/250910_batch20_06step_ID_match_FLASH.notCombined_1.fastq\n",
      "[FLASH]     fastq_1_2_3_4_5_6/D_merged_output/250910_batch20_06step_ID_match_FLASH.notCombined_2.fastq\n",
      "[FLASH]     fastq_1_2_3_4_5_6/D_merged_output/250910_batch20_06step_ID_match_FLASH.hist\n",
      "[FLASH]     fastq_1_2_3_4_5_6/D_merged_output/250910_batch20_06step_ID_match_FLASH.histogram\n",
      "[FLASH]  \n",
      "[FLASH] Parameters:\n",
      "[FLASH]     Min overlap:           136\n",
      "[FLASH]     Max overlap:           136\n",
      "[FLASH]     Max mismatch density:  0.250000\n",
      "[FLASH]     Allow \"outie\" pairs:   false\n",
      "[FLASH]     Cap mismatch quals:    false\n",
      "[FLASH]     Combiner threads:      4\n",
      "[FLASH]     Input format:          FASTQ, phred_offset=33\n",
      "[FLASH]     Output format:         FASTQ, phred_offset=33\n",
      "[FLASH]  \n",
      "[FLASH] Starting reader and writer threads\n",
      "[FLASH] Starting 4 combiner threads\n",
      "[FLASH] Processed 1551 read pairs\n",
      "[FLASH]  \n",
      "[FLASH] Read combination statistics:\n",
      "[FLASH]     Total pairs:      1551\n",
      "[FLASH]     Combined pairs:   690\n",
      "[FLASH]     Uncombined pairs: 861\n",
      "[FLASH]     Percent combined: 44.49%\n",
      "[FLASH]  \n",
      "[FLASH] Writing histogram files.\n",
      "[FLASH]  \n",
      "[FLASH] FLASH v1.2.11 complete!\n",
      "[FLASH] 0.030 seconds elapsed\n",
      "âœ… FLASH merging complete â†’ fastq_1_2_3_4_5_6/D_merged_output/250910_batch20_06step_ID_match_FLASH.fastq\n",
      "ğŸ”µ Running FLASH for sample: 250905_batch19_04step_ID_match (N=94)\n",
      "[FLASH] Starting FLASH v1.2.11\n",
      "[FLASH] Fast Length Adjustment of SHort reads\n",
      "[FLASH]  \n",
      "[FLASH] Input files:\n",
      "[FLASH]     fastq_1_2_3_4_5_6/C_ID_matched/250905_batch19_04step_ID_match_R1.fastq.gz\n",
      "[FLASH]     fastq_1_2_3_4_5_6/C_ID_matched/250905_batch19_04step_ID_match_R2.fastq.gz\n",
      "[FLASH]  \n",
      "[FLASH] Output files:\n",
      "[FLASH]     fastq_1_2_3_4_5_6/D_merged_output/250905_batch19_04step_ID_match_FLASH.extendedFrags.fastq\n",
      "[FLASH]     fastq_1_2_3_4_5_6/D_merged_output/250905_batch19_04step_ID_match_FLASH.notCombined_1.fastq\n",
      "[FLASH]     fastq_1_2_3_4_5_6/D_merged_output/250905_batch19_04step_ID_match_FLASH.notCombined_2.fastq\n",
      "[FLASH]     fastq_1_2_3_4_5_6/D_merged_output/250905_batch19_04step_ID_match_FLASH.hist\n",
      "[FLASH]     fastq_1_2_3_4_5_6/D_merged_output/250905_batch19_04step_ID_match_FLASH.histogram\n",
      "[FLASH]  \n",
      "[FLASH] Parameters:\n",
      "[FLASH]     Min overlap:           94\n",
      "[FLASH]     Max overlap:           94\n",
      "[FLASH]     Max mismatch density:  0.250000\n",
      "[FLASH]     Allow \"outie\" pairs:   false\n",
      "[FLASH]     Cap mismatch quals:    false\n",
      "[FLASH]     Combiner threads:      4\n",
      "[FLASH]     Input format:          FASTQ, phred_offset=33\n",
      "[FLASH]     Output format:         FASTQ, phred_offset=33\n",
      "[FLASH]  \n",
      "[FLASH] Starting reader and writer threads\n",
      "[FLASH] Starting 4 combiner threads\n",
      "[FLASH] Processed 2328 read pairs\n",
      "[FLASH]  \n",
      "[FLASH] Read combination statistics:\n",
      "[FLASH]     Total pairs:      2328\n",
      "[FLASH]     Combined pairs:   1786\n",
      "[FLASH]     Uncombined pairs: 542\n",
      "[FLASH]     Percent combined: 76.72%\n",
      "[FLASH]  \n",
      "[FLASH] Writing histogram files.\n",
      "[FLASH]  \n",
      "[FLASH] FLASH v1.2.11 complete!\n",
      "[FLASH] 0.036 seconds elapsed\n",
      "âœ… FLASH merging complete â†’ fastq_1_2_3_4_5_6/D_merged_output/250905_batch19_04step_ID_match_FLASH.fastq\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[FLASH] WARNING: An unexpectedly high proportion of combined pairs (16.04%)\n",
      "overlapped by more than 116 bp, the --max-overlap (-M) parameter.  Consider\n",
      "increasing this parameter.  (As-is, FLASH is penalizing overlaps longer than\n",
      "116 bp when considering them for possible combining!)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import subprocess\n",
    "\n",
    "# === í´ë” ì„¤ì • ===\n",
    "input_folder = \"fastq_1_2_3_4_5_6/C_ID_matched\"\n",
    "output_folder = \"fastq_1_2_3_4_5_6/D_merged_output\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# === Prefixë³„ Nê°’ ì„¤ì • ===\n",
    "sample_n_mapping = {\n",
    "    \"01step\": 32,#20+12\n",
    "    \"02step\": 52,#32+20\n",
    "    \"03step\": 74,#52+22\n",
    "    \"04step\": 94,#74+20\n",
    "    \"05step\": 116,#94+22\n",
    "    \"06step\": 136,#116+20\n",
    "\n",
    "}\n",
    "\n",
    "# === R1_B íŒŒì¼ ë¦¬ìŠ¤íŠ¸ ì°¾ê¸° ===\n",
    "r1_files = glob.glob(os.path.join(input_folder, \"*_R1.fastq.gz\"))\n",
    "\n",
    "print(f\"ğŸ” Found {len(r1_files)} R1 files.\")\n",
    "\n",
    "# === ê° R1_B íŒŒì¼ì— ëŒ€í•´ ===\n",
    "for r1_path in r1_files:\n",
    "    sample_base = os.path.basename(r1_path).replace(\"_R1.fastq.gz\", \"\")\n",
    "    r2_path = os.path.join(input_folder, f\"{sample_base}_R2.fastq.gz\")\n",
    "\n",
    "    if not os.path.exists(r2_path):\n",
    "        print(f\"âš ï¸ Matching R2 file not found for {sample_base} â†’ Skipping.\")\n",
    "        continue\n",
    "\n",
    "    # íŒŒì¼ ì´ë¦„ì— ë§ëŠ” Nê°’ ì°¾ê¸°\n",
    "    matched_n = None\n",
    "    for prefix, n_value in sample_n_mapping.items():\n",
    "        if prefix in sample_base:\n",
    "            matched_n = n_value\n",
    "            break\n",
    "\n",
    "    if matched_n is None:\n",
    "        print(f\"âš ï¸ No N value matched for {sample_base} â†’ Skipping.\")\n",
    "        continue\n",
    "\n",
    "    output_name = f\"{sample_base}_FLASH\"\n",
    "\n",
    "    print(f\"ğŸ”µ Running FLASH for sample: {sample_base} (N={matched_n})\")\n",
    "\n",
    "    try:\n",
    "        subprocess.check_call([\n",
    "            \"flash\",\n",
    "            \"-m\", str(matched_n),   # ìµœì†Œ overlap\n",
    "            \"-M\", str(matched_n),   # ìµœëŒ€ overlap\n",
    "            \"-o\", output_name,      # ê²°ê³¼ íŒŒì¼ prefix\n",
    "            \"-d\", output_folder,    # ê²°ê³¼ ì €ì¥ í´ë”\n",
    "            r1_path,\n",
    "            r2_path\n",
    "        ])\n",
    "        print(f\"âœ… FLASH merging complete â†’ {os.path.join(output_folder, output_name)}.fastq\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"âŒ FLASH merging failed for {sample_base}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d774d169",
   "metadata": {},
   "source": [
    "# Fastq to Fasta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "29a7fe75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted: 250905_batch19_04step_ID_match_FLASH.notCombined_2.fastq â†’ 250905_batch19_04step_ID_match_FLASH.notCombined_2.fasta\n",
      "Converted: 250905_batch19_02step_ID_match_FLASH.notCombined_2.fastq â†’ 250905_batch19_02step_ID_match_FLASH.notCombined_2.fasta\n",
      "Converted: 250905_batch19_01step_ID_match_FLASH.notCombined_2.fastq â†’ 250905_batch19_01step_ID_match_FLASH.notCombined_2.fasta\n",
      "Converted: 250905_batch19_01step_ID_match_FLASH.extendedFrags.fastq â†’ 250905_batch19_01step_ID_match_FLASH.extendedFrags.fasta\n",
      "Converted: 250905_batch19_02step_ID_match_FLASH.extendedFrags.fastq â†’ 250905_batch19_02step_ID_match_FLASH.extendedFrags.fasta\n",
      "Converted: 250905_batch19_04step_ID_match_FLASH.notCombined_1.fastq â†’ 250905_batch19_04step_ID_match_FLASH.notCombined_1.fasta\n",
      "Converted: 250905_batch19_04step_ID_match_FLASH.extendedFrags.fastq â†’ 250905_batch19_04step_ID_match_FLASH.extendedFrags.fasta\n",
      "Converted: 250905_batch19_02step_ID_match_FLASH.notCombined_1.fastq â†’ 250905_batch19_02step_ID_match_FLASH.notCombined_1.fasta\n",
      "Converted: 250905_batch19_01step_ID_match_FLASH.notCombined_1.fastq â†’ 250905_batch19_01step_ID_match_FLASH.notCombined_1.fasta\n",
      "Converted: 250905_batch19_03step_ID_match_FLASH.notCombined_1.fastq â†’ 250905_batch19_03step_ID_match_FLASH.notCombined_1.fasta\n",
      "Converted: 250910_batch20_05step_ID_match_FLASH.notCombined_2.fastq â†’ 250910_batch20_05step_ID_match_FLASH.notCombined_2.fasta\n",
      "Converted: 250905_batch19_03step_ID_match_FLASH.extendedFrags.fastq â†’ 250905_batch19_03step_ID_match_FLASH.extendedFrags.fasta\n",
      "Converted: 250910_batch20_06step_ID_match_FLASH.notCombined_2.fastq â†’ 250910_batch20_06step_ID_match_FLASH.notCombined_2.fasta\n",
      "Converted: 250910_batch20_06step_ID_match_FLASH.extendedFrags.fastq â†’ 250910_batch20_06step_ID_match_FLASH.extendedFrags.fasta\n",
      "Converted: 250910_batch20_05step_ID_match_FLASH.extendedFrags.fastq â†’ 250910_batch20_05step_ID_match_FLASH.extendedFrags.fasta\n",
      "Converted: 250905_batch19_03step_ID_match_FLASH.notCombined_2.fastq â†’ 250905_batch19_03step_ID_match_FLASH.notCombined_2.fasta\n",
      "Converted: 250910_batch20_05step_ID_match_FLASH.notCombined_1.fastq â†’ 250910_batch20_05step_ID_match_FLASH.notCombined_1.fasta\n",
      "Converted: 250910_batch20_06step_ID_match_FLASH.notCombined_1.fastq â†’ 250910_batch20_06step_ID_match_FLASH.notCombined_1.fasta\n",
      "All conversions are done.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gzip\n",
    "from Bio import SeqIO\n",
    "\n",
    "# ì…ë ¥ ë° ì¶œë ¥ í´ë” ê²½ë¡œ ì„¤ì •\n",
    "input_folder = \"fastq_1_2_3_4_5_6/D_merged_output\"\n",
    "output_folder = \"fastq_1_2_3_4_5_6/E_fastq_to_fasta\"\n",
    "\n",
    "os.makedirs(output_folder, exist_ok=True)  # ì¶œë ¥ í´ë” ìƒì„±\n",
    "\n",
    "for filename in os.listdir(input_folder):\n",
    "    # .fastq ë˜ëŠ” .fastq.gz í™•ì¥ì íŒŒì¼ë§Œ ì²˜ë¦¬\n",
    "    if filename.endswith(\".fastq\") or filename.endswith(\".fastq.gz\"):\n",
    "        input_file = os.path.join(input_folder, filename)\n",
    "        \n",
    "        # ì¶œë ¥ íŒŒì¼ëª… ì„¤ì • (.fasta í™•ì¥ì)\n",
    "        output_file = os.path.join(\n",
    "            output_folder,\n",
    "            filename.replace(\".fastq.gz\", \".fasta\").replace(\".fastq\", \".fasta\")\n",
    "        )\n",
    "\n",
    "        # íŒŒì¼ ì—´ê¸° ëª¨ë“œ ê²°ì • (gzip ì—¬ë¶€)\n",
    "        open_func = gzip.open if filename.endswith(\".gz\") else open\n",
    "\n",
    "        # FASTQ íŒŒì¼ ì½ì–´ì„œ FASTAë¡œ ë³€í™˜\n",
    "        with open_func(input_file, \"rt\") as fastq_file:  # í…ìŠ¤íŠ¸ ëª¨ë“œë¡œ ì—´ê¸°\n",
    "            records = list(SeqIO.parse(fastq_file, \"fastq\"))\n",
    "\n",
    "        # FASTA íŒŒì¼ë¡œ ì €ì¥\n",
    "        with open(output_file, \"w\") as fasta_file:\n",
    "            SeqIO.write(records, fasta_file, \"fasta\")\n",
    "\n",
    "        print(f\"Converted: {filename} â†’ {os.path.basename(output_file)}\")\n",
    "\n",
    "print(\"All conversions are done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c2bc7aed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250905_batch19_01step_ID_match_FLASH.extendedFrags.fasta :   2528 reads, Avg Length =  32.04 bp\n",
      "250905_batch19_01step_ID_match_FLASH.notCombined_1.fasta :    132 reads, Avg Length =   31.3 bp\n",
      "250905_batch19_01step_ID_match_FLASH.notCombined_2.fasta :    132 reads, Avg Length =  95.53 bp\n",
      "250905_batch19_02step_ID_match_FLASH.extendedFrags.fasta :   1921 reads, Avg Length =  52.13 bp\n",
      "250905_batch19_02step_ID_match_FLASH.notCombined_1.fasta :    271 reads, Avg Length =  43.08 bp\n",
      "250905_batch19_02step_ID_match_FLASH.notCombined_2.fasta :    271 reads, Avg Length =  53.74 bp\n",
      "250905_batch19_03step_ID_match_FLASH.extendedFrags.fasta :   1790 reads, Avg Length =  74.12 bp\n",
      "250905_batch19_03step_ID_match_FLASH.notCombined_1.fasta :    449 reads, Avg Length =  63.16 bp\n",
      "250905_batch19_03step_ID_match_FLASH.notCombined_2.fasta :    449 reads, Avg Length =  68.64 bp\n",
      "250905_batch19_04step_ID_match_FLASH.extendedFrags.fasta :   1786 reads, Avg Length =  94.24 bp\n",
      "250905_batch19_04step_ID_match_FLASH.notCombined_1.fasta :    542 reads, Avg Length =  83.57 bp\n",
      "250905_batch19_04step_ID_match_FLASH.notCombined_2.fasta :    542 reads, Avg Length =  86.83 bp\n",
      "250910_batch20_05step_ID_match_FLASH.extendedFrags.fasta :   1178 reads, Avg Length = 116.55 bp\n",
      "250910_batch20_05step_ID_match_FLASH.notCombined_1.fasta :    720 reads, Avg Length =  96.04 bp\n",
      "250910_batch20_05step_ID_match_FLASH.notCombined_2.fasta :    720 reads, Avg Length =  98.13 bp\n",
      "250910_batch20_06step_ID_match_FLASH.extendedFrags.fasta :    690 reads, Avg Length = 136.87 bp\n",
      "250910_batch20_06step_ID_match_FLASH.notCombined_1.fasta :    861 reads, Avg Length = 122.97 bp\n",
      "250910_batch20_06step_ID_match_FLASH.notCombined_2.fasta :    861 reads, Avg Length =  124.2 bp\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gzip\n",
    "from Bio import SeqIO\n",
    "\n",
    "# ë¶„ì„ ëŒ€ìƒ í´ë”\n",
    "input_folder = \"fastq_1_2_3_4_5_6/E_fastq_to_fasta\"\n",
    "\n",
    "# í—ˆìš© í™•ì¥ì: fastaë§Œ\n",
    "valid_extensions = [\".fasta\", \".fasta.gz\"]\n",
    "\n",
    "# íŒŒì¼ ì—´ê¸° í•¨ìˆ˜ ê²°ì •\n",
    "def get_format(filename):\n",
    "    if filename.endswith(\".fasta\") or filename.endswith(\".fasta.gz\"):\n",
    "        return \"fasta\"\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# ê²°ê³¼ ì €ì¥ ë¦¬ìŠ¤íŠ¸\n",
    "read_stats = []\n",
    "\n",
    "# íŒŒì¼ ìˆœíšŒ\n",
    "for filename in os.listdir(input_folder):\n",
    "    if any(filename.endswith(ext) for ext in valid_extensions):\n",
    "        file_path = os.path.join(input_folder, filename)\n",
    "        file_format = get_format(filename)\n",
    "        open_func = gzip.open if filename.endswith(\".gz\") else open\n",
    "\n",
    "        try:\n",
    "            total_len = 0\n",
    "            read_count = 0\n",
    "            with open_func(file_path, \"rt\") as handle:\n",
    "                for record in SeqIO.parse(handle, file_format):\n",
    "                    total_len += len(record.seq)\n",
    "                    read_count += 1\n",
    "            avg_length = total_len / read_count if read_count > 0 else 0\n",
    "            read_stats.append((filename, read_count, round(avg_length, 2)))\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Error processing {filename}: {e}\")\n",
    "\n",
    "# ì •ë ¬ ë° ì¶œë ¥\n",
    "read_stats.sort(key=lambda x: x[0].lower())\n",
    "for fname, count, avg_len in read_stats:\n",
    "    print(f\"{fname:40} : {count:6} reads, Avg Length = {avg_len:6} bp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa841a2",
   "metadata": {},
   "source": [
    "# step reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0b2e8019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… 01step FASTA saved: step_reference/01step_reference.fasta\n",
      "âœ… 02step FASTA saved: step_reference/02step_reference.fasta\n",
      "âœ… 03step FASTA saved: step_reference/03step_reference.fasta\n",
      "âœ… 04step FASTA saved: step_reference/04step_reference.fasta\n",
      "âœ… 05step FASTA saved: step_reference/05step_reference.fasta\n",
      "âœ… 06step FASTA saved: step_reference/06step_reference.fasta\n",
      "âœ… 07step FASTA saved: step_reference/07step_reference.fasta\n",
      "âœ… 08step FASTA saved: step_reference/08step_reference.fasta\n",
      "âœ… 09step FASTA saved: step_reference/09step_reference.fasta\n",
      "âœ… 10step FASTA saved: step_reference/10step_reference.fasta\n",
      "âœ… 11step FASTA saved: step_reference/11step_reference.fasta\n",
      "âœ… 12step FASTA saved: step_reference/12step_reference.fasta\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "def generate_sequences_for_bit(bit_length: int):\n",
    "    \"\"\"\n",
    "    íŠ¹ì • ë¹„íŠ¸ ìˆ˜(bit_length)ì— í•´ë‹¹í•˜ëŠ” ëª¨ë“  binary ì¡°í•©ì˜ DNA ì„œì—´ ìƒì„±\n",
    "    \"\"\"\n",
    "    sequences = {}\n",
    "\n",
    "    seq_0 = \"ACTCATATACACACTTAATC\"\n",
    "    seq_1 = \"ACTCATATACATACACTTAATC\"\n",
    "    prefix = \"ACACTTAATC\"\n",
    "\n",
    "    for i in range(2 ** bit_length):\n",
    "        binary_str = format(i, f'0{bit_length}b')\n",
    "        sequence = ''.join(seq_1 if bit == '1' else seq_0 for bit in binary_str)\n",
    "        full_sequence = prefix + sequence\n",
    "        seq_id = f\"seq_{i:04d}_{binary_str}\"\n",
    "        sequences[seq_id] = full_sequence\n",
    "\n",
    "    return sequences\n",
    "\n",
    "def write_fasta(sequences: dict, output_path: str):\n",
    "    \"\"\"FASTA íŒŒì¼ ìƒì„±\"\"\"\n",
    "    with open(output_path, \"w\") as f:\n",
    "        for seq_id, sequence in sequences.items():\n",
    "            f.write(f\">{seq_id}\\n{sequence}\\n\")\n",
    "\n",
    "# ===== ì„¤ì • =====\n",
    "output_dir = Path(\"step_reference\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "MAX_STEP = 12        # 1 ~ 12 step ìƒì„±\n",
    "PAD = len(str(MAX_STEP))  # íŒ¨ë”© í­(12 â†’ 2ìë¦¬)\n",
    "# =================\n",
    "\n",
    "for step in range(1, MAX_STEP + 1):\n",
    "    seqs = generate_sequences_for_bit(step)\n",
    "    out_name = output_dir / f\"{step:0{PAD}d}step_reference.fasta\"  # â†’ 01step_reference.fasta\n",
    "    write_fasta(seqs, out_name)\n",
    "    print(f\"âœ… {step:0{PAD}d}step FASTA saved: {out_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5d9aab",
   "metadata": {},
   "source": [
    "# fasta to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6f0aeee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Converted: 01step_reference.fasta â†’ 01step_reference.csv (rows=2, step=01)\n",
      "âœ… Converted: 02step_reference.fasta â†’ 02step_reference.csv (rows=4, step=02)\n",
      "âœ… Converted: 03step_reference.fasta â†’ 03step_reference.csv (rows=8, step=03)\n",
      "âœ… Converted: 04step_reference.fasta â†’ 04step_reference.csv (rows=16, step=04)\n",
      "âœ… Converted: 05step_reference.fasta â†’ 05step_reference.csv (rows=32, step=05)\n",
      "âœ… Converted: 06step_reference.fasta â†’ 06step_reference.csv (rows=64, step=06)\n",
      "âœ… Converted: 07step_reference.fasta â†’ 07step_reference.csv (rows=128, step=07)\n",
      "âœ… Converted: 08step_reference.fasta â†’ 08step_reference.csv (rows=256, step=08)\n",
      "âœ… Converted: 09step_reference.fasta â†’ 09step_reference.csv (rows=512, step=09)\n",
      "âœ… Converted: 10step_reference.fasta â†’ 10step_reference.csv (rows=1024, step=10)\n",
      "âœ… Converted: 11step_reference.fasta â†’ 11step_reference.csv (rows=2048, step=11)\n",
      "âœ… Converted: 12step_reference.fasta â†’ 12step_reference.csv (rows=4096, step=12)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import gzip\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from Bio import SeqIO\n",
    "\n",
    "STEP_RE = re.compile(r\"([0-9]+)step_reference\\.fasta(\\.gz)?$\", re.IGNORECASE)\n",
    "ID_RE   = re.compile(r\"^seq_(\\d{4})_([01]+)$\")  # seq_0000_000... í˜•íƒœ\n",
    "\n",
    "def parse_step_from_filename(fname: str):\n",
    "    \"\"\"\n",
    "    '01step_reference.fasta' / '12step_reference.fasta.gz' ì—ì„œ step ì •ìˆ˜ì™€ 0íŒ¨ë”© ë¬¸ìì—´ì„ ë°˜í™˜\n",
    "    \"\"\"\n",
    "    m = STEP_RE.search(fname)\n",
    "    if not m:\n",
    "        return None, None\n",
    "    step_str = m.group(1)            # e.g. '01'\n",
    "    step_int = int(step_str, 10)     # ì„ í–‰ 0 ì•ˆì „\n",
    "    return step_int, step_str\n",
    "\n",
    "def parse_id_fields(read_id: str):\n",
    "    \"\"\"\n",
    "    'seq_0007_000111' â†’ index=7, binary='000111'\n",
    "    ë§¤ì¹­ ì•ˆë˜ë©´ (None, None)\n",
    "    \"\"\"\n",
    "    m = ID_RE.match(read_id)\n",
    "    if not m:\n",
    "        return None, None\n",
    "    idx = int(m.group(1), 10)\n",
    "    binary = m.group(2)\n",
    "    return idx, binary\n",
    "\n",
    "def fasta_to_csv(fasta_path, csv_path, add_extra_cols=True):\n",
    "    \"\"\"\n",
    "    FASTA â†’ CSV ë³€í™˜\n",
    "    - gz ìë™ ì¸ì‹\n",
    "    - íŒŒì¼ëª…ì—ì„œ step ì¶”ì¶œ\n",
    "    - read_idì—ì„œ index/binary ì¶”ì¶œ\n",
    "    \"\"\"\n",
    "    fasta_path = Path(fasta_path)\n",
    "    csv_path = Path(csv_path)\n",
    "\n",
    "    step_int, step_str = parse_step_from_filename(fasta_path.name)\n",
    "    if step_int is None:\n",
    "        print(f\"âš ï¸  Skip (no step pattern): {fasta_path.name}\")\n",
    "        return\n",
    "\n",
    "    open_func = gzip.open if str(fasta_path).endswith(\".gz\") else open\n",
    "\n",
    "    rows = []\n",
    "    with open_func(fasta_path, \"rt\") as handle:\n",
    "        for record in SeqIO.parse(handle, \"fasta\"):\n",
    "            read_id = record.id\n",
    "            sequence = str(record.seq)\n",
    "            if add_extra_cols:\n",
    "                idx, binary = parse_id_fields(read_id)\n",
    "                rows.append([read_id, sequence, len(sequence), step_int, step_str, idx, binary])\n",
    "            else:\n",
    "                rows.append([read_id, sequence])\n",
    "\n",
    "    if add_extra_cols:\n",
    "        cols = [\"Read_ID\", \"Sequence\", \"SeqLen\", \"Step\", \"StepStr\", \"Index\", \"Binary\"]\n",
    "    else:\n",
    "        cols = [\"Read_ID\", \"Sequence\"]\n",
    "\n",
    "    df = pd.DataFrame(rows, columns=cols)\n",
    "    df.to_csv(csv_path, index=False)\n",
    "    print(f\"âœ… Converted: {fasta_path.name} â†’ {csv_path.name} (rows={len(df)}, step={step_str})\")\n",
    "\n",
    "def convert_all_fasta_in_folder(input_folder, output_folder, add_extra_cols=True):\n",
    "    \"\"\"\n",
    "    í´ë” ë‚´ *step_reference.fasta(.gz) ì „ë¶€ ë³€í™˜\n",
    "    ì¶œë ¥ íŒŒì¼ëª…ì€ ì…ë ¥ê³¼ ë™ì¼ ë² ì´ìŠ¤ì—ì„œ í™•ì¥ìë§Œ .csvë¡œ ë³€ê²½\n",
    "    (ì˜ˆ: 01step_reference.fasta â†’ 01step_reference.csv)\n",
    "    \"\"\"\n",
    "    input_folder = Path(input_folder)\n",
    "    output_folder = Path(output_folder)\n",
    "    output_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # step_referenceë§Œ ëŒ€ìƒìœ¼ë¡œ í•œì •\n",
    "    targets = sorted(list(input_folder.glob(\"*step_reference.fasta\")) +\n",
    "                     list(input_folder.glob(\"*step_reference.fasta.gz\")))\n",
    "\n",
    "    if not targets:\n",
    "        print(f\"âš ï¸  No step_reference fasta found in {input_folder}\")\n",
    "        return\n",
    "\n",
    "    for fp in targets:\n",
    "        out_name = fp.name.replace(\".fasta.gz\", \".csv\").replace(\".fasta\", \".csv\")\n",
    "        fasta_to_csv(fp, output_folder / out_name, add_extra_cols=add_extra_cols)\n",
    "\n",
    "# ğŸ“Œ ì‚¬ìš© ì˜ˆì‹œ\n",
    "input_folder = \"step_reference\"\n",
    "output_folder = \"step_reference/csv\"\n",
    "convert_all_fasta_in_folder(input_folder, output_folder, add_extra_cols=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceeeb22b",
   "metadata": {},
   "source": [
    "# length check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6dbd419b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01step_reference.fasta                   :      2 reads, Avg Length =   31.0 bp\n",
      "02step_reference.fasta                   :      4 reads, Avg Length =   52.0 bp\n",
      "03step_reference.fasta                   :      8 reads, Avg Length =   73.0 bp\n",
      "04step_reference.fasta                   :     16 reads, Avg Length =   94.0 bp\n",
      "05step_reference.fasta                   :     32 reads, Avg Length =  115.0 bp\n",
      "06step_reference.fasta                   :     64 reads, Avg Length =  136.0 bp\n",
      "07step_reference.fasta                   :    128 reads, Avg Length =  157.0 bp\n",
      "08step_reference.fasta                   :    256 reads, Avg Length =  178.0 bp\n",
      "09step_reference.fasta                   :    512 reads, Avg Length =  199.0 bp\n",
      "10step_reference.fasta                   :   1024 reads, Avg Length =  220.0 bp\n",
      "11step_reference.fasta                   :   2048 reads, Avg Length =  241.0 bp\n",
      "12step_reference.fasta                   :   4096 reads, Avg Length =  262.0 bp\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gzip\n",
    "from Bio import SeqIO\n",
    "\n",
    "# ë¶„ì„ ëŒ€ìƒ í´ë”\n",
    "input_folder = \"step_reference\"\n",
    "\n",
    "# í—ˆìš© í™•ì¥ì: fastaë§Œ\n",
    "valid_extensions = [\".fasta\", \".fasta.gz\"]\n",
    "\n",
    "# íŒŒì¼ ì—´ê¸° í•¨ìˆ˜ ê²°ì •\n",
    "def get_format(filename):\n",
    "    if filename.endswith(\".fasta\") or filename.endswith(\".fasta.gz\"):\n",
    "        return \"fasta\"\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# ê²°ê³¼ ì €ì¥ ë¦¬ìŠ¤íŠ¸\n",
    "read_stats = []\n",
    "\n",
    "# íŒŒì¼ ìˆœíšŒ\n",
    "for filename in os.listdir(input_folder):\n",
    "    if any(filename.endswith(ext) for ext in valid_extensions):\n",
    "        file_path = os.path.join(input_folder, filename)\n",
    "        file_format = get_format(filename)\n",
    "        open_func = gzip.open if filename.endswith(\".gz\") else open\n",
    "\n",
    "        try:\n",
    "            total_len = 0\n",
    "            read_count = 0\n",
    "            with open_func(file_path, \"rt\") as handle:\n",
    "                for record in SeqIO.parse(handle, file_format):\n",
    "                    total_len += len(record.seq)\n",
    "                    read_count += 1\n",
    "            avg_length = total_len / read_count if read_count > 0 else 0\n",
    "            read_stats.append((filename, read_count, round(avg_length, 2)))\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Error processing {filename}: {e}\")\n",
    "\n",
    "# ì •ë ¬ ë° ì¶œë ¥\n",
    "read_stats.sort(key=lambda x: x[0].lower())\n",
    "for fname, count, avg_len in read_stats:\n",
    "    print(f\"{fname:40} : {count:6} reads, Avg Length = {avg_len:6} bp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d44813",
   "metadata": {},
   "source": [
    "# bwa mem algorithm\n",
    "## reference align"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0625a0a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Indexing: step_reference/10step_reference.fasta\n",
      "ğŸ” Indexing: step_reference/09step_reference.fasta\n",
      "ğŸ” Indexing: step_reference/11step_reference.fasta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[bwa_index] Pack FASTA... 0.00 sec\n",
      "[bwa_index] Construct BWT for the packed sequence...\n",
      "[bwa_index] 0.01 seconds elapse.\n",
      "[bwa_index] Update BWT... 0.00 sec\n",
      "[bwa_index] Pack forward-only FASTA... 0.00 sec\n",
      "[bwa_index] Construct SA from BWT and Occ... 0.01 sec\n",
      "[main] Version: 0.7.17-r1188\n",
      "[main] CMD: bwa index step_reference/10step_reference.fasta\n",
      "[main] Real time: 0.110 sec; CPU: 0.030 sec\n",
      "[bwa_index] Pack FASTA... 0.00 sec\n",
      "[bwa_index] Construct BWT for the packed sequence...\n",
      "[bwa_index] 0.01 seconds elapse.\n",
      "[bwa_index] Update BWT... 0.00 sec\n",
      "[bwa_index] Pack forward-only FASTA... 0.00 sec\n",
      "[bwa_index] Construct SA from BWT and Occ... 0.00 sec\n",
      "[main] Version: 0.7.17-r1188\n",
      "[main] CMD: bwa index step_reference/09step_reference.fasta\n",
      "[main] Real time: 0.065 sec; CPU: 0.015 sec\n",
      "[bwa_index] Pack FASTA... 0.01 sec\n",
      "[bwa_index] Construct BWT for the packed sequence...\n",
      "[bwa_index] 0.03 seconds elapse.\n",
      "[bwa_index] Update BWT... 0.00 sec\n",
      "[bwa_index] Pack forward-only FASTA... 0.00 sec\n",
      "[bwa_index] Construct SA from BWT and Occ... 0.01 sec\n",
      "[main] Version: 0.7.17-r1188\n",
      "[main] CMD: bwa index step_reference/11step_reference.fasta\n",
      "[main] Real time: 0.168 sec; CPU: 0.058 sec\n",
      "[bwa_index] Pack FASTA... 0.00 sec\n",
      "[bwa_index] Construct BWT for the packed sequence...\n",
      "[bwa_index] 0.00 seconds elapse.\n",
      "[bwa_index] Update BWT... 0.00 sec\n",
      "[bwa_index] Pack forward-only FASTA... 0.00 sec\n",
      "[bwa_index] Construct SA from BWT and Occ... 0.00 sec\n",
      "[main] Version: 0.7.17-r1188\n",
      "[main] CMD: bwa index step_reference/08step_reference.fasta\n",
      "[main] Real time: 0.039 sec; CPU: 0.009 sec\n",
      "[bwa_index] Pack FASTA... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Indexing: step_reference/08step_reference.fasta\n",
      "ğŸ” Indexing: step_reference/12step_reference.fasta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.01 sec\n",
      "[bwa_index] Construct BWT for the packed sequence...\n",
      "[bwa_index] 0.06 seconds elapse.\n",
      "[bwa_index] Update BWT... 0.01 sec\n",
      "[bwa_index] Pack forward-only FASTA... 0.01 sec\n",
      "[bwa_index] Construct SA from BWT and Occ... 0.03 sec\n",
      "[main] Version: 0.7.17-r1188\n",
      "[main] CMD: bwa index step_reference/12step_reference.fasta\n",
      "[main] Real time: 0.337 sec; CPU: 0.121 sec\n",
      "[bwa_index] Pack FASTA... 0.00 sec\n",
      "[bwa_index] Construct BWT for the packed sequence...\n",
      "[bwa_index] 0.00 seconds elapse.\n",
      "[bwa_index] Update BWT... 0.00 sec\n",
      "[bwa_index] Pack forward-only FASTA... 0.00 sec\n",
      "[bwa_index] Construct SA from BWT and Occ... 0.00 sec\n",
      "[main] Version: 0.7.17-r1188\n",
      "[main] CMD: bwa index step_reference/02step_reference.fasta\n",
      "[main] Real time: 0.028 sec; CPU: 0.004 sec\n",
      "[bwa_index] Pack FASTA... 0.00 sec\n",
      "[bwa_index] Construct BWT for the packed sequence...\n",
      "[bwa_index] 0.00 seconds elapse.\n",
      "[bwa_index] Update BWT... 0.00 sec\n",
      "[bwa_index] Pack forward-only FASTA... 0.00 sec\n",
      "[bwa_index] Construct SA from BWT and Occ... 0.00 sec\n",
      "[main] Version: 0.7.17-r1188\n",
      "[main] CMD: bwa index step_reference/03step_reference.fasta\n",
      "[main] Real time: 0.024 sec; CPU: 0.003 sec\n",
      "[bwa_index] Pack FASTA... 0.00 sec\n",
      "[bwa_index] Construct BWT for the packed sequence...\n",
      "[bwa_index] 0.00 seconds elapse.\n",
      "[bwa_index] Update BWT... 0.00 sec\n",
      "[bwa_index] Pack forward-only FASTA... 0.00 sec\n",
      "[bwa_index] Construct SA from BWT and Occ... 0.00 sec\n",
      "[main] Version: 0.7.17-r1188\n",
      "[main] CMD: bwa index step_reference/01step_reference.fasta\n",
      "[main] Real time: 0.023 sec; CPU: 0.003 sec\n",
      "[bwa_index] Pack FASTA... 0.00 sec\n",
      "[bwa_index] Construct BWT for the packed sequence...\n",
      "[bwa_index] 0.00 seconds elapse.\n",
      "[bwa_index] Update BWT... 0.00 sec\n",
      "[bwa_index] Pack forward-only FASTA... 0.00 sec\n",
      "[bwa_index] Construct SA from BWT and Occ... 0.00 sec\n",
      "[main] Version: 0.7.17-r1188\n",
      "[main] CMD: bwa index step_reference/07step_reference.fasta\n",
      "[main] Real time: 0.029 sec; CPU: 0.005 sec\n",
      "[bwa_index] Pack FASTA... 0.00 sec\n",
      "[bwa_index] Construct BWT for the packed sequence...\n",
      "[bwa_index] 0.00 seconds elapse.\n",
      "[bwa_index] Update BWT... 0.00 sec\n",
      "[bwa_index] Pack forward-only FASTA... 0.00 sec\n",
      "[bwa_index] Construct SA from BWT and Occ... 0.00 sec\n",
      "[main] Version: 0.7.17-r1188\n",
      "[main] CMD: bwa index step_reference/06step_reference.fasta\n",
      "[main] Real time: 0.026 sec; CPU: 0.004 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Indexing: step_reference/02step_reference.fasta\n",
      "ğŸ” Indexing: step_reference/03step_reference.fasta\n",
      "ğŸ” Indexing: step_reference/01step_reference.fasta\n",
      "ğŸ” Indexing: step_reference/07step_reference.fasta\n",
      "ğŸ” Indexing: step_reference/06step_reference.fasta\n",
      "ğŸ” Indexing: step_reference/05step_reference.fasta\n",
      "ğŸ” Indexing: step_reference/04step_reference.fasta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[bwa_index] Pack FASTA... 0.00 sec\n",
      "[bwa_index] Construct BWT for the packed sequence...\n",
      "[bwa_index] 0.00 seconds elapse.\n",
      "[bwa_index] Update BWT... 0.00 sec\n",
      "[bwa_index] Pack forward-only FASTA... 0.00 sec\n",
      "[bwa_index] Construct SA from BWT and Occ... 0.00 sec\n",
      "[main] Version: 0.7.17-r1188\n",
      "[main] CMD: bwa index step_reference/05step_reference.fasta\n",
      "[main] Real time: 0.027 sec; CPU: 0.003 sec\n",
      "[bwa_index] Pack FASTA... 0.00 sec\n",
      "[bwa_index] Construct BWT for the packed sequence...\n",
      "[bwa_index] 0.00 seconds elapse.\n",
      "[bwa_index] Update BWT... 0.00 sec\n",
      "[bwa_index] Pack forward-only FASTA... 0.00 sec\n",
      "[bwa_index] Construct SA from BWT and Occ... 0.00 sec\n",
      "[main] Version: 0.7.17-r1188\n",
      "[main] CMD: bwa index step_reference/04step_reference.fasta\n",
      "[main] Real time: 0.024 sec; CPU: 0.003 sec\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "ref_dir = \"step_reference\"\n",
    "\n",
    "for filename in os.listdir(ref_dir):\n",
    "    if filename.endswith(\".fasta\"):\n",
    "        fasta_path = os.path.join(ref_dir, filename)\n",
    "        print(f\"ğŸ” Indexing: {fasta_path}\")\n",
    "        subprocess.run([\"bwa\", \"index\", fasta_path])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0fd56fd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” file: 250905_batch19_01step_ID_match_FLASH.extendedFrags.fasta | step=01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[bwa_index] Pack FASTA... 0.00 sec\n",
      "[bwa_index] Construct BWT for the packed sequence...\n",
      "[bwa_index] 0.00 seconds elapse.\n",
      "[bwa_index] Update BWT... 0.00 sec\n",
      "[bwa_index] Pack forward-only FASTA... 0.00 sec\n",
      "[bwa_index] Construct SA from BWT and Occ... 0.00 sec\n",
      "[main] Version: 0.7.17-r1188\n",
      "[main] CMD: bwa index step_reference/01step_reference.fasta\n",
      "[main] Real time: 0.042 sec; CPU: 0.004 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”„ Aligning to 01step_reference.fasta ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[M::bwa_idx_load_from_disk] read 0 ALT contigs\n",
      "[M::process] read 2528 sequences (80989 bp)...\n",
      "[M::mem_process_seqs] Processed 2528 reads in 0.010 CPU sec, 0.005 real sec\n",
      "[main] Version: 0.7.17-r1188\n",
      "[main] CMD: bwa mem -M -t 4 step_reference/01step_reference.fasta fastq_1_2_3_4_5_6/E_fastq_to_fasta/250905_batch19_01step_ID_match_FLASH.extendedFrags.fasta\n",
      "[main] Real time: 0.059 sec; CPU: 0.016 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Done: fastq_1_2_3_4_5_6/1_align_sam/250905_batch19_01step_ID_match_FLASH.extendedFrags.sam\n",
      "ğŸ” file: 250905_batch19_02step_ID_match_FLASH.extendedFrags.fasta | step=02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[bwa_index] Pack FASTA... 0.00 sec\n",
      "[bwa_index] Construct BWT for the packed sequence...\n",
      "[bwa_index] 0.00 seconds elapse.\n",
      "[bwa_index] Update BWT... 0.00 sec\n",
      "[bwa_index] Pack forward-only FASTA... 0.00 sec\n",
      "[bwa_index] Construct SA from BWT and Occ... 0.00 sec\n",
      "[main] Version: 0.7.17-r1188\n",
      "[main] CMD: bwa index step_reference/02step_reference.fasta\n",
      "[main] Real time: 0.028 sec; CPU: 0.004 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”„ Aligning to 02step_reference.fasta ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[M::bwa_idx_load_from_disk] read 0 ALT contigs\n",
      "[M::process] read 1921 sequences (100150 bp)...\n",
      "[M::mem_process_seqs] Processed 1921 reads in 0.049 CPU sec, 0.019 real sec\n",
      "[main] Version: 0.7.17-r1188\n",
      "[main] CMD: bwa mem -M -t 4 step_reference/02step_reference.fasta fastq_1_2_3_4_5_6/E_fastq_to_fasta/250905_batch19_02step_ID_match_FLASH.extendedFrags.fasta\n",
      "[main] Real time: 0.095 sec; CPU: 0.056 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Done: fastq_1_2_3_4_5_6/1_align_sam/250905_batch19_02step_ID_match_FLASH.extendedFrags.sam\n",
      "ğŸ” file: 250905_batch19_03step_ID_match_FLASH.extendedFrags.fasta | step=03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[bwa_index] Pack FASTA... 0.00 sec\n",
      "[bwa_index] Construct BWT for the packed sequence...\n",
      "[bwa_index] 0.00 seconds elapse.\n",
      "[bwa_index] Update BWT... 0.00 sec\n",
      "[bwa_index] Pack forward-only FASTA... 0.00 sec\n",
      "[bwa_index] Construct SA from BWT and Occ... 0.00 sec\n",
      "[main] Version: 0.7.17-r1188\n",
      "[main] CMD: bwa index step_reference/03step_reference.fasta\n",
      "[main] Real time: 0.051 sec; CPU: 0.005 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”„ Aligning to 03step_reference.fasta ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[M::bwa_idx_load_from_disk] read 0 ALT contigs\n",
      "[M::process] read 1790 sequences (132667 bp)...\n",
      "[M::mem_process_seqs] Processed 1790 reads in 0.095 CPU sec, 0.030 real sec\n",
      "[main] Version: 0.7.17-r1188\n",
      "[main] CMD: bwa mem -M -t 4 step_reference/03step_reference.fasta fastq_1_2_3_4_5_6/E_fastq_to_fasta/250905_batch19_03step_ID_match_FLASH.extendedFrags.fasta\n",
      "[main] Real time: 0.099 sec; CPU: 0.101 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Done: fastq_1_2_3_4_5_6/1_align_sam/250905_batch19_03step_ID_match_FLASH.extendedFrags.sam\n",
      "ğŸ” file: 250905_batch19_04step_ID_match_FLASH.extendedFrags.fasta | step=04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[bwa_index] Pack FASTA... 0.00 sec\n",
      "[bwa_index] Construct BWT for the packed sequence...\n",
      "[bwa_index] 0.00 seconds elapse.\n",
      "[bwa_index] Update BWT... 0.00 sec\n",
      "[bwa_index] Pack forward-only FASTA... 0.00 sec\n",
      "[bwa_index] Construct SA from BWT and Occ... 0.00 sec\n",
      "[main] Version: 0.7.17-r1188\n",
      "[main] CMD: bwa index step_reference/04step_reference.fasta\n",
      "[main] Real time: 0.050 sec; CPU: 0.005 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”„ Aligning to 04step_reference.fasta ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[M::bwa_idx_load_from_disk] read 0 ALT contigs\n",
      "[M::process] read 1786 sequences (168310 bp)...\n",
      "[M::mem_process_seqs] Processed 1786 reads in 0.142 CPU sec, 0.051 real sec\n",
      "[main] Version: 0.7.17-r1188\n",
      "[main] CMD: bwa mem -M -t 4 step_reference/04step_reference.fasta fastq_1_2_3_4_5_6/E_fastq_to_fasta/250905_batch19_04step_ID_match_FLASH.extendedFrags.fasta\n",
      "[main] Real time: 0.121 sec; CPU: 0.150 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Done: fastq_1_2_3_4_5_6/1_align_sam/250905_batch19_04step_ID_match_FLASH.extendedFrags.sam\n",
      "ğŸ” file: 250910_batch20_05step_ID_match_FLASH.extendedFrags.fasta | step=05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[bwa_index] Pack FASTA... 0.00 sec\n",
      "[bwa_index] Construct BWT for the packed sequence...\n",
      "[bwa_index] 0.00 seconds elapse.\n",
      "[bwa_index] Update BWT... 0.00 sec\n",
      "[bwa_index] Pack forward-only FASTA... 0.00 sec\n",
      "[bwa_index] Construct SA from BWT and Occ... 0.00 sec\n",
      "[main] Version: 0.7.17-r1188\n",
      "[main] CMD: bwa index step_reference/05step_reference.fasta\n",
      "[main] Real time: 0.047 sec; CPU: 0.004 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”„ Aligning to 05step_reference.fasta ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[M::bwa_idx_load_from_disk] read 0 ALT contigs\n",
      "[M::process] read 1178 sequences (137298 bp)...\n",
      "[M::mem_process_seqs] Processed 1178 reads in 0.143 CPU sec, 0.054 real sec\n",
      "[main] Version: 0.7.17-r1188\n",
      "[main] CMD: bwa mem -M -t 4 step_reference/05step_reference.fasta fastq_1_2_3_4_5_6/E_fastq_to_fasta/250910_batch20_05step_ID_match_FLASH.extendedFrags.fasta\n",
      "[main] Real time: 0.110 sec; CPU: 0.150 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Done: fastq_1_2_3_4_5_6/1_align_sam/250910_batch20_05step_ID_match_FLASH.extendedFrags.sam\n",
      "ğŸ” file: 250910_batch20_06step_ID_match_FLASH.extendedFrags.fasta | step=06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[bwa_index] Pack FASTA... 0.00 sec\n",
      "[bwa_index] Construct BWT for the packed sequence...\n",
      "[bwa_index] 0.00 seconds elapse.\n",
      "[bwa_index] Update BWT... 0.00 sec\n",
      "[bwa_index] Pack forward-only FASTA... 0.00 sec\n",
      "[bwa_index] Construct SA from BWT and Occ... 0.00 sec\n",
      "[main] Version: 0.7.17-r1188\n",
      "[main] CMD: bwa index step_reference/06step_reference.fasta\n",
      "[main] Real time: 0.048 sec; CPU: 0.006 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”„ Aligning to 06step_reference.fasta ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[M::bwa_idx_load_from_disk] read 0 ALT contigs\n",
      "[M::process] read 690 sequences (94440 bp)...\n",
      "[M::mem_process_seqs] Processed 690 reads in 0.116 CPU sec, 0.037 real sec\n",
      "[main] Version: 0.7.17-r1188\n",
      "[main] CMD: bwa mem -M -t 4 step_reference/06step_reference.fasta fastq_1_2_3_4_5_6/E_fastq_to_fasta/250910_batch20_06step_ID_match_FLASH.extendedFrags.fasta\n",
      "[main] Real time: 0.075 sec; CPU: 0.121 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Done: fastq_1_2_3_4_5_6/1_align_sam/250910_batch20_06step_ID_match_FLASH.extendedFrags.sam\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "set -euo pipefail\n",
    "shopt -s nullglob\n",
    "\n",
    "ref_dir=\"step_reference\"\n",
    "query_dir=\"fastq_1_2_3_4_5_6/E_fastq_to_fasta\"\n",
    "output_dir=\"fastq_1_2_3_4_5_6/1_align_sam\"\n",
    "mkdir -p \"$output_dir\"\n",
    "\n",
    "# ê°™ì€ ì°¸ì¡°ëŠ” í•œ ë²ˆë§Œ index\n",
    "declare -A indexed\n",
    "\n",
    "# *_01step_* ì™€ *_04step_1_* ëª¨ë‘ ë§¤ì¹­ë˜ë„ë¡ ê¸€ë¡­ í™•ì¥\n",
    "for query_file in \"$query_dir\"/*step*ID_match_FLASH.extendedFrags.fasta; do\n",
    "  filename=\"$(basename \"$query_file\")\"\n",
    "\n",
    "  # íŒŒì¼ëª…ì—ì„œ step ë¬¸ìì—´ ì¶”ì¶œ: ..._NNstep( _ ë˜ëŠ” ë )\n",
    "  if [[ \"$filename\" =~ _([0-9]+)step(_|$) ]]; then\n",
    "    step_str=\"${BASH_REMATCH[1]}\"               # ì˜ˆ: \"01\" ë˜ëŠ” \"4\"\n",
    "  else\n",
    "    echo \"âš ï¸  step number not found in $filename\"\n",
    "    continue\n",
    "  fi\n",
    "\n",
    "  # 0íŒ¨ë”© í†µì¼(ë ˆí¼ëŸ°ìŠ¤ê°€ 01step_reference.fasta í˜•ì‹ì´ë¯€ë¡œ)\n",
    "  step_pad=$(printf \"%02d\" $((10#$step_str)))\n",
    "  reference_file=\"${ref_dir}/${step_pad}step_reference.fasta\"\n",
    "  output_file=\"${output_dir}/${filename%.fasta}.sam\"\n",
    "\n",
    "  if [[ ! -f \"$reference_file\" ]]; then\n",
    "    echo \"âš ï¸  Missing reference: $reference_file\"\n",
    "    continue\n",
    "  fi\n",
    "\n",
    "  echo \"ğŸ” file: $filename | step=${step_pad}\"\n",
    "  if [[ -z \"${indexed[$reference_file]:-}\" ]]; then\n",
    "    bwa index \"$reference_file\"\n",
    "    indexed[$reference_file]=1\n",
    "  fi\n",
    "\n",
    "  echo \"ğŸ”„ Aligning to $(basename \"$reference_file\") ...\"\n",
    "  bwa mem -M -t 4 \"$reference_file\" \"$query_file\" > \"$output_file\"\n",
    "  echo \"âœ… Done: $output_file\"\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247c5a20",
   "metadata": {},
   "source": [
    "# sam to bam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0d1bdfbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversion from fastq_1_2_3_4_5_6/1_align_sam/250905_batch19_01step_ID_match_FLASH.extendedFrags.sam to fastq_1_2_3_4_5_6/2_align_bam/250905_batch19_01step_ID_match_FLASH.extendedFrags.bam is complete.\n",
      "Conversion from fastq_1_2_3_4_5_6/1_align_sam/250905_batch19_02step_ID_match_FLASH.extendedFrags.sam to fastq_1_2_3_4_5_6/2_align_bam/250905_batch19_02step_ID_match_FLASH.extendedFrags.bam is complete.\n",
      "Conversion from fastq_1_2_3_4_5_6/1_align_sam/250905_batch19_03step_ID_match_FLASH.extendedFrags.sam to fastq_1_2_3_4_5_6/2_align_bam/250905_batch19_03step_ID_match_FLASH.extendedFrags.bam is complete.\n",
      "Conversion from fastq_1_2_3_4_5_6/1_align_sam/250905_batch19_04step_ID_match_FLASH.extendedFrags.sam to fastq_1_2_3_4_5_6/2_align_bam/250905_batch19_04step_ID_match_FLASH.extendedFrags.bam is complete.\n",
      "Conversion from fastq_1_2_3_4_5_6/1_align_sam/250910_batch20_05step_ID_match_FLASH.extendedFrags.sam to fastq_1_2_3_4_5_6/2_align_bam/250910_batch20_05step_ID_match_FLASH.extendedFrags.bam is complete.\n",
      "Conversion from fastq_1_2_3_4_5_6/1_align_sam/250910_batch20_06step_ID_match_FLASH.extendedFrags.sam to fastq_1_2_3_4_5_6/2_align_bam/250910_batch20_06step_ID_match_FLASH.extendedFrags.bam is complete.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "# Set the path to the directory containing SAM files\n",
    "sam_dir=\"fastq_1_2_3_4_5_6/1_align_sam\"\n",
    "# Set the output directory for BAM files\n",
    "bam_dir=\"fastq_1_2_3_4_5_6/2_align_bam\"\n",
    "\n",
    "\n",
    "# Make sure the output directory exists or create it if necessary\n",
    "mkdir -p \"$bam_dir\"\n",
    "\n",
    "# Convert SAM files to BAM\n",
    "for sam_file in \"$sam_dir\"/*.sam; do\n",
    "    bam_file=\"$bam_dir/$(basename \"$sam_file\" .sam).bam\"\n",
    "    samtools view -bS \"$sam_file\" -o \"$bam_file\"\n",
    "    echo \"Conversion from $sam_file to $bam_file is complete.\"\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a50049b",
   "metadata": {},
   "source": [
    "# bam file to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "abe6073c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fastq_1_2_3_4_5_6/3_align_csv/250905_batch19_03step_ID_match_FLASH.extendedFrags.csv',\n",
       " 'fastq_1_2_3_4_5_6/3_align_csv/250905_batch19_04step_ID_match_FLASH.extendedFrags.csv',\n",
       " 'fastq_1_2_3_4_5_6/3_align_csv/250905_batch19_02step_ID_match_FLASH.extendedFrags.csv',\n",
       " 'fastq_1_2_3_4_5_6/3_align_csv/250910_batch20_06step_ID_match_FLASH.extendedFrags.csv',\n",
       " 'fastq_1_2_3_4_5_6/3_align_csv/250910_batch20_05step_ID_match_FLASH.extendedFrags.csv',\n",
       " 'fastq_1_2_3_4_5_6/3_align_csv/250905_batch19_01step_ID_match_FLASH.extendedFrags.csv']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pysam\n",
    "import pandas as pd\n",
    "\n",
    "# ì…ë ¥ í´ë” (BAM íŒŒì¼ì´ ìœ„ì¹˜í•œ ê²½ë¡œ)\n",
    "input_folder = \"fastq_1_2_3_4_5_6/2_align_bam\"\n",
    "# ì¶œë ¥ í´ë” (CSV íŒŒì¼ì„ ì €ì¥í•  ê²½ë¡œ, í•„ìš”í•˜ë©´ ë³€ê²½)\n",
    "output_folder = \"fastq_1_2_3_4_5_6/3_align_csv\"\n",
    "\n",
    "\n",
    "# ì¶œë ¥ í´ë”ê°€ ì—†ìœ¼ë©´ ìƒì„±\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# BAM -> CSV ë³€í™˜ í•¨ìˆ˜ (ì˜µì…˜ í•„ë“œ í¬í•¨)\n",
    "def bam_to_csv(bam_file, output_folder):\n",
    "    output_csv = os.path.join(output_folder, os.path.basename(bam_file).replace(\".bam\", \".csv\"))\n",
    "    \n",
    "    # BAM íŒŒì¼ ì½ê¸°\n",
    "    with pysam.AlignmentFile(bam_file, \"rb\") as bam:\n",
    "        records = []\n",
    "        all_tags = set()  # ì˜µì…˜ í•„ë“œë¥¼ ì €ì¥í•  ì§‘í•©\n",
    "        \n",
    "        for read in bam:\n",
    "            # ê¸°ë³¸ í•„ë“œ\n",
    "            record = {\n",
    "                \"QNAME\": read.query_name,\n",
    "                \"FLAG\": read.flag,\n",
    "                \"RNAME\": bam.get_reference_name(read.reference_id) if read.reference_id >= 0 else \"*\",\n",
    "                \"POS\": read.reference_start + 1,\n",
    "                \"MAPQ\": read.mapping_quality,\n",
    "                \"CIGAR\": read.cigarstring if read.cigarstring else \"*\",\n",
    "                \"RNEXT\": bam.get_reference_name(read.next_reference_id) if read.next_reference_id >= 0 else \"*\",\n",
    "                \"PNEXT\": read.next_reference_start + 1 if read.next_reference_start >= 0 else 0,\n",
    "                \"TLEN\": read.template_length,\n",
    "                \"SEQ\": read.query_sequence if read.query_sequence else \"*\",\n",
    "                \"QUAL\": read.qual if read.qual else \"*\",\n",
    "            }\n",
    "            \n",
    "            # ì˜µì…˜ í•„ë“œ ì¶”ê°€\n",
    "            for tag, value in read.tags:\n",
    "                record[tag] = value\n",
    "                all_tags.add(tag)\n",
    "\n",
    "            records.append(record)\n",
    "    \n",
    "    # ë°ì´í„°í”„ë ˆì„ ìƒì„±\n",
    "    df = pd.DataFrame(records)\n",
    "\n",
    "    # ì˜µì…˜ í•„ë“œê°€ ì—†ëŠ” ê²½ìš° NaNìœ¼ë¡œ ì²˜ë¦¬\n",
    "    df = df.fillna(\"*\")\n",
    "\n",
    "    # CSV ì €ì¥\n",
    "    df.to_csv(output_csv, index=False)\n",
    "    return output_csv\n",
    "\n",
    "# í´ë”ì—ì„œ ëª¨ë“  BAM íŒŒì¼ ì°¾ê¸°\n",
    "bam_files = [os.path.join(input_folder, f) for f in os.listdir(input_folder) if f.endswith(\".bam\")]\n",
    "\n",
    "# ëª¨ë“  BAM íŒŒì¼ì„ CSVë¡œ ë³€í™˜\n",
    "csv_files = []\n",
    "for bam_file in bam_files:\n",
    "    csv_file = bam_to_csv(bam_file, output_folder)\n",
    "    csv_files.append(csv_file)\n",
    "\n",
    "# ë³€í™˜ëœ CSV íŒŒì¼ ëª©ë¡ ì¶œë ¥\n",
    "csv_files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6527e970",
   "metadata": {},
   "source": [
    "# remove MAPQ=0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "538ef777",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… 250905_batch19_01step_ID_match_FLASH.extendedFrags.csv â†’ 250905_batch19_01step_ID_match_FLASH.extendedFrags.csv | kept=2467, removed=61\n",
      "âœ… 250905_batch19_02step_ID_match_FLASH.extendedFrags.csv â†’ 250905_batch19_02step_ID_match_FLASH.extendedFrags.csv | kept=1914, removed=10\n",
      "âœ… 250905_batch19_03step_ID_match_FLASH.extendedFrags.csv â†’ 250905_batch19_03step_ID_match_FLASH.extendedFrags.csv | kept=1783, removed=7\n",
      "âœ… 250905_batch19_04step_ID_match_FLASH.extendedFrags.csv â†’ 250905_batch19_04step_ID_match_FLASH.extendedFrags.csv | kept=1771, removed=15\n",
      "âœ… 250910_batch20_05step_ID_match_FLASH.extendedFrags.csv â†’ 250910_batch20_05step_ID_match_FLASH.extendedFrags.csv | kept=1164, removed=17\n",
      "âœ… 250910_batch20_06step_ID_match_FLASH.extendedFrags.csv â†’ 250910_batch20_06step_ID_match_FLASH.extendedFrags.csv | kept=673, removed=17\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# ì…ë ¥/ì¶œë ¥ í´ë”\n",
    "input_dir = Path(\"fastq_1_2_3_4_5_6/3_align_csv\")\n",
    "output_dir = input_dir / \"MAPQ0_removed\"\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ì²˜ë¦¬ íŒŒë¼ë¯¸í„°\n",
    "CHUNKSIZE = 200_000   # íŒŒì¼ì´ í¬ë©´ ê°’ ëŠ˜ë¦¬ë©´ ë¨\n",
    "\n",
    "def process_one_csv(in_path: Path, out_path: Path):\n",
    "    \"\"\"\n",
    "    MAPQ=0 í–‰ ì œê±° í›„ out_pathë¡œ ì €ì¥ (chunked)\n",
    "    \"\"\"\n",
    "    # ê¸°ì¡´ íŒŒì¼ ìˆìœ¼ë©´ ì‚­ì œ(ë®ì–´ì“°ê¸°)\n",
    "    if out_path.exists():\n",
    "        out_path.unlink()\n",
    "\n",
    "    kept = 0\n",
    "    removed = 0\n",
    "    wrote_header = False\n",
    "\n",
    "    for chunk in pd.read_csv(in_path, chunksize=CHUNKSIZE):\n",
    "        if \"MAPQ\" not in chunk.columns:\n",
    "            print(f\"âš ï¸  Skip (no MAPQ column): {in_path.name}\")\n",
    "            return\n",
    "\n",
    "        # MAPQ ìˆ«ìë¡œ ë³€í™˜(ë¬¸ì/NaNì€ ë³´ì¡´; NaNì€ ì œê±° ëŒ€ìƒ ì•„ë‹˜)\n",
    "        m = pd.to_numeric(chunk[\"MAPQ\"], errors=\"coerce\")\n",
    "        # keep: MAPQ != 0 ë˜ëŠ” NaN\n",
    "        keep_mask = (m != 0) | m.isna()\n",
    "\n",
    "        removed += (~keep_mask).sum()\n",
    "        kept += keep_mask.sum()\n",
    "\n",
    "        out_chunk = chunk.loc[keep_mask]\n",
    "\n",
    "        # append ë°©ì‹ìœ¼ë¡œ ì €ì¥\n",
    "        out_chunk.to_csv(out_path, index=False, mode=\"a\", header=not wrote_header)\n",
    "        wrote_header = True\n",
    "\n",
    "    print(f\"âœ… {in_path.name} â†’ {out_path.name} | kept={kept}, removed={removed}\")\n",
    "\n",
    "# ëª¨ë“  csv ì²˜ë¦¬\n",
    "csv_files = sorted(p for p in input_dir.glob(\"*.csv\"))\n",
    "if not csv_files:\n",
    "    print(f\"âš ï¸  No CSV files in {input_dir}\")\n",
    "else:\n",
    "    for p in csv_files:\n",
    "        process_one_csv(p, output_dir / p.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4a0c21",
   "metadata": {},
   "source": [
    "# Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5c4724b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Saved cleaned RNAME histogram: fastq_1_2_3_4_5_6/4_align_histogram/histogram_250905_batch19_01step_.csv\n",
      "âœ… Saved cleaned RNAME histogram: fastq_1_2_3_4_5_6/4_align_histogram/histogram_250910_batch20_05step_.csv\n",
      "âœ… Saved cleaned RNAME histogram: fastq_1_2_3_4_5_6/4_align_histogram/histogram_250910_batch20_06step_.csv\n",
      "âœ… Saved cleaned RNAME histogram: fastq_1_2_3_4_5_6/4_align_histogram/histogram_250905_batch19_02step_.csv\n",
      "âœ… Saved cleaned RNAME histogram: fastq_1_2_3_4_5_6/4_align_histogram/histogram_250905_batch19_04step_.csv\n",
      "âœ… Saved cleaned RNAME histogram: fastq_1_2_3_4_5_6/4_align_histogram/histogram_250905_batch19_03step_.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# ğŸ“ í´ë” ì„¤ì •\n",
    "input_folder = \"fastq_1_2_3_4_5_6/3_align_csv/MAPQ0_removed\"\n",
    "histogram_folder = \"fastq_1_2_3_4_5_6/4_align_histogram\"\n",
    "os.makedirs(histogram_folder, exist_ok=True)\n",
    "\n",
    "# ğŸ“„ ëª¨ë“  CSV íŒŒì¼ ì²˜ë¦¬\n",
    "files = [f for f in os.listdir(input_folder) if f.endswith('.csv')]\n",
    "\n",
    "for file_name in files:\n",
    "    file_path = os.path.join(input_folder, file_name)\n",
    "\n",
    "    # ğŸ”§ íŒŒì¼ëª… í´ë Œì§• (íŠ¹ì • ë¬¸ìì—´ ì œê±°)\n",
    "    clean_name = file_name\n",
    "    clean_name = clean_name.replace(\"assemble\", \"\")\n",
    "    clean_name = clean_name.replace(\"ID_match_FLASH.extendedFrags\", \"\")\n",
    "    clean_name = clean_name.replace(\"__\", \"_\").strip(\"_\")  # ì¤‘ë³µ/ë _ ì œê±°\n",
    "    output_csv = os.path.join(histogram_folder, f\"histogram_{clean_name}\")\n",
    "\n",
    "    try:\n",
    "        df = pd.read_csv(file_path, dtype=str)\n",
    "        if 'RNAME' not in df.columns:\n",
    "            print(f\"âš ï¸ Skipping file: {file_name} (no 'RNAME' column found)\")\n",
    "            continue\n",
    "\n",
    "        # RNAME ì§‘ê³„ ë° ì •ê·œí™”\n",
    "        rname_counts = df['RNAME'].value_counts().reset_index()\n",
    "        rname_counts.columns = ['RNAME', 'Count']\n",
    "        rname_counts.insert(0, 'File_Name', clean_name)\n",
    "        rname_counts['Count'] = rname_counts['Count'].astype(int)\n",
    "        total_count = rname_counts['Count'].sum()\n",
    "        rname_counts['Normalized_Count'] = rname_counts['Count'] / total_count\n",
    "\n",
    "        rname_counts.to_csv(output_csv, index=False)\n",
    "        print(f\"âœ… Saved cleaned RNAME histogram: {output_csv}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error processing file '{file_name}': {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3b663461",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Saved plot: fastq_1_2_3_4_5_6/4_align_histogram/graph_top5/histogram_250910_batch20_05step_.png, fastq_1_2_3_4_5_6/4_align_histogram/graph_top5/histogram_250910_batch20_05step_.svg\n",
      "âœ… Saved plot: fastq_1_2_3_4_5_6/4_align_histogram/graph_top5/histogram_250905_batch19_01step_.png, fastq_1_2_3_4_5_6/4_align_histogram/graph_top5/histogram_250905_batch19_01step_.svg\n",
      "âœ… Saved plot: fastq_1_2_3_4_5_6/4_align_histogram/graph_top5/histogram_250905_batch19_04step_.png, fastq_1_2_3_4_5_6/4_align_histogram/graph_top5/histogram_250905_batch19_04step_.svg\n",
      "âœ… Saved plot: fastq_1_2_3_4_5_6/4_align_histogram/graph_top5/histogram_250910_batch20_06step_.png, fastq_1_2_3_4_5_6/4_align_histogram/graph_top5/histogram_250910_batch20_06step_.svg\n",
      "âœ… Saved plot: fastq_1_2_3_4_5_6/4_align_histogram/graph_top5/histogram_250905_batch19_03step_.png, fastq_1_2_3_4_5_6/4_align_histogram/graph_top5/histogram_250905_batch19_03step_.svg\n",
      "âœ… Saved plot: fastq_1_2_3_4_5_6/4_align_histogram/graph_top5/histogram_250905_batch19_02step_.png, fastq_1_2_3_4_5_6/4_align_histogram/graph_top5/histogram_250905_batch19_02step_.svg\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ğŸ“ í´ë” ì„¤ì •\n",
    "histogram_folder = \"fastq_1_2_3_4_5_6/4_align_histogram\"\n",
    "summary_folder = \"fastq_1_2_3_4_5_6/4_align_histogram/graph_top5\"\n",
    "os.makedirs(summary_folder, exist_ok=True)\n",
    "\n",
    "# ğŸ”´ í•˜ì´ë¼ì´íŠ¸ ë§¤í•‘ (suffix ê¸°ë°˜)\n",
    "highlight_mapping = {\n",
    "    \"_01step\": \"seq_0001_1\",\n",
    "    \"_02step\": \"seq_0002_10\",\n",
    "    \"_03step\": \"seq_0005_101\",\n",
    "    \"_04step\": \"seq_0010_1010\",\n",
    "    \"_05step\": \"seq_0021_10101\",\n",
    "    \"_06step\": \"seq_0042_101010\",\n",
    "    \"_07step\": \"seq_0085_1010101\",\n",
    "    \"_08step\": \"seq_0170_10101010\",\n",
    "}\n",
    "\n",
    "# ğŸ“„ CSV íŒŒì¼ ë¦¬ìŠ¤íŠ¸\n",
    "csv_files = [f for f in os.listdir(histogram_folder) if f.startswith(\"histogram_\") and f.endswith(\".csv\")]\n",
    "\n",
    "# ğŸ” íŒŒì¼ ë°˜ë³µ ì²˜ë¦¬\n",
    "for file_name in csv_files:\n",
    "    file_path = os.path.join(histogram_folder, file_name)\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        if 'RNAME' not in df.columns or 'Normalized_Count' not in df.columns:\n",
    "            print(f\"âš ï¸ Skipping file: {file_name} (missing column)\")\n",
    "            continue\n",
    "\n",
    "        # Top 5 RNAME ì¶”ì¶œ\n",
    "        top_df = df.sort_values(by=\"Count\", ascending=False).head(5).reset_index(drop=True)\n",
    "        sample_name = file_name.replace(\"histogram_\", \"\").replace(\".csv\", \"\")\n",
    "\n",
    "        # ğŸ” suffix ê¸°ë°˜ í•˜ì´ë¼ì´íŠ¸ RNAME ì°¾ê¸°\n",
    "        highlight_rname = None\n",
    "        for suffix, rname in highlight_mapping.items():\n",
    "            if suffix in file_name:\n",
    "                highlight_rname = rname\n",
    "                break\n",
    "\n",
    "        # ğŸ“Š ê·¸ë˜í”„ ìƒì„±\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        bars = plt.bar(top_df[\"RNAME\"], top_df[\"Normalized_Count\"], color='blue')\n",
    "\n",
    "        # ğŸ”´ ë§¤ì¹­ë˜ëŠ” RNAMEì€ ë¹¨ê°•ìƒ‰ìœ¼ë¡œ\n",
    "        for bar, rname in zip(bars, top_df[\"RNAME\"]):\n",
    "            if rname == highlight_rname:\n",
    "                bar.set_color('red')\n",
    "\n",
    "        plt.title(f\"Top 5 RNAME Histogram - {sample_name}\")\n",
    "        plt.xlabel(\"RNAME\")\n",
    "        plt.ylabel(\"Normalized Count\")\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.ylim(0, 1)\n",
    "        plt.tight_layout()\n",
    "\n",
    "        # ğŸ’¾ ì €ì¥\n",
    "        output_png = os.path.join(summary_folder, file_name.replace(\".csv\", \".png\"))\n",
    "        output_svg = os.path.join(summary_folder, file_name.replace(\".csv\", \".svg\"))\n",
    "        plt.savefig(output_png)\n",
    "        plt.savefig(output_svg)\n",
    "        plt.close()\n",
    "\n",
    "        print(f\"âœ… Saved plot: {output_png}, {output_svg}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error processing {file_name}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "75ae5f74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ì €ì¥ ì™„ë£Œ:\n",
      " - PNG: fastq_1_2_3_4_5_6/5_align_summary/stacked_bar_top5_gray_rest_white_box.png\n",
      " - SVG: fastq_1_2_3_4_5_6/5_align_summary/stacked_bar_top5_gray_rest_white_box.svg\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# í´ë” ì„¤ì •\n",
    "histogram_folder = \"fastq_1_2_3_4_5_6/4_align_histogram\"\n",
    "summary_folder = \"fastq_1_2_3_4_5_6/5_align_summary\"\n",
    "os.makedirs(summary_folder, exist_ok=True)\n",
    "\n",
    "# highlight ë§¤í•‘ (ì ‘ë¯¸ì‚¬ ê¸°ì¤€)\n",
    "highlight_mapping = {\n",
    "    \"_01step\": \"seq_0001_1\",\n",
    "    \"_02step\": \"seq_0002_10\",\n",
    "    \"_03step\": \"seq_0005_101\",\n",
    "    \"_04step\": \"seq_0010_1010\",\n",
    "    \"_05step\": \"seq_0021_10101\",\n",
    "    \"_06step\": \"seq_0042_101010\",\n",
    "    \"_07step\": \"seq_0085_1010101\",\n",
    "    \"_08step\": \"seq_0170_10101010\",\n",
    "}\n",
    "\n",
    "# íšŒìƒ‰ â†’ í°ìƒ‰ ê·¸ë¼ë°ì´ì…˜ ìƒ‰ìƒ í•¨ìˆ˜\n",
    "def blend_color(base_rgb, t):\n",
    "    white = np.array([255, 255, 255])\n",
    "    base = np.array(base_rgb)\n",
    "    blended = (1 - t) * base + t * white\n",
    "    return tuple(blended / 255)\n",
    "\n",
    "base_rgb = (137, 137, 138)\n",
    "\n",
    "# step ë²ˆí˜¸ë¥¼ ì¶”ì¶œí•˜ì—¬ ì˜¤ë¦„ì°¨ìˆœ ì •ë ¬ì„ ìœ„í•œ í•¨ìˆ˜\n",
    "def extract_step_number(name):\n",
    "    match = re.search(r'_(\\d+)step', name)\n",
    "    return int(match.group(1)) if match else float('inf')\n",
    "\n",
    "# sampleë³„ ë°ì´í„° ë¡œë”©\n",
    "sample_rname_dfs = {}\n",
    "for file_name in os.listdir(histogram_folder):\n",
    "    if file_name.startswith(\"histogram_\") and file_name.endswith(\".csv\"):\n",
    "        sample_name = file_name.replace(\"histogram_\", \"\").replace(\".csv\", \"\")\n",
    "        df = pd.read_csv(os.path.join(histogram_folder, file_name))\n",
    "        if 'RNAME' not in df.columns or 'Count' not in df.columns:\n",
    "            continue\n",
    "        df['Sample'] = sample_name\n",
    "        df['Count'] = df['Count'].astype(int)\n",
    "        df['Normalized_Count'] = df['Count'] / df['Count'].sum()\n",
    "        df = df.sort_values(by='Count', ascending=False).reset_index(drop=True)\n",
    "        sample_rname_dfs[sample_name] = df\n",
    "\n",
    "# sample_nameì„ step ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬\n",
    "sorted_samples = sorted(sample_rname_dfs.items(), key=lambda x: extract_step_number(x[0]))\n",
    "\n",
    "# ì‹œê°í™”\n",
    "fig, ax = plt.subplots(figsize=(24, 12))\n",
    "\n",
    "for sample_idx, (sample_name, df) in enumerate(sorted_samples):\n",
    "    # highlight RNAME ì°¾ê¸°\n",
    "    highlight_rname = None\n",
    "    for suffix, rname in highlight_mapping.items():\n",
    "        if suffix in sample_name:  # ì •í™•í•œ ëì´ ì•„ë‹ˆë¼ í¬í•¨ ì—¬ë¶€ë¡œ ìˆ˜ì •\n",
    "            highlight_rname = rname\n",
    "            break\n",
    "\n",
    "    bottom = 0\n",
    "    top_n = 5\n",
    "    rest_sum = 0\n",
    "\n",
    "    for rank, row in df.iterrows():\n",
    "        rname = row['RNAME']\n",
    "        height = row['Normalized_Count']\n",
    "\n",
    "        if rname == highlight_rname:\n",
    "            ax.bar(sample_name, height, bottom=bottom, color='red', edgecolor='black', linewidth=0.2)\n",
    "            bottom += height\n",
    "        elif rank < top_n:\n",
    "            t = rank / (top_n - 1) if top_n > 1 else 0\n",
    "            color = blend_color(base_rgb, t)\n",
    "            ax.bar(sample_name, height, bottom=bottom, color=color, edgecolor='black', linewidth=0.2)\n",
    "            bottom += height\n",
    "        else:\n",
    "            rest_sum += height\n",
    "\n",
    "    if rest_sum > 0:\n",
    "        ax.bar(sample_name, rest_sum, bottom=bottom, color='white', edgecolor='black', linewidth=0.2)\n",
    "\n",
    "# ë³´ì¡°ì„ , ìŠ¤íƒ€ì¼\n",
    "ax.axhline(y=0.5, color='gray', linestyle='--', linewidth=1, label='y = 0.5')\n",
    "ax.set_ylabel(\"Normalized Count\", fontsize=20)\n",
    "ax.set_xlabel(\"Sample\", fontsize=20)\n",
    "ax.set_title(\"Stacked Bar Chart (Red = Highlight, Grayâ†’White = Top 5, Rest = One White Box)\", fontsize=16)\n",
    "ax.tick_params(axis='x', labelsize=20)\n",
    "ax.tick_params(axis='y', labelsize=20)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "\n",
    "# ì €ì¥\n",
    "png_path = os.path.join(summary_folder, \"stacked_bar_top5_gray_rest_white_box.png\")\n",
    "svg_path = os.path.join(summary_folder, \"stacked_bar_top5_gray_rest_white_box.svg\")\n",
    "plt.savefig(png_path)\n",
    "plt.savefig(svg_path)\n",
    "plt.close()\n",
    "\n",
    "print(f\"âœ… ì €ì¥ ì™„ë£Œ:\\n - PNG: {png_path}\\n - SVG: {svg_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4c241be4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Œ Highlight summary saved to: fastq_1_2_3_4_5_6/5_align_summary/highlight_result.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# === Highlight mapping (suffix -> RNAME) ===\n",
    "highlight_mapping = {\n",
    "    \"_01step\": \"seq_0001_1\",\n",
    "    \"_02step\": \"seq_0002_10\",\n",
    "    \"_03step\": \"seq_0005_101\",\n",
    "    \"_04step\": \"seq_0010_1010\",\n",
    "    \"_05step\": \"seq_0021_10101\",\n",
    "    \"_06step\": \"seq_0042_101010\",\n",
    "    \"_07step\": \"seq_0085_1010101\",\n",
    "    \"_08step\": \"seq_0170_10101010\",\n",
    "}\n",
    "\n",
    "# === í´ë” ì„¤ì • ===\n",
    "histogram_folder = \"fastq_1_2_3_4_5_6/4_align_histogram\"\n",
    "summary_folder = \"fastq_1_2_3_4_5_6/5_align_summary\"\n",
    "os.makedirs(summary_folder, exist_ok=True)\n",
    "highlight_result_csv = os.path.join(summary_folder, \"highlight_result.csv\")\n",
    "\n",
    "# === step ë²ˆí˜¸ ì¶”ì¶œ í•¨ìˆ˜ ===\n",
    "def extract_step_number(filename):\n",
    "    match = re.search(r\"_(\\d+)step\", filename)\n",
    "    return int(match.group(1)) if match else float(\"inf\")\n",
    "\n",
    "# === Highlight ìš”ì•½ ì •ë³´ ìˆ˜ì§‘ ===\n",
    "highlight_data = []\n",
    "csv_files = [f for f in os.listdir(histogram_folder) if f.startswith(\"histogram_\") and f.endswith(\".csv\")]\n",
    "\n",
    "for file in csv_files:\n",
    "    file_path = os.path.join(histogram_folder, file)\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        file_name = file.replace(\"histogram_\", \"\")\n",
    "\n",
    "        # suffix ê¸°ë°˜ highlight_rname ì¶”ì¶œ\n",
    "        highlight_rname = \"\"\n",
    "        for suffix, rname in highlight_mapping.items():\n",
    "            if suffix in file_name:\n",
    "                highlight_rname = rname\n",
    "                break\n",
    "\n",
    "        df['Count'] = df['Count'].astype(int)\n",
    "        total_count = df['Count'].sum()\n",
    "\n",
    "        highlight_count = df[df['RNAME'] == highlight_rname]['Count'].sum() if highlight_rname else 0\n",
    "        highlight_percentage = (highlight_count / total_count) * 100 if total_count > 0 else 0\n",
    "\n",
    "        sorted_counts = df['Count'].sort_values(ascending=False).values\n",
    "        second_max_count = sorted_counts[1] if len(sorted_counts) >= 2 else (sorted_counts[0] if len(sorted_counts) == 1 else 0)\n",
    "        highlight_vs_second_ratio = (highlight_count / second_max_count) if second_max_count > 0 else 0\n",
    "\n",
    "        highlight_data.append([\n",
    "            file_name,\n",
    "            highlight_count,\n",
    "            total_count,\n",
    "            round(highlight_percentage, 2),\n",
    "            highlight_rname,\n",
    "            round(highlight_vs_second_ratio, 3),\n",
    "            extract_step_number(file_name)\n",
    "        ])\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error processing file '{file}': {e}\")\n",
    "\n",
    "# === DataFrame ìƒì„± ë° step ê¸°ì¤€ ì •ë ¬ í›„ ì €ì¥ ===\n",
    "highlight_df = pd.DataFrame(highlight_data, columns=[\n",
    "    'File',\n",
    "    'Highlight_Count',\n",
    "    'Total_Count',\n",
    "    'Highlight_Percentage',\n",
    "    'Highlight_RNAMEs',\n",
    "    'Highlight_vs_SecondTop_Ratio',\n",
    "    'Step_Number'\n",
    "])\n",
    "\n",
    "highlight_df = highlight_df.sort_values(by='Step_Number').drop(columns='Step_Number')\n",
    "highlight_df.to_csv(highlight_result_csv, index=False)\n",
    "\n",
    "print(f\"ğŸ“Œ Highlight summary saved to: {highlight_result_csv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d973acc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e4f861",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
