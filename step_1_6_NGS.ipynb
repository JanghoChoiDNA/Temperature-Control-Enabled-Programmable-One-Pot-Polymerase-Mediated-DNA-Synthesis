{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39189dfb",
   "metadata": {},
   "source": [
    "# 1. Install Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e906fe9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get:1 https://packages.microsoft.com/repos/code stable InRelease [3,590 B]\n",
      "Get:2 https://packages.microsoft.com/repos/code stable/main amd64 Packages [20.5 kB]\n",
      "Get:3 https://packages.microsoft.com/repos/code stable/main arm64 Packages [20.5 kB]\n",
      "Get:4 https://packages.microsoft.com/repos/code stable/main armhf Packages [20.6 kB]\n",
      "Hit:5 http://ports.ubuntu.com/ubuntu-ports noble InRelease                     \n",
      "Get:6 http://ports.ubuntu.com/ubuntu-ports noble-updates InRelease [126 kB]    \n",
      "Hit:7 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu noble InRelease   \n",
      "Get:8 http://ports.ubuntu.com/ubuntu-ports noble-backports InRelease [126 kB]\n",
      "Get:9 http://ports.ubuntu.com/ubuntu-ports noble-security InRelease [126 kB]\n",
      "Get:10 http://ports.ubuntu.com/ubuntu-ports noble-updates/main arm64 Packages [1,617 kB]\n",
      "Get:11 http://ports.ubuntu.com/ubuntu-ports noble-updates/main Translation-en [292 kB]\n",
      "Get:12 http://ports.ubuntu.com/ubuntu-ports noble-updates/main arm64 Components [172 kB]\n",
      "Get:13 http://ports.ubuntu.com/ubuntu-ports noble-updates/restricted Translation-en [489 kB]\n",
      "Get:14 http://ports.ubuntu.com/ubuntu-ports noble-updates/restricted arm64 Components [212 B]\n",
      "Get:15 http://ports.ubuntu.com/ubuntu-ports noble-updates/universe arm64 Components [376 kB]\n",
      "Get:16 http://ports.ubuntu.com/ubuntu-ports noble-updates/multiverse arm64 Components [212 B]\n",
      "Get:17 http://ports.ubuntu.com/ubuntu-ports noble-backports/main arm64 Components [3,584 B]\n",
      "Get:18 http://ports.ubuntu.com/ubuntu-ports noble-backports/restricted arm64 Components [212 B]\n",
      "Get:19 http://ports.ubuntu.com/ubuntu-ports noble-backports/universe arm64 Components [11.0 kB]\n",
      "Get:20 http://ports.ubuntu.com/ubuntu-ports noble-backports/multiverse arm64 Components [212 B]\n",
      "Get:21 http://ports.ubuntu.com/ubuntu-ports noble-security/main arm64 Components [18.4 kB]\n",
      "Get:22 http://ports.ubuntu.com/ubuntu-ports noble-security/restricted arm64 Components [212 B]\n",
      "Get:23 http://ports.ubuntu.com/ubuntu-ports noble-security/universe arm64 Components [52.3 kB]\n",
      "Get:24 http://ports.ubuntu.com/ubuntu-ports noble-security/multiverse arm64 Components [208 B]\n",
      "Fetched 3,477 kB in 6s (537 kB/s)                                              \n",
      "Reading package lists... Done\n",
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "fastp is already the newest version (0.23.4+dfsg-1).\n",
      "flash is already the newest version (1.2.11-2).\n",
      "bwa is already the newest version (0.7.17-7).\n",
      "samtools is already the newest version (1.19.2-1build2).\n",
      "The following packages were automatically installed and are no longer required:\n",
      "  pigz python3-xopen\n",
      "Use 'sudo apt autoremove' to remove them.\n",
      "0 upgraded, 0 newly installed, 0 to remove and 275 not upgraded.\n",
      "Requirement already satisfied: biopython in /usr/local/lib/python3.12/dist-packages (1.84)\n",
      "Requirement already satisfied: cutadapt in /usr/local/lib/python3.12/dist-packages (5.0)\n",
      "Requirement already satisfied: pysam in /usr/local/lib/python3.12/dist-packages (0.22.1)\n",
      "Requirement already satisfied: numpy in /usr/lib/python3/dist-packages (from biopython) (1.26.4)\n",
      "Requirement already satisfied: dnaio>=1.2.3 in /usr/local/lib/python3.12/dist-packages (from cutadapt) (1.2.3)\n",
      "Requirement already satisfied: xopen>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from cutadapt) (2.0.2)\n",
      "Requirement already satisfied: isal>=1.6.1 in /usr/local/lib/python3.12/dist-packages (from xopen>=1.6.0->cutadapt) (1.7.1)\n",
      "Requirement already satisfied: zlib-ng>=0.4.1 in /usr/local/lib/python3.12/dist-packages (from xopen>=1.6.0->cutadapt) (0.5.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# Bioinformatics Tools (Ubuntu)\n",
    "!sudo apt-get update\n",
    "!sudo apt-get install -y fastp flash bwa samtools\n",
    "\n",
    "# Python Library\n",
    "!pip3 install biopython cutadapt pysam --break-system-packages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd54a0a6",
   "metadata": {},
   "source": [
    "# 2. Trimming and Discard trimmed sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8ac5eda6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Untrimmed sequences saved: fastq_1_2_3_4_5_6/A_Untrimmed_output/Stepwise_01step_R1_untrimmed.fastq.gz, fastq_1_2_3_4_5_6/A_Untrimmed_output/Stepwise_01step_R2_untrimmed.fastq.gz\n",
      "Untrimmed sequences saved: fastq_1_2_3_4_5_6/A_Untrimmed_output/Stepwise_06step_R1_untrimmed.fastq.gz, fastq_1_2_3_4_5_6/A_Untrimmed_output/Stepwise_06step_R2_untrimmed.fastq.gz\n",
      "Untrimmed sequences saved: fastq_1_2_3_4_5_6/A_Untrimmed_output/Stepwise_03step_R1_untrimmed.fastq.gz, fastq_1_2_3_4_5_6/A_Untrimmed_output/Stepwise_03step_R2_untrimmed.fastq.gz\n",
      "Untrimmed sequences saved: fastq_1_2_3_4_5_6/A_Untrimmed_output/Stepwise_04step_R1_untrimmed.fastq.gz, fastq_1_2_3_4_5_6/A_Untrimmed_output/Stepwise_04step_R2_untrimmed.fastq.gz\n",
      "Untrimmed sequences saved: fastq_1_2_3_4_5_6/A_Untrimmed_output/Stepwise_05step_R1_untrimmed.fastq.gz, fastq_1_2_3_4_5_6/A_Untrimmed_output/Stepwise_05step_R2_untrimmed.fastq.gz\n",
      "Untrimmed sequences saved: fastq_1_2_3_4_5_6/A_Untrimmed_output/Stepwise_02step_R1_untrimmed.fastq.gz, fastq_1_2_3_4_5_6/A_Untrimmed_output/Stepwise_02step_R2_untrimmed.fastq.gz\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# Specify the folder containing your input files\n",
    "# Specify the folder where you want to save the untrimmed sequences (adapter-free sequences)\n",
    "input_folder = \"fastq_1_2_3_4_5_6\"\n",
    "untrimmed_output_folder = \"fastq_1_2_3_4_5_6/A_Untrimmed_output\"\n",
    "\n",
    "# Define the adapter sequences for R1 and R2\n",
    "adapter_sequence_r1 = \"AGATCGGAAGAGCACACGTCTGAACTCCAGTCAC\"\n",
    "adapter_sequence_r2 = \"AGATCGGAAGAGCGTCGTGTAGGGAAAGAGTGT\"\n",
    "\n",
    "# Use glob to get a list of all input file pairs (R1 and R2) in the folder\n",
    "input_file_pairs = []\n",
    "for input_r1 in glob.glob(os.path.join(input_folder, \"*_R1.fastq.gz\")):\n",
    "    # Assuming R2 files have the same naming format as R1 files\n",
    "    input_r2 = input_r1.replace(\"_R1.fastq.gz\", \"_R2.fastq.gz\")\n",
    "    if os.path.exists(input_r2):  # Ensure R2 file exists\n",
    "        input_file_pairs.append({\"r1\": input_r1, \"r2\": input_r2})\n",
    "\n",
    "# Create the output folder if it doesn't exist\n",
    "os.makedirs(untrimmed_output_folder, exist_ok=True)\n",
    "\n",
    "for input_files in input_file_pairs:\n",
    "    input_r1 = input_files[\"r1\"]\n",
    "    input_r2 = input_files[\"r2\"]\n",
    "\n",
    "    # Define output file paths for untrimmed (clean, adapter-free) sequences\n",
    "    untrimmed_r1 = os.path.join(untrimmed_output_folder, os.path.basename(input_r1).replace(\".fastq.gz\", \"_untrimmed.fastq.gz\"))\n",
    "    untrimmed_r2 = os.path.join(untrimmed_output_folder, os.path.basename(input_r2).replace(\".fastq.gz\", \"_untrimmed.fastq.gz\"))\n",
    "\n",
    "    # Use cutadapt to keep only untrimmed sequences (completely adapter-free)\n",
    "    result = subprocess.run([\n",
    "        \"cutadapt\",\n",
    "        \"-a\", adapter_sequence_r1,  # Adapter for R1\n",
    "        \"-A\", adapter_sequence_r2,  # Adapter for R2\n",
    "        \"-O\", \"15\",  # Minimum overlap for adapter trimming\n",
    "        #\"--discard-trimmed\",  # Discard sequences where trimming occurred\n",
    "        \"-o\", untrimmed_r1,  # Save only untrimmed R1 reads\n",
    "        \"-p\", untrimmed_r2,  # Save only untrimmed R2 reads\n",
    "        input_r1, input_r2\n",
    "    ], capture_output=True, text=True)\n",
    "\n",
    "    # Log result\n",
    "    if result.returncode == 0:\n",
    "        print(f\"Untrimmed sequences saved: {untrimmed_r1}, {untrimmed_r2}\")\n",
    "    else:\n",
    "        print(f\"Error processing {input_r1} and {input_r2}:\\n{result.stderr}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d43590a",
   "metadata": {},
   "source": [
    "# 3. Q filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "330bc19f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: you specified the options for cutting by quality, but forogt to enable any of cut_front/cut_tail/cut_right. This will have no effect.\n",
      "Detecting adapter sequence for read1...\n",
      "No adapter detected for read1\n",
      "\n",
      "Read1 before filtering:\n",
      "total reads: 2468\n",
      "total bases: 271323\n",
      "Q20 bases: 262966(96.9199%)\n",
      "Q30 bases: 252892(93.207%)\n",
      "\n",
      "Read1 after filtering:\n",
      "total reads: 2144\n",
      "total bases: 232413\n",
      "Q20 bases: 230924(99.3593%)\n",
      "Q30 bases: 226129(97.2962%)\n",
      "\n",
      "Filtering result:\n",
      "reads passed filter: 2144\n",
      "reads failed due to low quality: 323\n",
      "reads failed due to too many N: 0\n",
      "reads failed due to too short: 1\n",
      "reads with adapter trimmed: 0\n",
      "bases trimmed due to adapters: 0\n",
      "\n",
      "Duplication rate (may be overestimated since this is SE data): 78.6872%\n",
      "\n",
      "JSON report: fastq_1_2_3_4_5_6/B_Qfiltered/Stepwise_05step_R1_Qfiltered.fastq.gz.json\n",
      "HTML report: fastq_1_2_3_4_5_6/B_Qfiltered/Stepwise_05step_R1_Qfiltered.fastq.gz.html\n",
      "\n",
      "fastp -i fastq_1_2_3_4_5_6/A_Untrimmed_output/Stepwise_05step_R1_untrimmed.fastq.gz -o fastq_1_2_3_4_5_6/B_Qfiltered/Stepwise_05step_R1_Qfiltered.fastq.gz -q 30 -u 15 --cut_mean_quality 30 --html fastq_1_2_3_4_5_6/B_Qfiltered/Stepwise_05step_R1_Qfiltered.fastq.gz.html --json fastq_1_2_3_4_5_6/B_Qfiltered/Stepwise_05step_R1_Qfiltered.fastq.gz.json \n",
      "fastp v0.23.4, time used: 1 seconds\n",
      "WARNING: you specified the options for cutting by quality, but forogt to enable any of cut_front/cut_tail/cut_right. This will have no effect.\n",
      "Detecting adapter sequence for read1...\n",
      "No adapter detected for read1\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering for Stepwise_05step_R1_untrimmed.fastq.gz is complete.\n",
      "Output FASTQ : fastq_1_2_3_4_5_6/B_Qfiltered/Stepwise_05step_R1_Qfiltered.fastq.gz\n",
      "Reports      : fastq_1_2_3_4_5_6/B_Qfiltered/Stepwise_05step_R1_Qfiltered.fastq.gz.html / fastq_1_2_3_4_5_6/B_Qfiltered/Stepwise_05step_R1_Qfiltered.fastq.gz.json\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read1 before filtering:\n",
      "total reads: 2632\n",
      "total bases: 163402\n",
      "Q20 bases: 151694(92.8348%)\n",
      "Q30 bases: 145564(89.0834%)\n",
      "\n",
      "Read1 after filtering:\n",
      "total reads: 2254\n",
      "total bases: 118174\n",
      "Q20 bases: 117972(99.8291%)\n",
      "Q30 bases: 117090(99.0827%)\n",
      "\n",
      "Filtering result:\n",
      "reads passed filter: 2254\n",
      "reads failed due to low quality: 355\n",
      "reads failed due to too many N: 0\n",
      "reads failed due to too short: 23\n",
      "reads with adapter trimmed: 0\n",
      "bases trimmed due to adapters: 0\n",
      "\n",
      "Duplication rate (may be overestimated since this is SE data): 85.9043%\n",
      "\n",
      "JSON report: fastq_1_2_3_4_5_6/B_Qfiltered/Stepwise_02step_R2_Qfiltered.fastq.gz.json\n",
      "HTML report: fastq_1_2_3_4_5_6/B_Qfiltered/Stepwise_02step_R2_Qfiltered.fastq.gz.html\n",
      "\n",
      "fastp -i fastq_1_2_3_4_5_6/A_Untrimmed_output/Stepwise_02step_R2_untrimmed.fastq.gz -o fastq_1_2_3_4_5_6/B_Qfiltered/Stepwise_02step_R2_Qfiltered.fastq.gz -q 30 -u 15 --cut_mean_quality 30 --html fastq_1_2_3_4_5_6/B_Qfiltered/Stepwise_02step_R2_Qfiltered.fastq.gz.html --json fastq_1_2_3_4_5_6/B_Qfiltered/Stepwise_02step_R2_Qfiltered.fastq.gz.json \n",
      "fastp v0.23.4, time used: 0 seconds\n",
      "WARNING: you specified the options for cutting by quality, but forogt to enable any of cut_front/cut_tail/cut_right. This will have no effect.\n",
      "Detecting adapter sequence for read1...\n",
      "No adapter detected for read1\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering for Stepwise_02step_R2_untrimmed.fastq.gz is complete.\n",
      "Output FASTQ : fastq_1_2_3_4_5_6/B_Qfiltered/Stepwise_02step_R2_Qfiltered.fastq.gz\n",
      "Reports      : fastq_1_2_3_4_5_6/B_Qfiltered/Stepwise_02step_R2_Qfiltered.fastq.gz.html / fastq_1_2_3_4_5_6/B_Qfiltered/Stepwise_02step_R2_Qfiltered.fastq.gz.json\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read1 before filtering:\n",
      "total reads: 2468\n",
      "total bases: 282991\n",
      "Q20 bases: 267052(94.3677%)\n",
      "Q30 bases: 252250(89.1371%)\n",
      "\n",
      "Read1 after filtering:\n",
      "total reads: 1954\n",
      "total bases: 214165\n",
      "Q20 bases: 210956(98.5016%)\n",
      "Q30 bases: 203983(95.2457%)\n",
      "\n",
      "Filtering result:\n",
      "reads passed filter: 1954\n",
      "reads failed due to low quality: 513\n",
      "reads failed due to too many N: 0\n",
      "reads failed due to too short: 1\n",
      "reads with adapter trimmed: 0\n",
      "bases trimmed due to adapters: 0\n",
      "\n",
      "Duplication rate (may be overestimated since this is SE data): 68.8817%\n",
      "\n",
      "JSON report: fastq_1_2_3_4_5_6/B_Qfiltered/Stepwise_05step_R2_Qfiltered.fastq.gz.json\n",
      "HTML report: fastq_1_2_3_4_5_6/B_Qfiltered/Stepwise_05step_R2_Qfiltered.fastq.gz.html\n",
      "\n",
      "fastp -i fastq_1_2_3_4_5_6/A_Untrimmed_output/Stepwise_05step_R2_untrimmed.fastq.gz -o fastq_1_2_3_4_5_6/B_Qfiltered/Stepwise_05step_R2_Qfiltered.fastq.gz -q 30 -u 15 --cut_mean_quality 30 --html fastq_1_2_3_4_5_6/B_Qfiltered/Stepwise_05step_R2_Qfiltered.fastq.gz.html --json fastq_1_2_3_4_5_6/B_Qfiltered/Stepwise_05step_R2_Qfiltered.fastq.gz.json \n",
      "fastp v0.23.4, time used: 1 seconds\n",
      "WARNING: you specified the options for cutting by quality, but forogt to enable any of cut_front/cut_tail/cut_right. This will have no effect.\n",
      "Detecting adapter sequence for read1...\n",
      "No adapter detected for read1\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering for Stepwise_05step_R2_untrimmed.fastq.gz is complete.\n",
      "Output FASTQ : fastq_1_2_3_4_5_6/B_Qfiltered/Stepwise_05step_R2_Qfiltered.fastq.gz\n",
      "Reports      : fastq_1_2_3_4_5_6/B_Qfiltered/Stepwise_05step_R2_Qfiltered.fastq.gz.html / fastq_1_2_3_4_5_6/B_Qfiltered/Stepwise_05step_R2_Qfiltered.fastq.gz.json\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read1 before filtering:\n",
      "total reads: 2632\n",
      "total bases: 133821\n",
      "Q20 bases: 132480(98.9979%)\n",
      "Q30 bases: 130150(97.2568%)\n",
      "\n",
      "Read1 after filtering:\n",
      "total reads: 2457\n",
      "total bases: 125363\n",
      "Q20 bases: 125152(99.8317%)\n",
      "Q30 bases: 124202(99.0739%)\n",
      "\n",
      "Filtering result:\n",
      "reads passed filter: 2457\n",
      "reads failed due to low quality: 150\n",
      "reads failed due to too many N: 0\n",
      "reads failed due to too short: 25\n",
      "reads with adapter trimmed: 0\n",
      "bases trimmed due to adapters: 0\n",
      "\n",
      "Duplication rate (may be overestimated since this is SE data): 94.5289%\n",
      "\n",
      "JSON report: fastq_1_2_3_4_5_6/B_Qfiltered/Stepwise_02step_R1_Qfiltered.fastq.gz.json\n",
      "HTML report: fastq_1_2_3_4_5_6/B_Qfiltered/Stepwise_02step_R1_Qfiltered.fastq.gz.html\n",
      "\n",
      "fastp -i fastq_1_2_3_4_5_6/A_Untrimmed_output/Stepwise_02step_R1_untrimmed.fastq.gz -o fastq_1_2_3_4_5_6/B_Qfiltered/Stepwise_02step_R1_Qfiltered.fastq.gz -q 30 -u 15 --cut_mean_quality 30 --html fastq_1_2_3_4_5_6/B_Qfiltered/Stepwise_02step_R1_Qfiltered.fastq.gz.html --json fastq_1_2_3_4_5_6/B_Qfiltered/Stepwise_02step_R1_Qfiltered.fastq.gz.json \n",
      "fastp v0.23.4, time used: 0 seconds\n",
      "WARNING: you specified the options for cutting by quality, but forogt to enable any of cut_front/cut_tail/cut_right. This will have no effect.\n",
      "Detecting adapter sequence for read1...\n",
      "No adapter detected for read1\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering for Stepwise_02step_R1_untrimmed.fastq.gz is complete.\n",
      "Output FASTQ : fastq_1_2_3_4_5_6/B_Qfiltered/Stepwise_02step_R1_Qfiltered.fastq.gz\n",
      "Reports      : fastq_1_2_3_4_5_6/B_Qfiltered/Stepwise_02step_R1_Qfiltered.fastq.gz.html / fastq_1_2_3_4_5_6/B_Qfiltered/Stepwise_02step_R1_Qfiltered.fastq.gz.json\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read1 before filtering:\n",
      "total reads: 2387\n",
      "total bases: 318681\n",
      "Q20 bases: 295857(92.838%)\n",
      "Q30 bases: 274463(86.1247%)\n",
      "\n",
      "Read1 after filtering:\n",
      "total reads: 1654\n",
      "total bases: 214977\n",
      "Q20 bases: 210076(97.7202%)\n",
      "Q30 bases: 200235(93.1425%)\n",
      "\n",
      "Filtering result:\n",
      "reads passed filter: 1654\n",
      "reads failed due to low quality: 732\n",
      "reads failed due to too many N: 0\n",
      "reads failed due to too short: 1\n",
      "reads with adapter trimmed: 0\n",
      "bases trimmed due to adapters: 0\n",
      "\n",
      "Duplication rate (may be overestimated since this is SE data): 51.9062%\n",
      "\n",
      "JSON report: fastq_1_2_3_4_5_6/B_Qfiltered/Stepwise_06step_R2_Qfiltered.fastq.gz.json\n",
      "HTML report: fastq_1_2_3_4_5_6/B_Qfiltered/Stepwise_06step_R2_Qfiltered.fastq.gz.html\n",
      "\n",
      "fastp -i fastq_1_2_3_4_5_6/A_Untrimmed_output/Stepwise_06step_R2_untrimmed.fastq.gz -o fastq_1_2_3_4_5_6/B_Qfiltered/Stepwise_06step_R2_Qfiltered.fastq.gz -q 30 -u 15 --cut_mean_quality 30 --html fastq_1_2_3_4_5_6/B_Qfiltered/Stepwise_06step_R2_Qfiltered.fastq.gz.html --json fastq_1_2_3_4_5_6/B_Qfiltered/Stepwise_06step_R2_Qfiltered.fastq.gz.json \n",
      "fastp v0.23.4, time used: 0 seconds\n",
      "WARNING: you specified the options for cutting by quality, but forogt to enable any of cut_front/cut_tail/cut_right. This will have no effect.\n",
      "Detecting adapter sequence for read1...\n",
      "No adapter detected for read1\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering for Stepwise_06step_R2_untrimmed.fastq.gz is complete.\n",
      "Output FASTQ : fastq_1_2_3_4_5_6/B_Qfiltered/Stepwise_06step_R2_Qfiltered.fastq.gz\n",
      "Reports      : fastq_1_2_3_4_5_6/B_Qfiltered/Stepwise_06step_R2_Qfiltered.fastq.gz.html / fastq_1_2_3_4_5_6/B_Qfiltered/Stepwise_06step_R2_Qfiltered.fastq.gz.json\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read1 before filtering:\n",
      "total reads: 3219\n",
      "total bases: 101569\n",
      "Q20 bases: 100677(99.1218%)\n",
      "Q30 bases: 98934(97.4057%)\n",
      "\n",
      "Read1 after filtering:\n",
      "total reads: 2960\n",
      "total bases: 94847\n",
      "Q20 bases: 94645(99.787%)\n",
      "Q30 bases: 93971(99.0764%)\n",
      "\n",
      "Filtering result:\n",
      "reads passed filter: 2960\n",
      "reads failed due to low quality: 190\n",
      "reads failed due to too many N: 0\n",
      "reads failed due to too short: 69\n",
      "reads with adapter trimmed: 0\n",
      "bases trimmed due to adapters: 0\n",
      "\n",
      "Duplication rate (may be overestimated since this is SE data): 97.2041%\n",
      "\n",
      "JSON report: fastq_1_2_3_4_5_6/B_Qfiltered/Stepwise_01step_R1_Qfiltered.fastq.gz.json\n",
      "HTML report: fastq_1_2_3_4_5_6/B_Qfiltered/Stepwise_01step_R1_Qfiltered.fastq.gz.html\n",
      "\n",
      "fastp -i fastq_1_2_3_4_5_6/A_Untrimmed_output/Stepwise_01step_R1_untrimmed.fastq.gz -o fastq_1_2_3_4_5_6/B_Qfiltered/Stepwise_01step_R1_Qfiltered.fastq.gz -q 30 -u 15 --cut_mean_quality 30 --html fastq_1_2_3_4_5_6/B_Qfiltered/Stepwise_01step_R1_Qfiltered.fastq.gz.html --json fastq_1_2_3_4_5_6/B_Qfiltered/Stepwise_01step_R1_Qfiltered.fastq.gz.json \n",
      "fastp v0.23.4, time used: 0 seconds\n",
      "WARNING: you specified the options for cutting by quality, but forogt to enable any of cut_front/cut_tail/cut_right. This will have no effect.\n",
      "Detecting adapter sequence for read1...\n",
      "No adapter detected for read1\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering for Stepwise_01step_R1_untrimmed.fastq.gz is complete.\n",
      "Output FASTQ : fastq_1_2_3_4_5_6/B_Qfiltered/Stepwise_01step_R1_Qfiltered.fastq.gz\n",
      "Reports      : fastq_1_2_3_4_5_6/B_Qfiltered/Stepwise_01step_R1_Qfiltered.fastq.gz.html / fastq_1_2_3_4_5_6/B_Qfiltered/Stepwise_01step_R1_Qfiltered.fastq.gz.json\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read1 before filtering:\n",
      "total reads: 2387\n",
      "total bases: 313755\n",
      "Q20 bases: 296656(94.5502%)\n",
      "Q30 bases: 279793(89.1756%)\n",
      "\n",
      "Read1 after filtering:\n",
      "total reads: 1802\n",
      "total bases: 232772\n",
      "Q20 bases: 230093(98.8491%)\n",
      "Q30 bases: 223168(95.8741%)\n",
      "\n",
      "Filtering result:\n",
      "reads passed filter: 1802\n",
      "reads failed due to low quality: 584\n",
      "reads failed due to too many N: 0\n",
      "reads failed due to too short: 1\n",
      "reads with adapter trimmed: 0\n",
      "bases trimmed due to adapters: 0\n",
      "\n",
      "Duplication rate (may be overestimated since this is SE data): 59.2375%\n",
      "\n",
      "JSON report: fastq_1_2_3_4_5_6/B_Qfiltered/Stepwise_06step_R1_Qfiltered.fastq.gz.json\n",
      "HTML report: fastq_1_2_3_4_5_6/B_Qfiltered/Stepwise_06step_R1_Qfiltered.fastq.gz.html\n",
      "\n",
      "fastp -i fastq_1_2_3_4_5_6/A_Untrimmed_output/Stepwise_06step_R1_untrimmed.fastq.gz -o fastq_1_2_3_4_5_6/B_Qfiltered/Stepwise_06step_R1_Qfiltered.fastq.gz -q 30 -u 15 --cut_mean_quality 30 --html fastq_1_2_3_4_5_6/B_Qfiltered/Stepwise_06step_R1_Qfiltered.fastq.gz.html --json fastq_1_2_3_4_5_6/B_Qfiltered/Stepwise_06step_R1_Qfiltered.fastq.gz.json \n",
      "fastp v0.23.4, time used: 1 seconds\n",
      "WARNING: you specified the options for cutting by quality, but forogt to enable any of cut_front/cut_tail/cut_right. This will have no effect.\n",
      "Detecting adapter sequence for read1...\n",
      "No adapter detected for read1\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering for Stepwise_06step_R1_untrimmed.fastq.gz is complete.\n",
      "Output FASTQ : fastq_1_2_3_4_5_6/B_Qfiltered/Stepwise_06step_R1_Qfiltered.fastq.gz\n",
      "Reports      : fastq_1_2_3_4_5_6/B_Qfiltered/Stepwise_06step_R1_Qfiltered.fastq.gz.html / fastq_1_2_3_4_5_6/B_Qfiltered/Stepwise_06step_R1_Qfiltered.fastq.gz.json\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read1 before filtering:\n",
      "total reads: 3219\n",
      "total bases: 147116\n",
      "Q20 bases: 132119(89.806%)\n",
      "Q30 bases: 125160(85.0757%)\n",
      "\n",
      "Read1 after filtering:\n",
      "total reads: 2724\n",
      "total bases: 95886\n",
      "Q20 bases: 95762(99.8707%)\n",
      "Q30 bases: 95123(99.2043%)\n",
      "\n",
      "Filtering result:\n",
      "reads passed filter: 2724\n",
      "reads failed due to low quality: 430\n",
      "reads failed due to too many N: 0\n",
      "reads failed due to too short: 65\n",
      "reads with adapter trimmed: 0\n",
      "bases trimmed due to adapters: 0\n",
      "\n",
      "Duplication rate (may be overestimated since this is SE data): 88.5057%\n",
      "\n",
      "JSON report: fastq_1_2_3_4_5_6/B_Qfiltered/Stepwise_01step_R2_Qfiltered.fastq.gz.json\n",
      "HTML report: fastq_1_2_3_4_5_6/B_Qfiltered/Stepwise_01step_R2_Qfiltered.fastq.gz.html\n",
      "\n",
      "fastp -i fastq_1_2_3_4_5_6/A_Untrimmed_output/Stepwise_01step_R2_untrimmed.fastq.gz -o fastq_1_2_3_4_5_6/B_Qfiltered/Stepwise_01step_R2_Qfiltered.fastq.gz -q 30 -u 15 --cut_mean_quality 30 --html fastq_1_2_3_4_5_6/B_Qfiltered/Stepwise_01step_R2_Qfiltered.fastq.gz.html --json fastq_1_2_3_4_5_6/B_Qfiltered/Stepwise_01step_R2_Qfiltered.fastq.gz.json \n",
      "fastp v0.23.4, time used: 0 seconds\n",
      "WARNING: you specified the options for cutting by quality, but forogt to enable any of cut_front/cut_tail/cut_right. This will have no effect.\n",
      "Detecting adapter sequence for read1...\n",
      "No adapter detected for read1\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering for Stepwise_01step_R2_untrimmed.fastq.gz is complete.\n",
      "Output FASTQ : fastq_1_2_3_4_5_6/B_Qfiltered/Stepwise_01step_R2_Qfiltered.fastq.gz\n",
      "Reports      : fastq_1_2_3_4_5_6/B_Qfiltered/Stepwise_01step_R2_Qfiltered.fastq.gz.html / fastq_1_2_3_4_5_6/B_Qfiltered/Stepwise_01step_R2_Qfiltered.fastq.gz.json\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read1 before filtering:\n",
      "total reads: 2741\n",
      "total bases: 267462\n",
      "Q20 bases: 255423(95.4988%)\n",
      "Q30 bases: 247215(92.43%)\n",
      "\n",
      "Read1 after filtering:\n",
      "total reads: 2374\n",
      "total bases: 219665\n",
      "Q20 bases: 218813(99.6121%)\n",
      "Q30 bases: 215981(98.3229%)\n",
      "\n",
      "Filtering result:\n",
      "reads passed filter: 2374\n",
      "reads failed due to low quality: 364\n",
      "reads failed due to too many N: 0\n",
      "reads failed due to too short: 3\n",
      "reads with adapter trimmed: 0\n",
      "bases trimmed due to adapters: 0\n",
      "\n",
      "Duplication rate (may be overestimated since this is SE data): 80.4816%\n",
      "\n",
      "JSON report: fastq_1_2_3_4_5_6/B_Qfiltered/Stepwise_04step_R2_Qfiltered.fastq.gz.json\n",
      "HTML report: fastq_1_2_3_4_5_6/B_Qfiltered/Stepwise_04step_R2_Qfiltered.fastq.gz.html\n",
      "\n",
      "fastp -i fastq_1_2_3_4_5_6/A_Untrimmed_output/Stepwise_04step_R2_untrimmed.fastq.gz -o fastq_1_2_3_4_5_6/B_Qfiltered/Stepwise_04step_R2_Qfiltered.fastq.gz -q 30 -u 15 --cut_mean_quality 30 --html fastq_1_2_3_4_5_6/B_Qfiltered/Stepwise_04step_R2_Qfiltered.fastq.gz.html --json fastq_1_2_3_4_5_6/B_Qfiltered/Stepwise_04step_R2_Qfiltered.fastq.gz.json \n",
      "fastp v0.23.4, time used: 0 seconds\n",
      "WARNING: you specified the options for cutting by quality, but forogt to enable any of cut_front/cut_tail/cut_right. This will have no effect.\n",
      "Detecting adapter sequence for read1...\n",
      "No adapter detected for read1\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering for Stepwise_04step_R2_untrimmed.fastq.gz is complete.\n",
      "Output FASTQ : fastq_1_2_3_4_5_6/B_Qfiltered/Stepwise_04step_R2_Qfiltered.fastq.gz\n",
      "Reports      : fastq_1_2_3_4_5_6/B_Qfiltered/Stepwise_04step_R2_Qfiltered.fastq.gz.html / fastq_1_2_3_4_5_6/B_Qfiltered/Stepwise_04step_R2_Qfiltered.fastq.gz.json\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read1 before filtering:\n",
      "total reads: 2706\n",
      "total bases: 194062\n",
      "Q20 bases: 191626(98.7447%)\n",
      "Q30 bases: 187949(96.85%)\n",
      "\n",
      "Read1 after filtering:\n",
      "total reads: 2530\n",
      "total bases: 181841\n",
      "Q20 bases: 181428(99.7729%)\n",
      "Q30 bases: 179808(98.882%)\n",
      "\n",
      "Filtering result:\n",
      "reads passed filter: 2530\n",
      "reads failed due to low quality: 159\n",
      "reads failed due to too many N: 0\n",
      "reads failed due to too short: 17\n",
      "reads with adapter trimmed: 0\n",
      "bases trimmed due to adapters: 0\n",
      "\n",
      "Duplication rate (may be overestimated since this is SE data): 91.4265%\n",
      "\n",
      "JSON report: fastq_1_2_3_4_5_6/B_Qfiltered/Stepwise_03step_R1_Qfiltered.fastq.gz.json\n",
      "HTML report: fastq_1_2_3_4_5_6/B_Qfiltered/Stepwise_03step_R1_Qfiltered.fastq.gz.html\n",
      "\n",
      "fastp -i fastq_1_2_3_4_5_6/A_Untrimmed_output/Stepwise_03step_R1_untrimmed.fastq.gz -o fastq_1_2_3_4_5_6/B_Qfiltered/Stepwise_03step_R1_Qfiltered.fastq.gz -q 30 -u 15 --cut_mean_quality 30 --html fastq_1_2_3_4_5_6/B_Qfiltered/Stepwise_03step_R1_Qfiltered.fastq.gz.html --json fastq_1_2_3_4_5_6/B_Qfiltered/Stepwise_03step_R1_Qfiltered.fastq.gz.json \n",
      "fastp v0.23.4, time used: 1 seconds\n",
      "WARNING: you specified the options for cutting by quality, but forogt to enable any of cut_front/cut_tail/cut_right. This will have no effect.\n",
      "Detecting adapter sequence for read1...\n",
      "No adapter detected for read1\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering for Stepwise_03step_R1_untrimmed.fastq.gz is complete.\n",
      "Output FASTQ : fastq_1_2_3_4_5_6/B_Qfiltered/Stepwise_03step_R1_Qfiltered.fastq.gz\n",
      "Reports      : fastq_1_2_3_4_5_6/B_Qfiltered/Stepwise_03step_R1_Qfiltered.fastq.gz.html / fastq_1_2_3_4_5_6/B_Qfiltered/Stepwise_03step_R1_Qfiltered.fastq.gz.json\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read1 before filtering:\n",
      "total reads: 2741\n",
      "total bases: 252271\n",
      "Q20 bases: 248474(98.4949%)\n",
      "Q30 bases: 243090(96.3607%)\n",
      "\n",
      "Read1 after filtering:\n",
      "total reads: 2543\n",
      "total bases: 233407\n",
      "Q20 bases: 232739(99.7138%)\n",
      "Q30 bases: 230134(98.5977%)\n",
      "\n",
      "Filtering result:\n",
      "reads passed filter: 2543\n",
      "reads failed due to low quality: 195\n",
      "reads failed due to too many N: 0\n",
      "reads failed due to too short: 3\n",
      "reads with adapter trimmed: 0\n",
      "bases trimmed due to adapters: 0\n",
      "\n",
      "Duplication rate (may be overestimated since this is SE data): 87.158%\n",
      "\n",
      "JSON report: fastq_1_2_3_4_5_6/B_Qfiltered/Stepwise_04step_R1_Qfiltered.fastq.gz.json\n",
      "HTML report: fastq_1_2_3_4_5_6/B_Qfiltered/Stepwise_04step_R1_Qfiltered.fastq.gz.html\n",
      "\n",
      "fastp -i fastq_1_2_3_4_5_6/A_Untrimmed_output/Stepwise_04step_R1_untrimmed.fastq.gz -o fastq_1_2_3_4_5_6/B_Qfiltered/Stepwise_04step_R1_Qfiltered.fastq.gz -q 30 -u 15 --cut_mean_quality 30 --html fastq_1_2_3_4_5_6/B_Qfiltered/Stepwise_04step_R1_Qfiltered.fastq.gz.html --json fastq_1_2_3_4_5_6/B_Qfiltered/Stepwise_04step_R1_Qfiltered.fastq.gz.json \n",
      "fastp v0.23.4, time used: 0 seconds\n",
      "WARNING: you specified the options for cutting by quality, but forogt to enable any of cut_front/cut_tail/cut_right. This will have no effect.\n",
      "Detecting adapter sequence for read1...\n",
      "No adapter detected for read1\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering for Stepwise_04step_R1_untrimmed.fastq.gz is complete.\n",
      "Output FASTQ : fastq_1_2_3_4_5_6/B_Qfiltered/Stepwise_04step_R1_Qfiltered.fastq.gz\n",
      "Reports      : fastq_1_2_3_4_5_6/B_Qfiltered/Stepwise_04step_R1_Qfiltered.fastq.gz.html / fastq_1_2_3_4_5_6/B_Qfiltered/Stepwise_04step_R1_Qfiltered.fastq.gz.json\n",
      "\n",
      "Filtering for Stepwise_03step_R2_untrimmed.fastq.gz is complete.\n",
      "Output FASTQ : fastq_1_2_3_4_5_6/B_Qfiltered/Stepwise_03step_R2_Qfiltered.fastq.gz\n",
      "Reports      : fastq_1_2_3_4_5_6/B_Qfiltered/Stepwise_03step_R2_Qfiltered.fastq.gz.html / fastq_1_2_3_4_5_6/B_Qfiltered/Stepwise_03step_R2_Qfiltered.fastq.gz.json\n",
      "\n",
      "All filtering processes are done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read1 before filtering:\n",
      "total reads: 2706\n",
      "total bases: 219279\n",
      "Q20 bases: 201488(91.8866%)\n",
      "Q30 bases: 193152(88.085%)\n",
      "\n",
      "Read1 after filtering:\n",
      "total reads: 2289\n",
      "total bases: 167242\n",
      "Q20 bases: 166915(99.8045%)\n",
      "Q30 bases: 165479(98.9458%)\n",
      "\n",
      "Filtering result:\n",
      "reads passed filter: 2289\n",
      "reads failed due to low quality: 402\n",
      "reads failed due to too many N: 0\n",
      "reads failed due to too short: 15\n",
      "reads with adapter trimmed: 0\n",
      "bases trimmed due to adapters: 0\n",
      "\n",
      "Duplication rate (may be overestimated since this is SE data): 82.3725%\n",
      "\n",
      "JSON report: fastq_1_2_3_4_5_6/B_Qfiltered/Stepwise_03step_R2_Qfiltered.fastq.gz.json\n",
      "HTML report: fastq_1_2_3_4_5_6/B_Qfiltered/Stepwise_03step_R2_Qfiltered.fastq.gz.html\n",
      "\n",
      "fastp -i fastq_1_2_3_4_5_6/A_Untrimmed_output/Stepwise_03step_R2_untrimmed.fastq.gz -o fastq_1_2_3_4_5_6/B_Qfiltered/Stepwise_03step_R2_Qfiltered.fastq.gz -q 30 -u 15 --cut_mean_quality 30 --html fastq_1_2_3_4_5_6/B_Qfiltered/Stepwise_03step_R2_Qfiltered.fastq.gz.html --json fastq_1_2_3_4_5_6/B_Qfiltered/Stepwise_03step_R2_Qfiltered.fastq.gz.json \n",
      "fastp v0.23.4, time used: 0 seconds\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "# Quality threshold (Phred score)\n",
    "quality_threshold = 30\n",
    "\n",
    "# Set input and output folders\n",
    "input_folder = \"fastq_1_2_3_4_5_6/A_Untrimmed_output\"\n",
    "output_folder = \"fastq_1_2_3_4_5_6/B_Qfiltered\"\n",
    "\n",
    "# Create output folder if it doesn't exist\n",
    "os.makedirs(output_folder, exist_ok=True) \n",
    "\n",
    "# Iterate through files in the input folder and process those ending with \"_untrimmed.fastq.gz\"\n",
    "for filename in os.listdir(input_folder):\n",
    "    if filename.endswith(\"_untrimmed.fastq.gz\"):\n",
    "        # Input file path\n",
    "        input_file = os.path.join(input_folder, filename)\n",
    "        \n",
    "        # Output file name (e.g., sample_untrimmed.fastq.gz -> sample_Qfiltered.fastq.gz)\n",
    "        output_file = os.path.join(\n",
    "            output_folder, \n",
    "            filename.replace(\"_untrimmed.fastq.gz\", \"_Qfiltered.fastq.gz\")\n",
    "        )\n",
    "        \n",
    "        # Run fastp (single-end mode)\n",
    "        subprocess.call([\n",
    "            \"fastp\",\n",
    "            \"-i\", input_file,                 # Input file\n",
    "            \"-o\", output_file,                # Output file\n",
    "            \"-q\", str(quality_threshold),     # Quality cutoff (Q30)\n",
    "            \"-u\", \"15\",                       # Discard reads with >15% low-quality bases\n",
    "            # \"-l\", \"151\",                    # Minimum read length (optional)\n",
    "            \"--cut_mean_quality\", \"30\",       # Discard reads with mean quality < 30\n",
    "            \"--html\", f\"{output_file}.html\",  # HTML report\n",
    "            \"--json\", f\"{output_file}.json\"   # JSON report\n",
    "        ])\n",
    "        \n",
    "        print(f\"Filtering for {filename} is complete.\\n\"\n",
    "              f\"Output FASTQ : {output_file}\\n\"\n",
    "              f\"Reports      : {output_file}.html / {output_file}.json\\n\")\n",
    "\n",
    "print(\"All filtering processes are done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34270d38",
   "metadata": {},
   "source": [
    "# 4. Match Paired-End Read IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0f915a10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Stepwise_06step_R1_Qfiltered.fastq.gz and Stepwise_06step_R2_Qfiltered.fastq.gz\n",
      "Total R1 IDs: 1802, Total R2 IDs: 1654, Matching IDs: 1551\n",
      "IDs only in R1: 251, IDs only in R2: 103\n",
      "\n",
      "Processing Stepwise_01step_R1_Qfiltered.fastq.gz and Stepwise_01step_R2_Qfiltered.fastq.gz\n",
      "Total R1 IDs: 2960, Total R2 IDs: 2724, Matching IDs: 2660\n",
      "IDs only in R1: 300, IDs only in R2: 64\n",
      "\n",
      "Processing Stepwise_04step_R1_Qfiltered.fastq.gz and Stepwise_04step_R2_Qfiltered.fastq.gz\n",
      "Total R1 IDs: 2543, Total R2 IDs: 2374, Matching IDs: 2328\n",
      "IDs only in R1: 215, IDs only in R2: 46\n",
      "\n",
      "Processing Stepwise_03step_R1_Qfiltered.fastq.gz and Stepwise_03step_R2_Qfiltered.fastq.gz\n",
      "Total R1 IDs: 2530, Total R2 IDs: 2289, Matching IDs: 2239\n",
      "IDs only in R1: 291, IDs only in R2: 50\n",
      "\n",
      "Processing Stepwise_02step_R1_Qfiltered.fastq.gz and Stepwise_02step_R2_Qfiltered.fastq.gz\n",
      "Total R1 IDs: 2457, Total R2 IDs: 2254, Matching IDs: 2192\n",
      "IDs only in R1: 265, IDs only in R2: 62\n",
      "\n",
      "Processing Stepwise_05step_R1_Qfiltered.fastq.gz and Stepwise_05step_R2_Qfiltered.fastq.gz\n",
      "Total R1 IDs: 2144, Total R2 IDs: 1954, Matching IDs: 1898\n",
      "IDs only in R1: 246, IDs only in R2: 56\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "import glob\n",
    "import os\n",
    "\n",
    "def extract_matching_reads(r1_path, r2_path, out_r1_path, out_r2_path):\n",
    "    def get_read_id(header):\n",
    "        # Extract read ID from FASTQ header\n",
    "        return header.split()[0].replace('/1', '').replace('/2', '')\n",
    "\n",
    "    r1_ids = set()\n",
    "    r2_ids = set()\n",
    "\n",
    "    # Extract all read IDs from the R1 file\n",
    "    with gzip.open(r1_path, 'rt') as r1_file:\n",
    "        while True:\n",
    "            header = r1_file.readline()\n",
    "            if not header:\n",
    "                break\n",
    "            r1_ids.add(get_read_id(header.strip()))\n",
    "            # Skip the other 3 lines of the read (sequence, +, quality)\n",
    "            [r1_file.readline() for _ in range(3)]  \n",
    "    \n",
    "    # Extract all read IDs from the R2 file\n",
    "    with gzip.open(r2_path, 'rt') as r2_file:\n",
    "        while True:\n",
    "            header = r2_file.readline()\n",
    "            if not header:\n",
    "                break\n",
    "            r2_ids.add(get_read_id(header.strip()))\n",
    "            [r2_file.readline() for _ in range(3)]\n",
    "\n",
    "    # Find common and unique IDs\n",
    "    matching_ids = r1_ids & r2_ids\n",
    "    r1_only = r1_ids - r2_ids\n",
    "    r2_only = r2_ids - r1_ids\n",
    "\n",
    "    print(f\"Processing {os.path.basename(r1_path)} and {os.path.basename(r2_path)}\")\n",
    "    print(f\"Total R1 IDs: {len(r1_ids)}, Total R2 IDs: {len(r2_ids)}, Matching IDs: {len(matching_ids)}\")\n",
    "    print(f\"IDs only in R1: {len(r1_only)}, IDs only in R2: {len(r2_only)}\\n\")\n",
    "\n",
    "    # Create output folders if necessary\n",
    "    for out_path in [out_r1_path, out_r2_path]:\n",
    "        os.makedirs(os.path.dirname(out_path), exist_ok=True)\n",
    "\n",
    "    # Function to write only the reads with matching IDs to a new file\n",
    "    def write_matching_reads(input_path, output_path, matching_ids):\n",
    "        with gzip.open(input_path, 'rt') as infile, gzip.open(output_path, 'wt') as outfile:\n",
    "            while True:\n",
    "                lines = [infile.readline() for _ in range(4)]\n",
    "                if not lines[0]:\n",
    "                    break\n",
    "                read_id = get_read_id(lines[0].strip())\n",
    "                if read_id in matching_ids:\n",
    "                    outfile.writelines(lines)\n",
    "\n",
    "    # Write the filtered R1 and R2 files\n",
    "    write_matching_reads(r1_path, out_r1_path, matching_ids)\n",
    "    write_matching_reads(r2_path, out_r2_path, matching_ids)\n",
    "\n",
    "# ----------------------\n",
    "# Apply to all files\n",
    "# ----------------------\n",
    "\n",
    "input_folder = \"fastq_1_2_3_4_5_6/B_Qfiltered\"\n",
    "output_folder = \"fastq_1_2_3_4_5_6/C_ID_matched\"\n",
    "\n",
    "# Find all R1 files\n",
    "r1_files = glob.glob(os.path.join(input_folder, \"*_R1_Qfiltered.fastq.gz\"))\n",
    "\n",
    "# For each R1, find the matching R2 and process\n",
    "for r1_file in r1_files:\n",
    "    r2_file = r1_file.replace(\"_R1_Qfiltered.fastq.gz\", \"_R2_Qfiltered.fastq.gz\")\n",
    "    \n",
    "    if os.path.exists(r2_file):\n",
    "        # Set output paths\n",
    "        base_name = os.path.basename(r1_file).replace(\"_R1_Qfiltered.fastq.gz\", \"\")\n",
    "        out_r1 = os.path.join(output_folder, f\"{base_name}_ID_match_R1.fastq.gz\")\n",
    "        out_r2 = os.path.join(output_folder, f\"{base_name}_ID_match_R2.fastq.gz\")\n",
    "        \n",
    "        # Execute the function\n",
    "        extract_matching_reads(r1_file, r2_file, out_r1, out_r2)\n",
    "    else:\n",
    "        print(f\"Warning: {r2_file} not found. Skipping.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c1bd29",
   "metadata": {},
   "source": [
    "# 5. Merge W/ Flash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7c9d0055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔎 Found 6 R1 files.\n",
      "🔵 Running FLASH for sample: Stepwise_06step_ID_match (N=136)\n",
      "[FLASH] Starting FLASH v1.2.11\n",
      "[FLASH] Fast Length Adjustment of SHort reads\n",
      "[FLASH]  \n",
      "[FLASH] Input files:\n",
      "[FLASH]     fastq_1_2_3_4_5_6/C_ID_matched/Stepwise_06step_ID_match_R1.fastq.gz\n",
      "[FLASH]     fastq_1_2_3_4_5_6/C_ID_matched/Stepwise_06step_ID_match_R2.fastq.gz\n",
      "[FLASH]  \n",
      "[FLASH] Output files:\n",
      "[FLASH]     fastq_1_2_3_4_5_6/D_merged_output/Stepwise_06step_ID_match_FLASH.extendedFrags.fastq\n",
      "[FLASH]     fastq_1_2_3_4_5_6/D_merged_output/Stepwise_06step_ID_match_FLASH.notCombined_1.fastq\n",
      "[FLASH]     fastq_1_2_3_4_5_6/D_merged_output/Stepwise_06step_ID_match_FLASH.notCombined_2.fastq\n",
      "[FLASH]     fastq_1_2_3_4_5_6/D_merged_output/Stepwise_06step_ID_match_FLASH.hist\n",
      "[FLASH]     fastq_1_2_3_4_5_6/D_merged_output/Stepwise_06step_ID_match_FLASH.histogram\n",
      "[FLASH]  \n",
      "[FLASH] Parameters:\n",
      "[FLASH]     Min overlap:           136\n",
      "[FLASH]     Max overlap:           136\n",
      "[FLASH]     Max mismatch density:  0.250000\n",
      "[FLASH]     Allow \"outie\" pairs:   false\n",
      "[FLASH]     Cap mismatch quals:    false\n",
      "[FLASH]     Combiner threads:      4\n",
      "[FLASH]     Input format:          FASTQ, phred_offset=33\n",
      "[FLASH]     Output format:         FASTQ, phred_offset=33\n",
      "[FLASH]  \n",
      "[FLASH] Starting reader and writer threads\n",
      "[FLASH] Starting 4 combiner threads\n",
      "[FLASH] Processed 1551 read pairs\n",
      "[FLASH]  \n",
      "[FLASH] Read combination statistics:\n",
      "[FLASH]     Total pairs:      1551\n",
      "[FLASH]     Combined pairs:   690\n",
      "[FLASH]     Uncombined pairs: 861\n",
      "[FLASH]     Percent combined: 44.49%\n",
      "[FLASH]  \n",
      "[FLASH] Writing histogram files.\n",
      "[FLASH]  \n",
      "[FLASH] FLASH v1.2.11 complete!\n",
      "[FLASH] 0.025 seconds elapsed\n",
      "✅ FLASH merging complete → fastq_1_2_3_4_5_6/D_merged_output/Stepwise_06step_ID_match_FLASH.fastq\n",
      "🔵 Running FLASH for sample: Stepwise_02step_ID_match (N=52)\n",
      "[FLASH] Starting FLASH v1.2.11\n",
      "[FLASH] Fast Length Adjustment of SHort reads\n",
      "[FLASH]  \n",
      "[FLASH] Input files:\n",
      "[FLASH]     fastq_1_2_3_4_5_6/C_ID_matched/Stepwise_02step_ID_match_R1.fastq.gz\n",
      "[FLASH]     fastq_1_2_3_4_5_6/C_ID_matched/Stepwise_02step_ID_match_R2.fastq.gz\n",
      "[FLASH]  \n",
      "[FLASH] Output files:\n",
      "[FLASH]     fastq_1_2_3_4_5_6/D_merged_output/Stepwise_02step_ID_match_FLASH.extendedFrags.fastq\n",
      "[FLASH]     fastq_1_2_3_4_5_6/D_merged_output/Stepwise_02step_ID_match_FLASH.notCombined_1.fastq\n",
      "[FLASH]     fastq_1_2_3_4_5_6/D_merged_output/Stepwise_02step_ID_match_FLASH.notCombined_2.fastq\n",
      "[FLASH]     fastq_1_2_3_4_5_6/D_merged_output/Stepwise_02step_ID_match_FLASH.hist\n",
      "[FLASH]     fastq_1_2_3_4_5_6/D_merged_output/Stepwise_02step_ID_match_FLASH.histogram\n",
      "[FLASH]  \n",
      "[FLASH] Parameters:\n",
      "[FLASH]     Min overlap:           52\n",
      "[FLASH]     Max overlap:           52\n",
      "[FLASH]     Max mismatch density:  0.250000\n",
      "[FLASH]     Allow \"outie\" pairs:   false\n",
      "[FLASH]     Cap mismatch quals:    false\n",
      "[FLASH]     Combiner threads:      4\n",
      "[FLASH]     Input format:          FASTQ, phred_offset=33\n",
      "[FLASH]     Output format:         FASTQ, phred_offset=33\n",
      "[FLASH]  \n",
      "[FLASH] Starting reader and writer threads\n",
      "[FLASH] Starting 4 combiner threads\n",
      "[FLASH] Processed 2192 read pairs\n",
      "[FLASH]  \n",
      "[FLASH] Read combination statistics:\n",
      "[FLASH]     Total pairs:      2192\n",
      "[FLASH]     Combined pairs:   1921\n",
      "[FLASH]     Uncombined pairs: 271\n",
      "[FLASH]     Percent combined: 87.64%\n",
      "[FLASH]  \n",
      "[FLASH] Writing histogram files.\n",
      "[FLASH]  \n",
      "[FLASH] FLASH v1.2.11 complete!\n",
      "[FLASH] 0.027 seconds elapsed\n",
      "✅ FLASH merging complete → fastq_1_2_3_4_5_6/D_merged_output/Stepwise_02step_ID_match_FLASH.fastq\n",
      "🔵 Running FLASH for sample: Stepwise_03step_ID_match (N=74)\n",
      "[FLASH] Starting FLASH v1.2.11\n",
      "[FLASH] Fast Length Adjustment of SHort reads\n",
      "[FLASH]  \n",
      "[FLASH] Input files:\n",
      "[FLASH]     fastq_1_2_3_4_5_6/C_ID_matched/Stepwise_03step_ID_match_R1.fastq.gz\n",
      "[FLASH]     fastq_1_2_3_4_5_6/C_ID_matched/Stepwise_03step_ID_match_R2.fastq.gz\n",
      "[FLASH]  \n",
      "[FLASH] Output files:\n",
      "[FLASH]     fastq_1_2_3_4_5_6/D_merged_output/Stepwise_03step_ID_match_FLASH.extendedFrags.fastq\n",
      "[FLASH]     fastq_1_2_3_4_5_6/D_merged_output/Stepwise_03step_ID_match_FLASH.notCombined_1.fastq\n",
      "[FLASH]     fastq_1_2_3_4_5_6/D_merged_output/Stepwise_03step_ID_match_FLASH.notCombined_2.fastq\n",
      "[FLASH]     fastq_1_2_3_4_5_6/D_merged_output/Stepwise_03step_ID_match_FLASH.hist\n",
      "[FLASH]     fastq_1_2_3_4_5_6/D_merged_output/Stepwise_03step_ID_match_FLASH.histogram\n",
      "[FLASH]  \n",
      "[FLASH] Parameters:\n",
      "[FLASH]     Min overlap:           74\n",
      "[FLASH]     Max overlap:           74\n",
      "[FLASH]     Max mismatch density:  0.250000\n",
      "[FLASH]     Allow \"outie\" pairs:   false\n",
      "[FLASH]     Cap mismatch quals:    false\n",
      "[FLASH]     Combiner threads:      4\n",
      "[FLASH]     Input format:          FASTQ, phred_offset=33\n",
      "[FLASH]     Output format:         FASTQ, phred_offset=33\n",
      "[FLASH]  \n",
      "[FLASH] Starting reader and writer threads\n",
      "[FLASH] Starting 4 combiner threads\n",
      "[FLASH] Processed 2239 read pairs\n",
      "[FLASH]  \n",
      "[FLASH] Read combination statistics:\n",
      "[FLASH]     Total pairs:      2239\n",
      "[FLASH]     Combined pairs:   1790\n",
      "[FLASH]     Uncombined pairs: 449\n",
      "[FLASH]     Percent combined: 79.95%\n",
      "[FLASH]  \n",
      "[FLASH] Writing histogram files.\n",
      "[FLASH]  \n",
      "[FLASH] FLASH v1.2.11 complete!\n",
      "[FLASH] 0.025 seconds elapsed\n",
      "✅ FLASH merging complete → fastq_1_2_3_4_5_6/D_merged_output/Stepwise_03step_ID_match_FLASH.fastq\n",
      "🔵 Running FLASH for sample: Stepwise_05step_ID_match (N=116)\n",
      "[FLASH] Starting FLASH v1.2.11\n",
      "[FLASH] Fast Length Adjustment of SHort reads\n",
      "[FLASH]  \n",
      "[FLASH] Input files:\n",
      "[FLASH]     fastq_1_2_3_4_5_6/C_ID_matched/Stepwise_05step_ID_match_R1.fastq.gz\n",
      "[FLASH]     fastq_1_2_3_4_5_6/C_ID_matched/Stepwise_05step_ID_match_R2.fastq.gz\n",
      "[FLASH]  \n",
      "[FLASH] Output files:\n",
      "[FLASH]     fastq_1_2_3_4_5_6/D_merged_output/Stepwise_05step_ID_match_FLASH.extendedFrags.fastq\n",
      "[FLASH]     fastq_1_2_3_4_5_6/D_merged_output/Stepwise_05step_ID_match_FLASH.notCombined_1.fastq\n",
      "[FLASH]     fastq_1_2_3_4_5_6/D_merged_output/Stepwise_05step_ID_match_FLASH.notCombined_2.fastq\n",
      "[FLASH]     fastq_1_2_3_4_5_6/D_merged_output/Stepwise_05step_ID_match_FLASH.hist\n",
      "[FLASH]     fastq_1_2_3_4_5_6/D_merged_output/Stepwise_05step_ID_match_FLASH.histogram\n",
      "[FLASH]  \n",
      "[FLASH] Parameters:\n",
      "[FLASH]     Min overlap:           116\n",
      "[FLASH]     Max overlap:           116\n",
      "[FLASH]     Max mismatch density:  0.250000\n",
      "[FLASH]     Allow \"outie\" pairs:   false\n",
      "[FLASH]     Cap mismatch quals:    false\n",
      "[FLASH]     Combiner threads:      4\n",
      "[FLASH]     Input format:          FASTQ, phred_offset=33\n",
      "[FLASH]     Output format:         FASTQ, phred_offset=33\n",
      "[FLASH]  \n",
      "[FLASH] Starting reader and writer threads\n",
      "[FLASH] Starting 4 combiner threads\n",
      "[FLASH] Processed 1898 read pairs\n",
      "[FLASH]  \n",
      "[FLASH] Read combination statistics:\n",
      "[FLASH]     Total pairs:      1898\n",
      "[FLASH]     Combined pairs:   1178\n",
      "[FLASH]     Uncombined pairs: 720\n",
      "[FLASH]     Percent combined: 62.07%\n",
      "[FLASH]  \n",
      "[FLASH] Writing histogram files.\n",
      "[FLASH]  \n",
      "[FLASH] FLASH v1.2.11 complete!\n",
      "[FLASH] 0.029 seconds elapsed\n",
      "[FLASH] Finished with 1 warning (see above)\n",
      "✅ FLASH merging complete → fastq_1_2_3_4_5_6/D_merged_output/Stepwise_05step_ID_match_FLASH.fastq\n",
      "🔵 Running FLASH for sample: Stepwise_01step_ID_match (N=32)\n",
      "[FLASH] Starting FLASH v1.2.11\n",
      "[FLASH] Fast Length Adjustment of SHort reads\n",
      "[FLASH]  \n",
      "[FLASH] Input files:\n",
      "[FLASH]     fastq_1_2_3_4_5_6/C_ID_matched/Stepwise_01step_ID_match_R1.fastq.gz\n",
      "[FLASH]     fastq_1_2_3_4_5_6/C_ID_matched/Stepwise_01step_ID_match_R2.fastq.gz\n",
      "[FLASH]  \n",
      "[FLASH] Output files:\n",
      "[FLASH]     fastq_1_2_3_4_5_6/D_merged_output/Stepwise_01step_ID_match_FLASH.extendedFrags.fastq\n",
      "[FLASH]     fastq_1_2_3_4_5_6/D_merged_output/Stepwise_01step_ID_match_FLASH.notCombined_1.fastq\n",
      "[FLASH]     fastq_1_2_3_4_5_6/D_merged_output/Stepwise_01step_ID_match_FLASH.notCombined_2.fastq\n",
      "[FLASH]     fastq_1_2_3_4_5_6/D_merged_output/Stepwise_01step_ID_match_FLASH.hist\n",
      "[FLASH]     fastq_1_2_3_4_5_6/D_merged_output/Stepwise_01step_ID_match_FLASH.histogram\n",
      "[FLASH]  \n",
      "[FLASH] Parameters:\n",
      "[FLASH]     Min overlap:           32\n",
      "[FLASH]     Max overlap:           32\n",
      "[FLASH]     Max mismatch density:  0.250000\n",
      "[FLASH]     Allow \"outie\" pairs:   false\n",
      "[FLASH]     Cap mismatch quals:    false\n",
      "[FLASH]     Combiner threads:      4\n",
      "[FLASH]     Input format:          FASTQ, phred_offset=33\n",
      "[FLASH]     Output format:         FASTQ, phred_offset=33\n",
      "[FLASH]  \n",
      "[FLASH] Starting reader and writer threads\n",
      "[FLASH] Starting 4 combiner threads\n",
      "[FLASH] Processed 2660 read pairs\n",
      "[FLASH]  \n",
      "[FLASH] Read combination statistics:\n",
      "[FLASH]     Total pairs:      2660\n",
      "[FLASH]     Combined pairs:   2528\n",
      "[FLASH]     Uncombined pairs: 132\n",
      "[FLASH]     Percent combined: 95.04%\n",
      "[FLASH]  \n",
      "[FLASH] Writing histogram files.\n",
      "[FLASH]  \n",
      "[FLASH] FLASH v1.2.11 complete!\n",
      "[FLASH] 0.028 seconds elapsed\n",
      "✅ FLASH merging complete → fastq_1_2_3_4_5_6/D_merged_output/Stepwise_01step_ID_match_FLASH.fastq\n",
      "🔵 Running FLASH for sample: Stepwise_04step_ID_match (N=94)\n",
      "[FLASH] Starting FLASH v1.2.11\n",
      "[FLASH] Fast Length Adjustment of SHort reads\n",
      "[FLASH]  \n",
      "[FLASH] Input files:\n",
      "[FLASH]     fastq_1_2_3_4_5_6/C_ID_matched/Stepwise_04step_ID_match_R1.fastq.gz\n",
      "[FLASH]     fastq_1_2_3_4_5_6/C_ID_matched/Stepwise_04step_ID_match_R2.fastq.gz\n",
      "[FLASH]  \n",
      "[FLASH] Output files:\n",
      "[FLASH]     fastq_1_2_3_4_5_6/D_merged_output/Stepwise_04step_ID_match_FLASH.extendedFrags.fastq\n",
      "[FLASH]     fastq_1_2_3_4_5_6/D_merged_output/Stepwise_04step_ID_match_FLASH.notCombined_1.fastq\n",
      "[FLASH]     fastq_1_2_3_4_5_6/D_merged_output/Stepwise_04step_ID_match_FLASH.notCombined_2.fastq\n",
      "[FLASH]     fastq_1_2_3_4_5_6/D_merged_output/Stepwise_04step_ID_match_FLASH.hist\n",
      "[FLASH]     fastq_1_2_3_4_5_6/D_merged_output/Stepwise_04step_ID_match_FLASH.histogram\n",
      "[FLASH]  \n",
      "[FLASH] Parameters:\n",
      "[FLASH]     Min overlap:           94\n",
      "[FLASH]     Max overlap:           94\n",
      "[FLASH]     Max mismatch density:  0.250000\n",
      "[FLASH]     Allow \"outie\" pairs:   false\n",
      "[FLASH]     Cap mismatch quals:    false\n",
      "[FLASH]     Combiner threads:      4\n",
      "[FLASH]     Input format:          FASTQ, phred_offset=33\n",
      "[FLASH]     Output format:         FASTQ, phred_offset=33\n",
      "[FLASH]  \n",
      "[FLASH] Starting reader and writer threads\n",
      "[FLASH] Starting 4 combiner threads\n",
      "[FLASH] Processed 2328 read pairs\n",
      "[FLASH]  \n",
      "[FLASH] Read combination statistics:\n",
      "[FLASH]     Total pairs:      2328\n",
      "[FLASH]     Combined pairs:   1786\n",
      "[FLASH]     Uncombined pairs: 542\n",
      "[FLASH]     Percent combined: 76.72%\n",
      "[FLASH]  \n",
      "[FLASH] Writing histogram files.\n",
      "[FLASH]  \n",
      "[FLASH] FLASH v1.2.11 complete!\n",
      "[FLASH] 0.030 seconds elapsed\n",
      "✅ FLASH merging complete → fastq_1_2_3_4_5_6/D_merged_output/Stepwise_04step_ID_match_FLASH.fastq\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[FLASH] WARNING: An unexpectedly high proportion of combined pairs (16.04%)\n",
      "overlapped by more than 116 bp, the --max-overlap (-M) parameter.  Consider\n",
      "increasing this parameter.  (As-is, FLASH is penalizing overlaps longer than\n",
      "116 bp when considering them for possible combining!)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import subprocess\n",
    "\n",
    "# === Folder setup ===\n",
    "input_folder = \"fastq_1_2_3_4_5_6/C_ID_matched\"\n",
    "output_folder = \"fastq_1_2_3_4_5_6/D_merged_output\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# === Set N-values (Overlap Length) per Sample Prefix ===\n",
    "sample_n_mapping = {\n",
    "    \"01step\": 32,  # 20 + 12\n",
    "    \"02step\": 52,  # 32 + 20\n",
    "    \"03step\": 74,  # 52 + 22\n",
    "    \"04step\": 94,  # 74 + 20\n",
    "    \"05step\": 116, # 94 + 22\n",
    "    \"06step\": 136, # 116 + 20\n",
    "}\n",
    "\n",
    "# === Find R1 files ===\n",
    "r1_files = glob.glob(os.path.join(input_folder, \"*_R1.fastq.gz\"))\n",
    "print(f\"🔎 Found {len(r1_files)} R1 files.\")\n",
    "\n",
    "# === Process each R1 file ===\n",
    "for r1_path in r1_files:\n",
    "    sample_base = os.path.basename(r1_path).replace(\"_R1.fastq.gz\", \"\")\n",
    "    r2_path = os.path.join(input_folder, f\"{sample_base}_R2.fastq.gz\")\n",
    "\n",
    "    if not os.path.exists(r2_path):\n",
    "        print(f\"⚠️ Matching R2 file not found for {sample_base} → Skipping.\")\n",
    "        continue\n",
    "\n",
    "    # Find the corresponding N value from the filename\n",
    "    matched_n = None\n",
    "    for prefix, n_value in sample_n_mapping.items():\n",
    "        if prefix in sample_base:\n",
    "            matched_n = n_value\n",
    "            break\n",
    "\n",
    "    if matched_n is None:\n",
    "        print(f\"⚠️ No N value matched for {sample_base} → Skipping.\")\n",
    "        continue\n",
    "\n",
    "    output_name = f\"{sample_base}_FLASH\"\n",
    "    print(f\"🔵 Running FLASH for sample: {sample_base} (N={matched_n})\")\n",
    "\n",
    "    try:\n",
    "        # Execute the FLASH command\n",
    "        subprocess.check_call([\n",
    "            \"flash\",\n",
    "            \"-m\", str(matched_n),   # minimum overlap\n",
    "            \"-M\", str(matched_n),   # Maximum overlap\n",
    "            \"-o\", output_name,      # Output file prefix\n",
    "            \"-d\", output_folder,    # Output directory\n",
    "            r1_path,\n",
    "            r2_path\n",
    "        ])\n",
    "        print(f\"✅ FLASH merging complete → {os.path.join(output_folder, output_name)}.fastq\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"❌ FLASH merging failed for {sample_base}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d774d169",
   "metadata": {},
   "source": [
    "# 6. fastq -> fasta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "29a7fe75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted: Stepwise_03step_ID_match_FLASH.extendedFrags.fastq → Stepwise_03step_ID_match_FLASH.extendedFrags.fasta\n",
      "Converted: Stepwise_06step_ID_match_FLASH.extendedFrags.fastq → Stepwise_06step_ID_match_FLASH.extendedFrags.fasta\n",
      "Converted: Stepwise_05step_ID_match_FLASH.extendedFrags.fastq → Stepwise_05step_ID_match_FLASH.extendedFrags.fasta\n",
      "Converted: Stepwise_04step_ID_match_FLASH.extendedFrags.fastq → Stepwise_04step_ID_match_FLASH.extendedFrags.fasta\n",
      "Converted: Stepwise_01step_ID_match_FLASH.extendedFrags.fastq → Stepwise_01step_ID_match_FLASH.extendedFrags.fasta\n",
      "Converted: Stepwise_02step_ID_match_FLASH.extendedFrags.fastq → Stepwise_02step_ID_match_FLASH.extendedFrags.fasta\n",
      "All conversions are done.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gzip\n",
    "from Bio import SeqIO\n",
    "\n",
    "# Input and output folder paths\n",
    "input_folder = \"fastq_1_2_3_4_5_6/D_merged_output\"\n",
    "output_folder = \"fastq_1_2_3_4_5_6/E_fastq_to_fasta\"\n",
    "\n",
    "# Create the output folder if it doesn't exist.\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "for filename in os.listdir(input_folder):\n",
    "    # Process only files with .fastq or .fastq.gz extensions\n",
    "    if filename.endswith(\".extendedFrags.fastq\") or filename.endswith(\".extendedFrags.fastq.gz\"):\n",
    "        input_file = os.path.join(input_folder, filename)\n",
    "        \n",
    "        # Set output filename (.fasta extension)\n",
    "        output_file = os.path.join(\n",
    "            output_folder,\n",
    "            filename.replace(\".fastq.gz\", \".fasta\").replace(\".fastq\", \".fasta\")\n",
    "        )\n",
    "\n",
    "        # Choose open mode based on gzip\n",
    "        open_func = gzip.open if filename.endswith(\".gz\") else open\n",
    "\n",
    "        # Read FASTQ and convert to FASTA\n",
    "        with open_func(input_file, \"rt\") as fastq_file:  # open in text mode\n",
    "            records = list(SeqIO.parse(fastq_file, \"fastq\"))\n",
    "\n",
    "        # Save as FASTA\n",
    "        with open(output_file, \"w\") as fasta_file:\n",
    "            SeqIO.write(records, fasta_file, \"fasta\")\n",
    "\n",
    "        print(f\"Converted: {filename} → {os.path.basename(output_file)}\")\n",
    "\n",
    "print(\"All conversions are done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa841a2",
   "metadata": {},
   "source": [
    "# 7. Each step reference data generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "0b2e8019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 01step FASTA saved: step_reference/01step_reference.fasta\n",
      "✅ 02step FASTA saved: step_reference/02step_reference.fasta\n",
      "✅ 03step FASTA saved: step_reference/03step_reference.fasta\n",
      "✅ 04step FASTA saved: step_reference/04step_reference.fasta\n",
      "✅ 05step FASTA saved: step_reference/05step_reference.fasta\n",
      "✅ 06step FASTA saved: step_reference/06step_reference.fasta\n",
      "✅ 07step FASTA saved: step_reference/07step_reference.fasta\n",
      "✅ 08step FASTA saved: step_reference/08step_reference.fasta\n",
      "✅ 09step FASTA saved: step_reference/09step_reference.fasta\n",
      "✅ 10step FASTA saved: step_reference/10step_reference.fasta\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "def generate_sequences_for_bit(bit_length: int):\n",
    "    \"\"\"\n",
    "    Generate DNA sequences for all binary combinations of the given bit_length.\n",
    "    \"\"\"\n",
    "    sequences = {}\n",
    "\n",
    "    seq_0 = \"ACTCATATACACACTTAATC\"\n",
    "    seq_1 = \"ACTCATATACATACACTTAATC\"\n",
    "    prefix = \"ACACTTAATC\"\n",
    "\n",
    "    for i in range(2 ** bit_length):\n",
    "        binary_str = format(i, f'0{bit_length}b')\n",
    "        sequence = ''.join(seq_1 if bit == '1' else seq_0 for bit in binary_str)\n",
    "        full_sequence = prefix + sequence\n",
    "        seq_id = f\"seq_{i:04d}_{binary_str}\"\n",
    "        sequences[seq_id] = full_sequence\n",
    "\n",
    "    return sequences\n",
    "\n",
    "def write_fasta(sequences: dict, output_path: str):\n",
    "    \"\"\"Write sequences to a FASTA file.\"\"\"\n",
    "    with open(output_path, \"w\") as f:\n",
    "        for seq_id, sequence in sequences.items():\n",
    "            f.write(f\">{seq_id}\\n{sequence}\\n\")\n",
    "\n",
    "# ===== Settings =====\n",
    "output_dir = Path(\"step_reference\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "MAX_STEP = 10              # Generate 1 ~ 10 steps\n",
    "PAD = len(str(MAX_STEP))   # Zero-padding width (12 → 2 digits)\n",
    "# =====================\n",
    "\n",
    "for step in range(1, MAX_STEP + 1):\n",
    "    seqs = generate_sequences_for_bit(step)\n",
    "    out_name = output_dir / f\"{step:0{PAD}d}step_reference.fasta\"  # → 01step_reference.fasta\n",
    "    write_fasta(seqs, out_name)\n",
    "    print(f\"✅ {step:0{PAD}d}step FASTA saved: {out_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d44813",
   "metadata": {},
   "source": [
    "# 8. Reference sequence - Sample Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c0613f6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 Aligning: Stepwise_02step_ID_match_FLASH.extendedFrags.fasta → 02step_reference.fasta (step=02)\n",
      "🔧 Indexing reference...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[bwa_index] Pack FASTA... 0.00 sec\n",
      "[bwa_index] Construct BWT for the packed sequence...\n",
      "[bwa_index] 0.00 seconds elapse.\n",
      "[bwa_index] Update BWT... 0.00 sec\n",
      "[bwa_index] Pack forward-only FASTA... 0.00 sec\n",
      "[bwa_index] Construct SA from BWT and Occ... 0.00 sec\n",
      "[main] Version: 0.7.17-r1188\n",
      "[main] CMD: bwa index step_reference/02step_reference.fasta\n",
      "[main] Real time: 0.027 sec; CPU: 0.003 sec\n",
      "[M::bwa_idx_load_from_disk] read 0 ALT contigs\n",
      "[M::process] read 1921 sequences (100150 bp)...\n",
      "[M::mem_process_seqs] Processed 1921 reads in 0.048 CPU sec, 0.013 real sec\n",
      "[main] Version: 0.7.17-r1188\n",
      "[main] CMD: bwa mem -M -t 4 step_reference/02step_reference.fasta fastq_1_2_3_4_5_6/E_fastq_to_fasta/Stepwise_02step_ID_match_FLASH.extendedFrags.fasta\n",
      "[main] Real time: 0.060 sec; CPU: 0.054 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Done: fastq_1_2_3_4_5_6/1_align_sam/Stepwise_02step_ID_match_FLASH.extendedFrags.sam\n",
      "🔄 Aligning: Stepwise_06step_ID_match_FLASH.extendedFrags.fasta → 06step_reference.fasta (step=06)\n",
      "🔧 Indexing reference...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[bwa_index] Pack FASTA... 0.00 sec\n",
      "[bwa_index] Construct BWT for the packed sequence...\n",
      "[bwa_index] 0.00 seconds elapse.\n",
      "[bwa_index] Update BWT... 0.00 sec\n",
      "[bwa_index] Pack forward-only FASTA... 0.00 sec\n",
      "[bwa_index] Construct SA from BWT and Occ... 0.00 sec\n",
      "[main] Version: 0.7.17-r1188\n",
      "[main] CMD: bwa index step_reference/06step_reference.fasta\n",
      "[main] Real time: 0.033 sec; CPU: 0.005 sec\n",
      "[M::bwa_idx_load_from_disk] read 0 ALT contigs\n",
      "[M::process] read 690 sequences (94440 bp)...\n",
      "[M::mem_process_seqs] Processed 690 reads in 0.118 CPU sec, 0.031 real sec\n",
      "[main] Version: 0.7.17-r1188\n",
      "[main] CMD: bwa mem -M -t 4 step_reference/06step_reference.fasta fastq_1_2_3_4_5_6/E_fastq_to_fasta/Stepwise_06step_ID_match_FLASH.extendedFrags.fasta\n",
      "[main] Real time: 0.062 sec; CPU: 0.122 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Done: fastq_1_2_3_4_5_6/1_align_sam/Stepwise_06step_ID_match_FLASH.extendedFrags.sam\n",
      "🔄 Aligning: Stepwise_05step_ID_match_FLASH.extendedFrags.fasta → 05step_reference.fasta (step=05)\n",
      "🔧 Indexing reference...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[bwa_index] Pack FASTA... 0.00 sec\n",
      "[bwa_index] Construct BWT for the packed sequence...\n",
      "[bwa_index] 0.00 seconds elapse.\n",
      "[bwa_index] Update BWT... 0.00 sec\n",
      "[bwa_index] Pack forward-only FASTA... 0.00 sec\n",
      "[bwa_index] Construct SA from BWT and Occ... 0.00 sec\n",
      "[main] Version: 0.7.17-r1188\n",
      "[main] CMD: bwa index step_reference/05step_reference.fasta\n",
      "[main] Real time: 0.028 sec; CPU: 0.004 sec\n",
      "[M::bwa_idx_load_from_disk] read 0 ALT contigs\n",
      "[M::process] read 1178 sequences (137298 bp)...\n",
      "[M::mem_process_seqs] Processed 1178 reads in 0.121 CPU sec, 0.031 real sec\n",
      "[main] Version: 0.7.17-r1188\n",
      "[main] CMD: bwa mem -M -t 4 step_reference/05step_reference.fasta fastq_1_2_3_4_5_6/E_fastq_to_fasta/Stepwise_05step_ID_match_FLASH.extendedFrags.fasta\n",
      "[main] Real time: 0.067 sec; CPU: 0.126 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Done: fastq_1_2_3_4_5_6/1_align_sam/Stepwise_05step_ID_match_FLASH.extendedFrags.sam\n",
      "🔄 Aligning: Stepwise_03step_ID_match_FLASH.extendedFrags.fasta → 03step_reference.fasta (step=03)\n",
      "🔧 Indexing reference...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[bwa_index] Pack FASTA... 0.00 sec\n",
      "[bwa_index] Construct BWT for the packed sequence...\n",
      "[bwa_index] 0.00 seconds elapse.\n",
      "[bwa_index] Update BWT... 0.00 sec\n",
      "[bwa_index] Pack forward-only FASTA... 0.00 sec\n",
      "[bwa_index] Construct SA from BWT and Occ... 0.00 sec\n",
      "[main] Version: 0.7.17-r1188\n",
      "[main] CMD: bwa index step_reference/03step_reference.fasta\n",
      "[main] Real time: 0.031 sec; CPU: 0.003 sec\n",
      "[M::bwa_idx_load_from_disk] read 0 ALT contigs\n",
      "[M::process] read 1790 sequences (132667 bp)...\n",
      "[M::mem_process_seqs] Processed 1790 reads in 0.098 CPU sec, 0.033 real sec\n",
      "[main] Version: 0.7.17-r1188\n",
      "[main] CMD: bwa mem -M -t 4 step_reference/03step_reference.fasta fastq_1_2_3_4_5_6/E_fastq_to_fasta/Stepwise_03step_ID_match_FLASH.extendedFrags.fasta\n",
      "[main] Real time: 0.127 sec; CPU: 0.107 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Done: fastq_1_2_3_4_5_6/1_align_sam/Stepwise_03step_ID_match_FLASH.extendedFrags.sam\n",
      "🔄 Aligning: Stepwise_01step_ID_match_FLASH.extendedFrags.fasta → 01step_reference.fasta (step=01)\n",
      "🔧 Indexing reference...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[bwa_index] Pack FASTA... 0.00 sec\n",
      "[bwa_index] Construct BWT for the packed sequence...\n",
      "[bwa_index] 0.00 seconds elapse.\n",
      "[bwa_index] Update BWT... 0.00 sec\n",
      "[bwa_index] Pack forward-only FASTA... 0.00 sec\n",
      "[bwa_index] Construct SA from BWT and Occ... 0.00 sec\n",
      "[main] Version: 0.7.17-r1188\n",
      "[main] CMD: bwa index step_reference/01step_reference.fasta\n",
      "[main] Real time: 0.051 sec; CPU: 0.005 sec\n",
      "[M::bwa_idx_load_from_disk] read 0 ALT contigs\n",
      "[M::process] read 2528 sequences (80989 bp)...\n",
      "[M::mem_process_seqs] Processed 2528 reads in 0.019 CPU sec, 0.006 real sec\n",
      "[main] Version: 0.7.17-r1188\n",
      "[main] CMD: bwa mem -M -t 4 step_reference/01step_reference.fasta fastq_1_2_3_4_5_6/E_fastq_to_fasta/Stepwise_01step_ID_match_FLASH.extendedFrags.fasta\n",
      "[main] Real time: 0.051 sec; CPU: 0.026 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Done: fastq_1_2_3_4_5_6/1_align_sam/Stepwise_01step_ID_match_FLASH.extendedFrags.sam\n",
      "🔄 Aligning: Stepwise_04step_ID_match_FLASH.extendedFrags.fasta → 04step_reference.fasta (step=04)\n",
      "🔧 Indexing reference...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[bwa_index] Pack FASTA... 0.00 sec\n",
      "[bwa_index] Construct BWT for the packed sequence...\n",
      "[bwa_index] 0.00 seconds elapse.\n",
      "[bwa_index] Update BWT... 0.00 sec\n",
      "[bwa_index] Pack forward-only FASTA... 0.00 sec\n",
      "[bwa_index] Construct SA from BWT and Occ... 0.00 sec\n",
      "[main] Version: 0.7.17-r1188\n",
      "[main] CMD: bwa index step_reference/04step_reference.fasta\n",
      "[main] Real time: 0.028 sec; CPU: 0.004 sec\n",
      "[M::bwa_idx_load_from_disk] read 0 ALT contigs\n",
      "[M::process] read 1786 sequences (168310 bp)...\n",
      "[M::mem_process_seqs] Processed 1786 reads in 0.129 CPU sec, 0.035 real sec\n",
      "[main] Version: 0.7.17-r1188\n",
      "[main] CMD: bwa mem -M -t 4 step_reference/04step_reference.fasta fastq_1_2_3_4_5_6/E_fastq_to_fasta/Stepwise_04step_ID_match_FLASH.extendedFrags.fasta\n",
      "[main] Real time: 0.084 sec; CPU: 0.136 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Done: fastq_1_2_3_4_5_6/1_align_sam/Stepwise_04step_ID_match_FLASH.extendedFrags.sam\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "set -euo pipefail\n",
    "shopt -s nullglob\n",
    "\n",
    "# ========== Configuration ==========\n",
    "ref_dir=\"step_reference\"                       # Reference FASTA directory\n",
    "query_dir=\"fastq_1_2_3_4_5_6/E_fastq_to_fasta\"  # Input FASTA directory\n",
    "output_dir=\"fastq_1_2_3_4_5_6/1_align_sam\"      # Output SAM directory\n",
    "threads=4\n",
    "\n",
    "# Optional: filter steps (e.g., \"07\"–\"12\")\n",
    "# Leave empty to process all steps automatically.\n",
    "step_min=\"01\"   # e.g., \"07\"\n",
    "step_max=\"06\"   # e.g., \"12\"\n",
    "# ====================================\n",
    "\n",
    "mkdir -p \"$output_dir\"\n",
    "\n",
    "# Avoid duplicate indexing during the run\n",
    "declare -A indexed\n",
    "# Avoid duplicate processing: prefer \"*assemble.fasta\"\n",
    "declare -A seen\n",
    "\n",
    "# 1) Collect \"*assemble.fasta\" first\n",
    "for f in \"$query_dir\"/*step*assemble.fasta; do\n",
    "  seen[\"$f\"]=1\n",
    "done\n",
    "\n",
    "# 2) Collect other *step*.fasta only if not already included\n",
    "for f in \"$query_dir\"/*step*.fasta; do\n",
    "  [[ -n \"${seen[$f]:-}\" ]] && continue\n",
    "  seen[\"$f\"]=1\n",
    "done\n",
    "\n",
    "# Alignment loop\n",
    "for query_file in \"${!seen[@]}\"; do\n",
    "  filename=\"$(basename \"$query_file\")\"\n",
    "\n",
    "  # Extract step digit(s): matches both _07step_ and _7step\n",
    "  if [[ \"$filename\" =~ _([0-9]+)step(_|$) ]]; then\n",
    "    step_raw=\"${BASH_REMATCH[1]}\"\n",
    "  else\n",
    "    echo \"⚠️  Step number not found in filename: $filename\"\n",
    "    continue\n",
    "  fi\n",
    "\n",
    "  # Zero-padding to 2 digits (e.g., 7 → 07)\n",
    "  step_pad=$(printf \"%02d\" $((10#$step_raw)))\n",
    "\n",
    "  # Optional step range filtering\n",
    "  if [[ -n \"$step_min\" && -n \"$step_max\" ]]; then\n",
    "    s_val=$((10#$step_pad))\n",
    "    s_min=$((10#$step_min))\n",
    "    s_max=$((10#$step_max))\n",
    "    if (( s_val < s_min || s_val > s_max )); then\n",
    "      echo \"⏭️  Skip (step not in ${step_min}–${step_max}): $filename\"\n",
    "      continue\n",
    "    fi\n",
    "  fi\n",
    "\n",
    "  reference_file=\"${ref_dir}/${step_pad}step_reference.fasta\"\n",
    "  if [[ ! -f \"$reference_file\" ]]; then\n",
    "    echo \"⚠️  Missing reference: $reference_file\"\n",
    "    continue\n",
    "  fi\n",
    "\n",
    "  out_file=\"${output_dir}/${filename%.fasta}.sam\"\n",
    "  echo \"🔄 Aligning: $filename → $(basename \"$reference_file\") (step=$step_pad)\"\n",
    "\n",
    "  # Index only once per reference in this run, and reuse existing index files\n",
    "  if [[ -z \"${indexed[$reference_file]:-}\" ]]; then\n",
    "    if [[ -f \"${reference_file}.bwt\" ]]; then\n",
    "      echo \"⏭️  Index exists, skipping indexing.\"\n",
    "    else\n",
    "      echo \"🔧 Indexing reference...\"\n",
    "      bwa index \"$reference_file\"\n",
    "    fi\n",
    "    indexed[$reference_file]=1\n",
    "  fi\n",
    "\n",
    "  bwa mem -M -t \"$threads\" \"$reference_file\" \"$query_file\" > \"$out_file\"\n",
    "  echo \"✅ Done: $out_file\"\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247c5a20",
   "metadata": {},
   "source": [
    "## 8.1 sam to bam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0d1bdfbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversion from fastq_1_2_3_4_5_6/1_align_sam/Stepwise_01step_ID_match_FLASH.extendedFrags.sam to fastq_1_2_3_4_5_6/2_align_bam/Stepwise_01step_ID_match_FLASH.extendedFrags.bam is complete.\n",
      "Conversion from fastq_1_2_3_4_5_6/1_align_sam/Stepwise_02step_ID_match_FLASH.extendedFrags.sam to fastq_1_2_3_4_5_6/2_align_bam/Stepwise_02step_ID_match_FLASH.extendedFrags.bam is complete.\n",
      "Conversion from fastq_1_2_3_4_5_6/1_align_sam/Stepwise_03step_ID_match_FLASH.extendedFrags.sam to fastq_1_2_3_4_5_6/2_align_bam/Stepwise_03step_ID_match_FLASH.extendedFrags.bam is complete.\n",
      "Conversion from fastq_1_2_3_4_5_6/1_align_sam/Stepwise_04step_ID_match_FLASH.extendedFrags.sam to fastq_1_2_3_4_5_6/2_align_bam/Stepwise_04step_ID_match_FLASH.extendedFrags.bam is complete.\n",
      "Conversion from fastq_1_2_3_4_5_6/1_align_sam/Stepwise_05step_ID_match_FLASH.extendedFrags.sam to fastq_1_2_3_4_5_6/2_align_bam/Stepwise_05step_ID_match_FLASH.extendedFrags.bam is complete.\n",
      "Conversion from fastq_1_2_3_4_5_6/1_align_sam/Stepwise_06step_ID_match_FLASH.extendedFrags.sam to fastq_1_2_3_4_5_6/2_align_bam/Stepwise_06step_ID_match_FLASH.extendedFrags.bam is complete.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "# Set the path to the directory containing SAM files\n",
    "sam_dir=\"fastq_1_2_3_4_5_6/1_align_sam\"\n",
    "# Set the output directory for BAM files\n",
    "bam_dir=\"fastq_1_2_3_4_5_6/2_align_bam\"\n",
    "\n",
    "# Make sure the output directory exists or create it if necessary\n",
    "mkdir -p \"$bam_dir\"\n",
    "\n",
    "# Convert SAM files to BAM\n",
    "for sam_file in \"$sam_dir\"/*.sam; do\n",
    "    bam_file=\"$bam_dir/$(basename \"$sam_file\" .sam).bam\"\n",
    "    samtools view -bS \"$sam_file\" -o \"$bam_file\"\n",
    "    echo \"Conversion from $sam_file to $bam_file is complete.\"\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a50049b",
   "metadata": {},
   "source": [
    "## 8.2 Convert BAM to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "abe6073c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Converted: Stepwise_05step_ID_match_FLASH.extendedFrags.bam -> Stepwise_05step_ID_match_FLASH.extendedFrags.csv\n",
      "✅ Converted: Stepwise_02step_ID_match_FLASH.extendedFrags.bam -> Stepwise_02step_ID_match_FLASH.extendedFrags.csv\n",
      "✅ Converted: Stepwise_04step_ID_match_FLASH.extendedFrags.bam -> Stepwise_04step_ID_match_FLASH.extendedFrags.csv\n",
      "✅ Converted: Stepwise_03step_ID_match_FLASH.extendedFrags.bam -> Stepwise_03step_ID_match_FLASH.extendedFrags.csv\n",
      "✅ Converted: Stepwise_01step_ID_match_FLASH.extendedFrags.bam -> Stepwise_01step_ID_match_FLASH.extendedFrags.csv\n",
      "✅ Converted: Stepwise_06step_ID_match_FLASH.extendedFrags.bam -> Stepwise_06step_ID_match_FLASH.extendedFrags.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['fastq_1_2_3_4_5_6/3_align_csv/Stepwise_05step_ID_match_FLASH.extendedFrags.csv',\n",
       " 'fastq_1_2_3_4_5_6/3_align_csv/Stepwise_02step_ID_match_FLASH.extendedFrags.csv',\n",
       " 'fastq_1_2_3_4_5_6/3_align_csv/Stepwise_04step_ID_match_FLASH.extendedFrags.csv',\n",
       " 'fastq_1_2_3_4_5_6/3_align_csv/Stepwise_03step_ID_match_FLASH.extendedFrags.csv',\n",
       " 'fastq_1_2_3_4_5_6/3_align_csv/Stepwise_01step_ID_match_FLASH.extendedFrags.csv',\n",
       " 'fastq_1_2_3_4_5_6/3_align_csv/Stepwise_06step_ID_match_FLASH.extendedFrags.csv']"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pysam\n",
    "import pandas as pd\n",
    "\n",
    "# Input folder (path containing BAM files)\n",
    "input_folder = \"fastq_1_2_3_4_5_6/2_align_bam\"\n",
    "# Output folder (path to save CSV files; change if needed)\n",
    "output_folder = \"fastq_1_2_3_4_5_6/3_align_csv\"\n",
    "\n",
    "# Create output folder if it does not exist\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# BAM -> CSV conversion function (including optional SAM tags)\n",
    "def bam_to_csv(bam_file, output_folder):\n",
    "    output_csv = os.path.join(output_folder, os.path.basename(bam_file).replace(\".bam\", \".csv\"))\n",
    "    \n",
    "    # Read BAM file\n",
    "    with pysam.AlignmentFile(bam_file, \"rb\") as bam:\n",
    "        records = []\n",
    "        all_tags = set()  # set to collect optional tag names\n",
    "        \n",
    "        for read in bam:\n",
    "            # Core fields\n",
    "            record = {\n",
    "                \"QNAME\": read.query_name,\n",
    "                \"FLAG\": read.flag,\n",
    "                \"RNAME\": bam.get_reference_name(read.reference_id) if read.reference_id >= 0 else \"*\",\n",
    "                \"POS\": read.reference_start + 1,\n",
    "                \"MAPQ\": read.mapping_quality,\n",
    "                \"CIGAR\": read.cigarstring if read.cigarstring else \"*\",\n",
    "                \"RNEXT\": bam.get_reference_name(read.next_reference_id) if read.next_reference_id >= 0 else \"*\",\n",
    "                \"PNEXT\": read.next_reference_start + 1 if read.next_reference_start >= 0 else 0,\n",
    "                \"TLEN\": read.template_length,\n",
    "                \"SEQ\": read.query_sequence if read.query_sequence else \"*\",\n",
    "                \"QUAL\": read.qual if read.qual else \"*\",\n",
    "            }\n",
    "            \n",
    "            # Optional SAM tags (aux fields)\n",
    "            for tag, value in read.tags:\n",
    "                record[tag] = value\n",
    "                all_tags.add(tag)\n",
    "\n",
    "            records.append(record)\n",
    "    \n",
    "    # Build DataFrame\n",
    "    df = pd.DataFrame(records)\n",
    "\n",
    "    # Fill missing optional fields with \"*\"\n",
    "    df = df.fillna(\"*\")\n",
    "\n",
    "    # Save CSV\n",
    "    df.to_csv(output_csv, index=False)\n",
    "    print(f\"✅ Converted: {os.path.basename(bam_file)} -> {os.path.basename(output_csv)}\")\n",
    "\n",
    "    return output_csv\n",
    "\n",
    "# Find all BAM files in the folder\n",
    "bam_files = [os.path.join(input_folder, f) for f in os.listdir(input_folder) if f.endswith(\".bam\")]\n",
    "\n",
    "# Convert all BAM files to CSV\n",
    "csv_files = []\n",
    "for bam_file in bam_files:\n",
    "    csv_file = bam_to_csv(bam_file, output_folder)\n",
    "    csv_files.append(csv_file)\n",
    "\n",
    "# Print the list of newly created CSV files.\n",
    "csv_files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6527e970",
   "metadata": {},
   "source": [
    "## 8.3 Filter Alignments by MAPQ Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "0e4d67a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Stepwise_01step_ID_match_FLASH.extendedFrags.csv → Stepwise_01step_ID_match_FLASH.extendedFrags.csv | kept=2467, removed=61 | threshold=10, keep_nan=True\n",
      "✅ Stepwise_02step_ID_match_FLASH.extendedFrags.csv → Stepwise_02step_ID_match_FLASH.extendedFrags.csv | kept=1881, removed=43 | threshold=10, keep_nan=True\n",
      "✅ Stepwise_03step_ID_match_FLASH.extendedFrags.csv → Stepwise_03step_ID_match_FLASH.extendedFrags.csv | kept=1751, removed=39 | threshold=10, keep_nan=True\n",
      "✅ Stepwise_04step_ID_match_FLASH.extendedFrags.csv → Stepwise_04step_ID_match_FLASH.extendedFrags.csv | kept=1721, removed=65 | threshold=10, keep_nan=True\n",
      "✅ Stepwise_05step_ID_match_FLASH.extendedFrags.csv → Stepwise_05step_ID_match_FLASH.extendedFrags.csv | kept=1128, removed=53 | threshold=10, keep_nan=True\n",
      "✅ Stepwise_06step_ID_match_FLASH.extendedFrags.csv → Stepwise_06step_ID_match_FLASH.extendedFrags.csv | kept=629, removed=61 | threshold=10, keep_nan=True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# ===== Settings =====\n",
    "input_dir = Path(\"fastq_1_2_3_4_5_6/3_align_csv\")  # Input folder containing CSV files\n",
    "output_dir = input_dir / \"MAPQ_removed\"            # Output folder for filtered CSV files\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "MAPQ_THRESHOLD = 10     # Keep rows where MAPQ > this value\n",
    "KEEP_NAN = True         # Keep rows with NaN MAPQ values (e.g., unaligned reads)\n",
    "# ====================\n",
    "\n",
    "def process_one_csv(in_path: Path, out_dir: Path, mapq_threshold: int, keep_nan: bool = True):\n",
    "    out_path = out_dir / in_path.name\n",
    "\n",
    "    # Remove existing output file to avoid duplicates\n",
    "    if out_path.exists():\n",
    "        out_path.unlink()\n",
    "\n",
    "    # Read input CSV\n",
    "    try:\n",
    "        df = pd.read_csv(in_path)\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️  Read fail: {in_path.name} -> {e}\")\n",
    "        return\n",
    "\n",
    "    # Skip if MAPQ column does not exist\n",
    "    if \"MAPQ\" not in df.columns:\n",
    "        print(f\"⚠️  Skip (no MAPQ column): {in_path.name}\")\n",
    "        return\n",
    "\n",
    "    # Convert MAPQ column to numeric (invalid entries become NaN)\n",
    "    m = pd.to_numeric(df[\"MAPQ\"], errors=\"coerce\")\n",
    "\n",
    "    # Filtering mask: keep MAPQ > threshold, optionally keep NaN\n",
    "    keep_mask = (m > mapq_threshold) | (m.isna() if keep_nan else False)\n",
    "\n",
    "    kept = int(keep_mask.sum())\n",
    "    removed = int((~keep_mask).sum())\n",
    "\n",
    "    # Save filtered CSV\n",
    "    df.loc[keep_mask].to_csv(out_path, index=False)\n",
    "    print(\n",
    "        f\"✅ {in_path.name} → {out_path.name} | kept={kept}, removed={removed} \"\n",
    "        f\"| threshold={mapq_threshold}, keep_nan={keep_nan}\"\n",
    "    )\n",
    "\n",
    "def main():\n",
    "    csv_files = sorted(input_dir.glob(\"*.csv\"))\n",
    "    if not csv_files:\n",
    "        print(f\"⚠️  No CSV files in {input_dir}\")\n",
    "        return\n",
    "\n",
    "    for p in csv_files:\n",
    "        process_one_csv(p, output_dir, MAPQ_THRESHOLD, KEEP_NAN)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4a0c21",
   "metadata": {},
   "source": [
    "# Histogram Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37cc2d30",
   "metadata": {},
   "source": [
    "## A. Generate Histogram Data from Aligned Reads(MAPQ filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "5c4724b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved cleaned RNAME histogram: fastq_1_2_3_4_5_6/4_align_histogram/histogram_Stepwise_06step_.csv\n",
      "✅ Saved cleaned RNAME histogram: fastq_1_2_3_4_5_6/4_align_histogram/histogram_Stepwise_01step_.csv\n",
      "✅ Saved cleaned RNAME histogram: fastq_1_2_3_4_5_6/4_align_histogram/histogram_Stepwise_03step_.csv\n",
      "✅ Saved cleaned RNAME histogram: fastq_1_2_3_4_5_6/4_align_histogram/histogram_Stepwise_04step_.csv\n",
      "✅ Saved cleaned RNAME histogram: fastq_1_2_3_4_5_6/4_align_histogram/histogram_Stepwise_02step_.csv\n",
      "✅ Saved cleaned RNAME histogram: fastq_1_2_3_4_5_6/4_align_histogram/histogram_Stepwise_05step_.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Folder setup\n",
    "input_folder = \"fastq_1_2_3_4_5_6/3_align_csv/MAPQ_removed\"\n",
    "histogram_folder = \"fastq_1_2_3_4_5_6/4_align_histogram\"\n",
    "os.makedirs(histogram_folder, exist_ok=True)\n",
    "\n",
    "# Process all CSV files in the input folder\n",
    "files = [f for f in os.listdir(input_folder) if f.endswith('.csv')]\n",
    "\n",
    "for file_name in files:\n",
    "    file_path = os.path.join(input_folder, file_name)\n",
    "\n",
    "    # Clean filename (remove specific substrings)\n",
    "    clean_name = file_name\n",
    "    clean_name = clean_name.replace(\"assemble\", \"\")\n",
    "    clean_name = clean_name.replace(\"ID_match_FLASH.extendedFrags\", \"\")\n",
    "    # remove duplicate/trailing underscores\n",
    "    clean_name = clean_name.replace(\"__\", \"_\").strip(\"_\")  \n",
    "    output_csv = os.path.join(histogram_folder, f\"histogram_{clean_name}\")\n",
    "\n",
    "    try:\n",
    "        df = pd.read_csv(file_path, dtype=str)\n",
    "        if 'RNAME' not in df.columns:\n",
    "            print(f\"⚠️ Skipping file: {file_name} (no 'RNAME' column found)\")\n",
    "            continue\n",
    "\n",
    "        # Aggregate and normalize RNAME counts\n",
    "        rname_counts = df['RNAME'].value_counts().reset_index()\n",
    "        rname_counts.columns = ['RNAME', 'Count']\n",
    "        rname_counts.insert(0, 'File_Name', clean_name)\n",
    "        rname_counts['Count'] = rname_counts['Count'].astype(int)\n",
    "        total_count = rname_counts['Count'].sum()\n",
    "        rname_counts['Normalized_Count'] = rname_counts['Count'] / total_count\n",
    "\n",
    "        rname_counts.to_csv(output_csv, index=False)\n",
    "        print(f\"✅ Saved cleaned RNAME histogram: {output_csv}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error processing file '{file_name}': {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5bcf40",
   "metadata": {},
   "source": [
    "## B. Create Top 5 Histogram Plots for Each Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "3b663461",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved plot: fastq_1_2_3_4_5_6/4_align_histogram/graph_top5/histogram_Stepwise_01step_.png, fastq_1_2_3_4_5_6/4_align_histogram/graph_top5/histogram_Stepwise_01step_.svg\n",
      "✅ Saved plot: fastq_1_2_3_4_5_6/4_align_histogram/graph_top5/histogram_Stepwise_06step_.png, fastq_1_2_3_4_5_6/4_align_histogram/graph_top5/histogram_Stepwise_06step_.svg\n",
      "✅ Saved plot: fastq_1_2_3_4_5_6/4_align_histogram/graph_top5/histogram_Stepwise_03step_.png, fastq_1_2_3_4_5_6/4_align_histogram/graph_top5/histogram_Stepwise_03step_.svg\n",
      "✅ Saved plot: fastq_1_2_3_4_5_6/4_align_histogram/graph_top5/histogram_Stepwise_02step_.png, fastq_1_2_3_4_5_6/4_align_histogram/graph_top5/histogram_Stepwise_02step_.svg\n",
      "✅ Saved plot: fastq_1_2_3_4_5_6/4_align_histogram/graph_top5/histogram_Stepwise_04step_.png, fastq_1_2_3_4_5_6/4_align_histogram/graph_top5/histogram_Stepwise_04step_.svg\n",
      "✅ Saved plot: fastq_1_2_3_4_5_6/4_align_histogram/graph_top5/histogram_Stepwise_05step_.png, fastq_1_2_3_4_5_6/4_align_histogram/graph_top5/histogram_Stepwise_05step_.svg\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 📁 Folder setup\n",
    "histogram_folder = \"fastq_1_2_3_4_5_6/4_align_histogram\"\n",
    "summary_folder = \"fastq_1_2_3_4_5_6/4_align_histogram/graph_top5\"\n",
    "os.makedirs(summary_folder, exist_ok=True)\n",
    "\n",
    "# 🔴 Highlight mapping (based on filename suffix)\n",
    "highlight_mapping = {\n",
    "    \"_01step\": \"seq_0001_1\",\n",
    "    \"_02step\": \"seq_0002_10\",\n",
    "    \"_03step\": \"seq_0005_101\",\n",
    "    \"_04step\": \"seq_0010_1010\",\n",
    "    \"_05step\": \"seq_0021_10101\",\n",
    "    \"_06step\": \"seq_0042_101010\",\n",
    "    \"_07step\": \"seq_0085_1010101\",\n",
    "    \"_08step\": \"seq_0170_10101010\",\n",
    "}\n",
    "\n",
    "# 📄 List CSV files\n",
    "csv_files = [f for f in os.listdir(histogram_folder) if f.startswith(\"histogram_\") and f.endswith(\".csv\")]\n",
    "\n",
    "# 🔁 Iterate over files\n",
    "for file_name in csv_files:\n",
    "    file_path = os.path.join(histogram_folder, file_name)\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        if 'RNAME' not in df.columns or 'Normalized_Count' not in df.columns:\n",
    "            print(f\"⚠️ Skipping file: {file_name} (missing column)\")\n",
    "            continue\n",
    "\n",
    "        # Extract Top 5 RNAMEs\n",
    "        top_df = df.sort_values(by=\"Count\", ascending=False).head(5).reset_index(drop=True)\n",
    "        sample_name = file_name.replace(\"histogram_\", \"\").replace(\".csv\", \"\")\n",
    "\n",
    "        # 🔍 Find highlight RNAME using the suffix\n",
    "        highlight_rname = None\n",
    "        for suffix, rname in highlight_mapping.items():\n",
    "            if suffix in file_name:\n",
    "                highlight_rname = rname\n",
    "                break\n",
    "\n",
    "        # 📊 Create plot\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        bars = plt.bar(top_df[\"RNAME\"], top_df[\"Normalized_Count\"], color='blue')\n",
    "\n",
    "        # 🔴 Color the matched RNAME in red\n",
    "        for bar, rname in zip(bars, top_df[\"RNAME\"]):\n",
    "            if rname == highlight_rname:\n",
    "                bar.set_color('red')\n",
    "\n",
    "        plt.title(f\"Top 5 RNAME Histogram - {sample_name}\")\n",
    "        plt.xlabel(\"RNAME\")\n",
    "        plt.ylabel(\"Normalized Count\")\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.ylim(0, 1)\n",
    "        plt.tight_layout()\n",
    "\n",
    "        # 💾 Save\n",
    "        output_png = os.path.join(summary_folder, file_name.replace(\".csv\", \".png\"))\n",
    "        output_svg = os.path.join(summary_folder, file_name.replace(\".csv\", \".svg\"))\n",
    "        plt.savefig(output_png)\n",
    "        plt.savefig(output_svg)\n",
    "        plt.close()\n",
    "\n",
    "        print(f\"✅ Saved plot: {output_png}, {output_svg}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error processing {file_name}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d12289",
   "metadata": {},
   "source": [
    "## C. Summarize Highlighted Read Counts into a CSV File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "4c241be4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📌 Highlight summary saved to: fastq_1_2_3_4_5_6/5_align_summary/highlight_result.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# === Highlight mapping (suffix -> RNAME) ===\n",
    "highlight_mapping = {\n",
    "    \"_01step\": \"seq_0001_1\",\n",
    "    \"_02step\": \"seq_0002_10\",\n",
    "    \"_03step\": \"seq_0005_101\",\n",
    "    \"_04step\": \"seq_0010_1010\",\n",
    "    \"_05step\": \"seq_0021_10101\",\n",
    "    \"_06step\": \"seq_0042_101010\",\n",
    "    \"_07step\": \"seq_0085_1010101\",\n",
    "    \"_08step\": \"seq_0170_10101010\",\n",
    "}\n",
    "\n",
    "# === Folder setup ===\n",
    "histogram_folder = \"fastq_1_2_3_4_5_6/4_align_histogram\"\n",
    "summary_folder = \"fastq_1_2_3_4_5_6/5_align_summary\"\n",
    "os.makedirs(summary_folder, exist_ok=True)\n",
    "highlight_result_csv = os.path.join(summary_folder, \"highlight_result.csv\")\n",
    "\n",
    "# === Function to extract step number ===\n",
    "def extract_step_number(filename):\n",
    "    match = re.search(r\"_(\\d+)step\", filename)\n",
    "    return int(match.group(1)) if match else float(\"inf\")\n",
    "\n",
    "# === Collect highlight summary info ===\n",
    "highlight_data = []\n",
    "csv_files = [f for f in os.listdir(histogram_folder) if f.startswith(\"histogram_\") and f.endswith(\".csv\")]\n",
    "\n",
    "for file in csv_files:\n",
    "    file_path = os.path.join(histogram_folder, file)\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        file_name = file.replace(\"histogram_\", \"\")\n",
    "\n",
    "        # Get highlight_rname by suffix\n",
    "        highlight_rname = \"\"\n",
    "        for suffix, rname in highlight_mapping.items():\n",
    "            if suffix in file_name:\n",
    "                highlight_rname = rname\n",
    "                break\n",
    "\n",
    "        df['Count'] = df['Count'].astype(int)\n",
    "        total_count = df['Count'].sum()\n",
    "\n",
    "        highlight_count = df[df['RNAME'] == highlight_rname]['Count'].sum() if highlight_rname else 0\n",
    "        highlight_percentage = (highlight_count / total_count) * 100 if total_count > 0 else 0\n",
    "\n",
    "        sorted_counts = df['Count'].sort_values(ascending=False).values\n",
    "        second_max_count = sorted_counts[1] if len(sorted_counts) >= 2 else (sorted_counts[0] if len(sorted_counts) == 1 else 0)\n",
    "        highlight_vs_second_ratio = (highlight_count / second_max_count) if second_max_count > 0 else 0\n",
    "\n",
    "        highlight_data.append([\n",
    "            file_name,\n",
    "            highlight_count,\n",
    "            total_count,\n",
    "            round(highlight_percentage, 2),\n",
    "            highlight_rname,\n",
    "            round(highlight_vs_second_ratio, 3),\n",
    "            extract_step_number(file_name)\n",
    "        ])\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error processing file '{file}': {e}\")\n",
    "\n",
    "# === Create DataFrame, sort by step, and save ===\n",
    "highlight_df = pd.DataFrame(highlight_data, columns=[\n",
    "    'File',\n",
    "    'Highlight_Count',\n",
    "    'Total_Count',\n",
    "    'Highlight_Percentage',\n",
    "    'Highlight_RNAMEs',\n",
    "    'Highlight_vs_SecondTop_Ratio',\n",
    "    'Step_Number'\n",
    "])\n",
    "\n",
    "highlight_df = highlight_df.sort_values(by='Step_Number').drop(columns='Step_Number')\n",
    "highlight_df.to_csv(highlight_result_csv, index=False)\n",
    "\n",
    "print(f\"📌 Highlight summary saved to: {highlight_result_csv}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d2f5fd3",
   "metadata": {},
   "source": [
    "## D. Plot Stacked Bar Graph top5_gray_rest_white_box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "75ae5f74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved:\n",
      " - PNG: fastq_1_2_3_4_5_6/5_align_summary/stacked_bar_top5_gray_rest_white_box.png\n",
      " - SVG: fastq_1_2_3_4_5_6/5_align_summary/stacked_bar_top5_gray_rest_white_box.svg\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# Folder setup\n",
    "histogram_folder = \"fastq_1_2_3_4_5_6/4_align_histogram\"\n",
    "summary_folder = \"fastq_1_2_3_4_5_6/5_align_summary\"\n",
    "os.makedirs(summary_folder, exist_ok=True)\n",
    "\n",
    "# Highlight mapping (based on filename suffix)\n",
    "highlight_mapping = {\n",
    "    \"_01step\": \"seq_0001_1\",\n",
    "    \"_02step\": \"seq_0002_10\",\n",
    "    \"_03step\": \"seq_0005_101\",\n",
    "    \"_04step\": \"seq_0010_1010\",\n",
    "    \"_05step\": \"seq_0021_10101\",\n",
    "    \"_06step\": \"seq_0042_101010\",\n",
    "    \"_07step\": \"seq_0085_1010101\",\n",
    "    \"_08step\": \"seq_0170_10101010\",\n",
    "}\n",
    "\n",
    "# Gray → white gradient color function\n",
    "def blend_color(base_rgb, t):\n",
    "    white = np.array([255, 255, 255])\n",
    "    base = np.array(base_rgb)\n",
    "    blended = (1 - t) * base + t * white\n",
    "    return tuple(blended / 255)\n",
    "\n",
    "base_rgb = (137, 137, 138)\n",
    "\n",
    "# Extract step number for ascending sort\n",
    "def extract_step_number(name):\n",
    "    match = re.search(r'_(\\d+)step', name)\n",
    "    return int(match.group(1)) if match else float('inf')\n",
    "\n",
    "# Load per-sample data\n",
    "sample_rname_dfs = {}\n",
    "for file_name in os.listdir(histogram_folder):\n",
    "    if file_name.startswith(\"histogram_\") and file_name.endswith(\".csv\"):\n",
    "        sample_name = file_name.replace(\"histogram_\", \"\").replace(\".csv\", \"\")\n",
    "        df = pd.read_csv(os.path.join(histogram_folder, file_name))\n",
    "        if 'RNAME' not in df.columns or 'Count' not in df.columns:\n",
    "            continue\n",
    "        df['Sample'] = sample_name\n",
    "        df['Count'] = df['Count'].astype(int)\n",
    "        df['Normalized_Count'] = df['Count'] / df['Count'].sum()\n",
    "        df = df.sort_values(by='Count', ascending=False).reset_index(drop=True)\n",
    "        sample_rname_dfs[sample_name] = df\n",
    "\n",
    "# Sort sample_name by step\n",
    "sorted_samples = sorted(sample_rname_dfs.items(), key=lambda x: extract_step_number(x[0]))\n",
    "\n",
    "# Visualization\n",
    "fig, ax = plt.subplots(figsize=(24, 12))\n",
    "\n",
    "for sample_idx, (sample_name, df) in enumerate(sorted_samples):\n",
    "    # Find highlight RNAME\n",
    "    highlight_rname = None\n",
    "    for suffix, rname in highlight_mapping.items():\n",
    "        if suffix in sample_name:  # check inclusion (not only end-of-string)\n",
    "            highlight_rname = rname\n",
    "            break\n",
    "\n",
    "    bottom = 0\n",
    "    top_n = 5\n",
    "    rest_sum = 0\n",
    "\n",
    "    for rank, row in df.iterrows():\n",
    "        rname = row['RNAME']\n",
    "        height = row['Normalized_Count']\n",
    "\n",
    "        if rname == highlight_rname:\n",
    "            ax.bar(sample_name, height, bottom=bottom, color='red', edgecolor='black', linewidth=0.2)\n",
    "            bottom += height\n",
    "        elif rank < top_n:\n",
    "            t = rank / (top_n - 1) if top_n > 1 else 0\n",
    "            color = blend_color(base_rgb, t)\n",
    "            ax.bar(sample_name, height, bottom=bottom, color=color, edgecolor='black', linewidth=0.2)\n",
    "            bottom += height\n",
    "        else:\n",
    "            rest_sum += height\n",
    "\n",
    "    if rest_sum > 0:\n",
    "        ax.bar(sample_name, rest_sum, bottom=bottom, color='white', edgecolor='black', linewidth=0.2)\n",
    "\n",
    "# Reference line & styling\n",
    "ax.axhline(y=0.5, color='gray', linestyle='--', linewidth=1, label='y = 0.5')\n",
    "ax.set_ylabel(\"Normalized Count\", fontsize=20)\n",
    "ax.set_xlabel(\"Sample\", fontsize=20)\n",
    "ax.set_title(\"Stacked Bar Chart (Red = Highlight, Gray→White = Top 5, Rest = One White Box)\", fontsize=16)\n",
    "ax.tick_params(axis='x', labelsize=20)\n",
    "ax.tick_params(axis='y', labelsize=20)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save\n",
    "png_path = os.path.join(summary_folder, \"stacked_bar_top5_gray_rest_white_box.png\")\n",
    "svg_path = os.path.join(summary_folder, \"stacked_bar_top5_gray_rest_white_box.svg\")\n",
    "plt.savefig(png_path)\n",
    "plt.savefig(svg_path)\n",
    "plt.close()\n",
    "\n",
    "print(f\"✅ Saved:\\n - PNG: {png_path}\\n - SVG: {svg_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d973acc8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
